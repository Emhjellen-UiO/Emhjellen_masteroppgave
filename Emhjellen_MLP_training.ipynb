{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training MLP-models\n",
    "\n",
    "Linn Alexandra Emhjellen, 2021. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,confusion_matrix\n",
    "\n",
    "from sklearn.metrics import recall_score,roc_curve,auc\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_excel('ML_training_features.xlsx')\n",
    "train_y = pd.read_excel('ML_training_target.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_X = pd.read_excel('ML_validation_features.xlsx')\n",
    "validation_y = pd.read_excel('ML_validation_target.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_y = validation_y['ReleaseArea']\n",
    "train_y = train_y['ReleaseArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_MLP = pd.read_excel('MLP_best_params_RandomSearch.xlsx')\n",
    "best_params_MLP = best_params_MLP.drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_grid = best_params_MLP.to_dict(orient = 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'solver': 'adam', 'hidden_layer_sizes': 37, 'alpha': 0.0},\n",
       " {'solver': 'lbfgs', 'hidden_layer_sizes': 62, 'alpha': 0.5},\n",
       " {'solver': 'lbfgs', 'hidden_layer_sizes': 50, 'alpha': 1.0},\n",
       " {'solver': 'adam', 'hidden_layer_sizes': 53, 'alpha': 1.0},\n",
       " {'solver': 'adam', 'hidden_layer_sizes': 54, 'alpha': 0.0},\n",
       " {'solver': 'adam', 'hidden_layer_sizes': 61, 'alpha': 0.5},\n",
       " {'solver': 'adam', 'hidden_layer_sizes': 49, 'alpha': 0.5},\n",
       " {'solver': 'adam', 'hidden_layer_sizes': 45, 'alpha': 0.0}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         836.480713\n",
       "1         685.930054\n",
       "2        1726.991577\n",
       "3         111.803398\n",
       "4         538.516479\n",
       "            ...     \n",
       "29817    2197.908203\n",
       "29818     452.769257\n",
       "29819    2962.785889\n",
       "29820    3012.573730\n",
       "29821    3483.231201\n",
       "Name: Distance_to_roads, Length: 29822, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X['Distance_to_roads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature combinations\n",
    "p1 = ['Slope']\n",
    "\n",
    "p2 = ['Slope','Elevation']\n",
    "\n",
    "p3 = ['Slope','North','East','North East','North West','South','South East','South West','West']\n",
    "\n",
    "p4 = ['Slope','Elevation','Plan_curv','Profile_curv','TRI','Distance_to_roads']\n",
    "\n",
    "p5 = ['Slope','Elevation','Plan_curv','Profile_curv','TRI','Flow_dir','Flow_acc','Distance_to_roads']\n",
    "\n",
    "p6 = ['Slope','Elevation','Plan_curv','Profile_curv','TRI']\n",
    "\n",
    "p7 = ['Elevation','North','East','North East','North West','South','South East','South West','West','Plan_curv','Profile_curv','TRI','Flow_dir','Flow_acc','Distance_to_roads']\n",
    "\n",
    "p8 = ['Slope','Elevation','North','East','North East','North West','South','South East','South West','West','Plan_curv','Profile_curv','TRI','Flow_dir','Flow_acc','Distance_to_roads',\n",
    "      'Granite','Granodiorite','Tonalite','Trondhjemite','Syenite','Monzonite','Monzodiorite','Quartz diorite','Diorite','Gabbro','Norite','Peridotite','Pyroksenite','Charnockite','Mangerite','Anorthosite','Mafic dyke (Diabase, Dolerite)','Pegmatite/aplite','Felsic volcanic rock','Rhyolite','Dacite','Intermediate volcanic rock','Andesite','Mafic volcanic rock','Basalt',\n",
    "                  'Pyroclastic rock','Volcanic breccia','Siltstone','Sandstone','Greywacke','Arkose','Konglomerate','Sedimentary breccia','Limestone','Tuffite','Shale','Phyllite','Mica schist','Garnet mica schist','Calcareous phyllite','Calcareous mica schist','Amphibole schist','Graphitic schist','Calcite marble',\n",
    "                 'Metasandstone','Metagreywacke','Meta-arkose','Quartzite','Quartz schist','Mica gneiss','Calc-silicate rock','Amphibole gneiss','Granitic gneiss','Granodioritic gneiss','Tonalitic gneiss','Quartz dioritic gneiss','Monzonitic gneiss','Dioritic gneis','Orthopyroxene gneiss','Migmatite','Augengneiss',\n",
    "                    'Banded gneiss','Greenschist','Greenstone','Amphibolite','Metagabbro','Eclogite','Serpentinite','Mylonite/Phyllonite','Cataclasite']\n",
    "\n",
    "feature_combinations = [p1,p2,p3,p4,p5,p6,p7,p8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf_mlp = MLPClassifier(hidden_layer_sizes=best_params_MLP.iloc[1][1], solver=best_params_MLP.iloc[1][0], alpha=best_params_MLP.iloc[1][2], max_iter=200,verbose=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_param_grid[0][\"hidden_layer_sizes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.44452890\n",
      "Iteration 2, loss = 0.22328555\n",
      "Iteration 3, loss = 0.17387520\n",
      "Iteration 4, loss = 0.16318544\n",
      "Iteration 5, loss = 0.16020081\n",
      "Iteration 6, loss = 0.15906919\n",
      "Iteration 7, loss = 0.15843653\n",
      "Iteration 8, loss = 0.15797384\n",
      "Iteration 9, loss = 0.15760658\n",
      "Iteration 10, loss = 0.15730770\n",
      "Iteration 11, loss = 0.15707473\n",
      "Iteration 12, loss = 0.15688242\n",
      "Iteration 13, loss = 0.15673433\n",
      "Iteration 14, loss = 0.15662019\n",
      "Iteration 15, loss = 0.15660796\n",
      "Iteration 16, loss = 0.15646407\n",
      "Iteration 17, loss = 0.15643931\n",
      "Iteration 18, loss = 0.15634715\n",
      "Iteration 19, loss = 0.15631822\n",
      "Iteration 20, loss = 0.15630637\n",
      "Iteration 21, loss = 0.15621841\n",
      "Iteration 22, loss = 0.15629388\n",
      "Iteration 23, loss = 0.15629925\n",
      "Iteration 24, loss = 0.15625167\n",
      "Iteration 25, loss = 0.15635004\n",
      "Iteration 26, loss = 0.15622942\n",
      "Iteration 27, loss = 0.15616594\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.83657723\n",
      "Iteration 2, loss = 0.43137885\n",
      "Iteration 3, loss = 0.24933670\n",
      "Iteration 4, loss = 0.19203285\n",
      "Iteration 5, loss = 0.17231969\n",
      "Iteration 6, loss = 0.16429946\n",
      "Iteration 7, loss = 0.16060631\n",
      "Iteration 8, loss = 0.15870173\n",
      "Iteration 9, loss = 0.15758813\n",
      "Iteration 10, loss = 0.15688023\n",
      "Iteration 11, loss = 0.15633842\n",
      "Iteration 12, loss = 0.15591355\n",
      "Iteration 13, loss = 0.15562655\n",
      "Iteration 14, loss = 0.15530933\n",
      "Iteration 15, loss = 0.15506925\n",
      "Iteration 16, loss = 0.15492232\n",
      "Iteration 17, loss = 0.15476126\n",
      "Iteration 18, loss = 0.15470294\n",
      "Iteration 19, loss = 0.15457749\n",
      "Iteration 20, loss = 0.15451966\n",
      "Iteration 21, loss = 0.15447229\n",
      "Iteration 22, loss = 0.15446724\n",
      "Iteration 23, loss = 0.15436610\n",
      "Iteration 24, loss = 0.15436380\n",
      "Iteration 25, loss = 0.15432358\n",
      "Iteration 26, loss = 0.15437867\n",
      "Iteration 27, loss = 0.15431030\n",
      "Iteration 28, loss = 0.15432342\n",
      "Iteration 29, loss = 0.15428040\n",
      "Iteration 30, loss = 0.15433613\n",
      "Iteration 31, loss = 0.15432710\n",
      "Iteration 32, loss = 0.15425286\n",
      "Iteration 33, loss = 0.15426450\n",
      "Iteration 34, loss = 0.15425855\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.49092745\n",
      "Iteration 2, loss = 0.26387315\n",
      "Iteration 3, loss = 0.19416457\n",
      "Iteration 4, loss = 0.17209942\n",
      "Iteration 5, loss = 0.16395531\n",
      "Iteration 6, loss = 0.16072427\n",
      "Iteration 7, loss = 0.15932429\n",
      "Iteration 8, loss = 0.15860218\n",
      "Iteration 9, loss = 0.15814623\n",
      "Iteration 10, loss = 0.15782544\n",
      "Iteration 11, loss = 0.15747585\n",
      "Iteration 12, loss = 0.15720659\n",
      "Iteration 13, loss = 0.15707067\n",
      "Iteration 14, loss = 0.15689396\n",
      "Iteration 15, loss = 0.15680845\n",
      "Iteration 16, loss = 0.15666327\n",
      "Iteration 17, loss = 0.15655903\n",
      "Iteration 18, loss = 0.15640532\n",
      "Iteration 19, loss = 0.15643511\n",
      "Iteration 20, loss = 0.15635246\n",
      "Iteration 21, loss = 0.15634666\n",
      "Iteration 22, loss = 0.15621215\n",
      "Iteration 23, loss = 0.15634422\n",
      "Iteration 24, loss = 0.15623693\n",
      "Iteration 25, loss = 0.15623456\n",
      "Iteration 26, loss = 0.15617611\n",
      "Iteration 27, loss = 0.15619420\n",
      "Iteration 28, loss = 0.15623813\n",
      "Iteration 29, loss = 0.15617486\n",
      "Iteration 30, loss = 0.15614552\n",
      "Iteration 31, loss = 0.15625784\n",
      "Iteration 32, loss = 0.15613270\n",
      "Iteration 33, loss = 0.15614272\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.48438453\n",
      "Iteration 2, loss = 0.27162345\n",
      "Iteration 3, loss = 0.19322516\n",
      "Iteration 4, loss = 0.17175609\n",
      "Iteration 5, loss = 0.16462182\n",
      "Iteration 6, loss = 0.16164360\n",
      "Iteration 7, loss = 0.16009852\n",
      "Iteration 8, loss = 0.15875988\n",
      "Iteration 9, loss = 0.15806299\n",
      "Iteration 10, loss = 0.15739220\n",
      "Iteration 11, loss = 0.15694258\n",
      "Iteration 12, loss = 0.15665290\n",
      "Iteration 13, loss = 0.15638056\n",
      "Iteration 14, loss = 0.15624968\n",
      "Iteration 15, loss = 0.15604365\n",
      "Iteration 16, loss = 0.15593697\n",
      "Iteration 17, loss = 0.15584929\n",
      "Iteration 18, loss = 0.15554814\n",
      "Iteration 19, loss = 0.15577451\n",
      "Iteration 20, loss = 0.15567854\n",
      "Iteration 21, loss = 0.15561860\n",
      "Iteration 22, loss = 0.15579661\n",
      "Iteration 23, loss = 0.15554462\n",
      "Iteration 24, loss = 0.15554778\n",
      "Iteration 25, loss = 0.15554217\n",
      "Iteration 26, loss = 0.15550672\n",
      "Iteration 27, loss = 0.15545616\n",
      "Iteration 28, loss = 0.15550090\n",
      "Iteration 29, loss = 0.15542725\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.55283858\n",
      "Iteration 2, loss = 0.34822034\n",
      "Iteration 3, loss = 0.24645815\n",
      "Iteration 4, loss = 0.19832674\n",
      "Iteration 5, loss = 0.17614656\n",
      "Iteration 6, loss = 0.16590200\n",
      "Iteration 7, loss = 0.16094300\n",
      "Iteration 8, loss = 0.15863314\n",
      "Iteration 9, loss = 0.15746140\n",
      "Iteration 10, loss = 0.15678904\n",
      "Iteration 11, loss = 0.15630635\n",
      "Iteration 12, loss = 0.15599619\n",
      "Iteration 13, loss = 0.15575239\n",
      "Iteration 14, loss = 0.15568711\n",
      "Iteration 15, loss = 0.15545400\n",
      "Iteration 16, loss = 0.15531023\n",
      "Iteration 17, loss = 0.15525242\n",
      "Iteration 18, loss = 0.15519695\n",
      "Iteration 19, loss = 0.15512226\n",
      "Iteration 20, loss = 0.15503819\n",
      "Iteration 21, loss = 0.15508558\n",
      "Iteration 22, loss = 0.15503811\n",
      "Iteration 23, loss = 0.15501357\n",
      "Iteration 24, loss = 0.15499878\n",
      "Iteration 25, loss = 0.15500239\n",
      "Iteration 26, loss = 0.15490010\n",
      "Iteration 27, loss = 0.15497303\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.45155291\n",
      "Iteration 2, loss = 0.25126358\n",
      "Iteration 3, loss = 0.18836632\n",
      "Iteration 4, loss = 0.17096650\n",
      "Iteration 5, loss = 0.16552836\n",
      "Iteration 6, loss = 0.16349164\n",
      "Iteration 7, loss = 0.16256105\n",
      "Iteration 8, loss = 0.16204766\n",
      "Iteration 9, loss = 0.16157224\n",
      "Iteration 10, loss = 0.16126845\n",
      "Iteration 11, loss = 0.16108258\n",
      "Iteration 12, loss = 0.16073789\n",
      "Iteration 13, loss = 0.16066885\n",
      "Iteration 14, loss = 0.16040955\n",
      "Iteration 15, loss = 0.16031487\n",
      "Iteration 16, loss = 0.16019719\n",
      "Iteration 17, loss = 0.16018761\n",
      "Iteration 18, loss = 0.16006400\n",
      "Iteration 19, loss = 0.15999701\n",
      "Iteration 20, loss = 0.16000498\n",
      "Iteration 21, loss = 0.15995027\n",
      "Iteration 22, loss = 0.15996170\n",
      "Iteration 23, loss = 0.15994230\n",
      "Iteration 24, loss = 0.15995260\n",
      "Iteration 25, loss = 0.15993458\n",
      "Iteration 26, loss = 0.15985845\n",
      "Iteration 27, loss = 0.15986725\n",
      "Iteration 28, loss = 0.15982312\n",
      "Iteration 29, loss = 0.15980626\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.40002197\n",
      "Iteration 2, loss = 0.22556571\n",
      "Iteration 3, loss = 0.19409110\n",
      "Iteration 4, loss = 0.18384145\n",
      "Iteration 5, loss = 0.17879054\n",
      "Iteration 6, loss = 0.17592298\n",
      "Iteration 7, loss = 0.17378633\n",
      "Iteration 8, loss = 0.17248789\n",
      "Iteration 9, loss = 0.17149372\n",
      "Iteration 10, loss = 0.17088552\n",
      "Iteration 11, loss = 0.17038425\n",
      "Iteration 12, loss = 0.17010855\n",
      "Iteration 13, loss = 0.16980326\n",
      "Iteration 14, loss = 0.16963290\n",
      "Iteration 15, loss = 0.16923143\n",
      "Iteration 16, loss = 0.16918552\n",
      "Iteration 17, loss = 0.16924894\n",
      "Iteration 18, loss = 0.16904394\n",
      "Iteration 19, loss = 0.16888879\n",
      "Iteration 20, loss = 0.16882843\n",
      "Iteration 21, loss = 0.16891398\n",
      "Iteration 22, loss = 0.16864840\n",
      "Iteration 23, loss = 0.16849817\n",
      "Iteration 24, loss = 0.16864737\n",
      "Iteration 25, loss = 0.16852088\n",
      "Iteration 26, loss = 0.16853391\n",
      "Iteration 27, loss = 0.16840941\n",
      "Iteration 28, loss = 0.16837605\n",
      "Iteration 29, loss = 0.16834216\n",
      "Iteration 30, loss = 0.16835129\n",
      "Iteration 31, loss = 0.16836871\n",
      "Iteration 32, loss = 0.16832734\n",
      "Iteration 33, loss = 0.16820961\n",
      "Iteration 34, loss = 0.16811854\n",
      "Iteration 35, loss = 0.16833614\n",
      "Iteration 36, loss = 0.16822996\n",
      "Iteration 37, loss = 0.16820896\n",
      "Iteration 38, loss = 0.16816949\n",
      "Iteration 39, loss = 0.16815808\n",
      "Iteration 40, loss = 0.16821929\n",
      "Iteration 41, loss = 0.16812811\n",
      "Iteration 42, loss = 0.16824975\n",
      "Iteration 43, loss = 0.16815429\n",
      "Iteration 44, loss = 0.16806297\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.57501570\n",
      "Iteration 2, loss = 0.28729828\n",
      "Iteration 3, loss = 0.21845972\n",
      "Iteration 4, loss = 0.19460541\n",
      "Iteration 5, loss = 0.18452310\n",
      "Iteration 6, loss = 0.17975602\n",
      "Iteration 7, loss = 0.17668352\n",
      "Iteration 8, loss = 0.17460810\n",
      "Iteration 9, loss = 0.17325131\n",
      "Iteration 10, loss = 0.17198360\n",
      "Iteration 11, loss = 0.17115016\n",
      "Iteration 12, loss = 0.17030011\n",
      "Iteration 13, loss = 0.16961973\n",
      "Iteration 14, loss = 0.16917817\n",
      "Iteration 15, loss = 0.16887813\n",
      "Iteration 16, loss = 0.16853261\n",
      "Iteration 17, loss = 0.16838053\n",
      "Iteration 18, loss = 0.16808366\n",
      "Iteration 19, loss = 0.16792143\n",
      "Iteration 20, loss = 0.16777784\n",
      "Iteration 21, loss = 0.16763868\n",
      "Iteration 22, loss = 0.16770590\n",
      "Iteration 23, loss = 0.16756016\n",
      "Iteration 24, loss = 0.16751022\n",
      "Iteration 25, loss = 0.16736532\n",
      "Iteration 26, loss = 0.16740253\n",
      "Iteration 27, loss = 0.16727198\n",
      "Iteration 28, loss = 0.16721246\n",
      "Iteration 29, loss = 0.16718738\n",
      "Iteration 30, loss = 0.16718547\n",
      "Iteration 31, loss = 0.16751149\n",
      "Iteration 32, loss = 0.16718558\n",
      "Iteration 33, loss = 0.16706950\n",
      "Iteration 34, loss = 0.16724646\n",
      "Iteration 35, loss = 0.16700769\n",
      "Iteration 36, loss = 0.16716007\n",
      "Iteration 37, loss = 0.16714136\n",
      "Iteration 38, loss = 0.16708773\n",
      "Iteration 39, loss = 0.16704045\n",
      "Iteration 40, loss = 0.16692231\n",
      "Iteration 41, loss = 0.16699866\n",
      "Iteration 42, loss = 0.16682779\n",
      "Iteration 43, loss = 0.16701520\n",
      "Iteration 44, loss = 0.16693538\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.45984202\n",
      "Iteration 2, loss = 0.25529360\n",
      "Iteration 3, loss = 0.20583406\n",
      "Iteration 4, loss = 0.19064570\n",
      "Iteration 5, loss = 0.18409118\n",
      "Iteration 6, loss = 0.18042615\n",
      "Iteration 7, loss = 0.17778185\n",
      "Iteration 8, loss = 0.17610440\n",
      "Iteration 9, loss = 0.17478151\n",
      "Iteration 10, loss = 0.17384150\n",
      "Iteration 11, loss = 0.17272658\n",
      "Iteration 12, loss = 0.17202080\n",
      "Iteration 13, loss = 0.17143897\n",
      "Iteration 14, loss = 0.17137607\n",
      "Iteration 15, loss = 0.17075510\n",
      "Iteration 16, loss = 0.17045959\n",
      "Iteration 17, loss = 0.17026988\n",
      "Iteration 18, loss = 0.17015807\n",
      "Iteration 19, loss = 0.16992725\n",
      "Iteration 20, loss = 0.16974122\n",
      "Iteration 21, loss = 0.16970312\n",
      "Iteration 22, loss = 0.16946432\n",
      "Iteration 23, loss = 0.16949085\n",
      "Iteration 24, loss = 0.16950373\n",
      "Iteration 25, loss = 0.16925083\n",
      "Iteration 26, loss = 0.16922209\n",
      "Iteration 27, loss = 0.16930828\n",
      "Iteration 28, loss = 0.16918394\n",
      "Iteration 29, loss = 0.16903723\n",
      "Iteration 30, loss = 0.16912442\n",
      "Iteration 31, loss = 0.16908270\n",
      "Iteration 32, loss = 0.16901241\n",
      "Iteration 33, loss = 0.16925833\n",
      "Iteration 34, loss = 0.16888374\n",
      "Iteration 35, loss = 0.16890219\n",
      "Iteration 36, loss = 0.16915207\n",
      "Iteration 37, loss = 0.16889052\n",
      "Iteration 38, loss = 0.16894358\n",
      "Iteration 39, loss = 0.16879406\n",
      "Iteration 40, loss = 0.16890898\n",
      "Iteration 41, loss = 0.16875960\n",
      "Iteration 42, loss = 0.16880065\n",
      "Iteration 43, loss = 0.16864421\n",
      "Iteration 44, loss = 0.16868344\n",
      "Iteration 45, loss = 0.16864050\n",
      "Iteration 46, loss = 0.16881094\n",
      "Iteration 47, loss = 0.16856083\n",
      "Iteration 48, loss = 0.16860576\n",
      "Iteration 49, loss = 0.16866348\n",
      "Iteration 50, loss = 0.16858560\n",
      "Iteration 51, loss = 0.16853576\n",
      "Iteration 52, loss = 0.16876837\n",
      "Iteration 53, loss = 0.16860248\n",
      "Iteration 54, loss = 0.16865533\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.47082963\n",
      "Iteration 2, loss = 0.25806271\n",
      "Iteration 3, loss = 0.20289271\n",
      "Iteration 4, loss = 0.18695212\n",
      "Iteration 5, loss = 0.18056893\n",
      "Iteration 6, loss = 0.17690555\n",
      "Iteration 7, loss = 0.17459160\n",
      "Iteration 8, loss = 0.17293497\n",
      "Iteration 9, loss = 0.17187890\n",
      "Iteration 10, loss = 0.17110348\n",
      "Iteration 11, loss = 0.17047929\n",
      "Iteration 12, loss = 0.16990732\n",
      "Iteration 13, loss = 0.16959606\n",
      "Iteration 14, loss = 0.16925233\n",
      "Iteration 15, loss = 0.16903064\n",
      "Iteration 16, loss = 0.16904287\n",
      "Iteration 17, loss = 0.16868743\n",
      "Iteration 18, loss = 0.16841322\n",
      "Iteration 19, loss = 0.16846082\n",
      "Iteration 20, loss = 0.16845714\n",
      "Iteration 21, loss = 0.16813556\n",
      "Iteration 22, loss = 0.16814759\n",
      "Iteration 23, loss = 0.16809777\n",
      "Iteration 24, loss = 0.16799092\n",
      "Iteration 25, loss = 0.16783847\n",
      "Iteration 26, loss = 0.16777583\n",
      "Iteration 27, loss = 0.16791590\n",
      "Iteration 28, loss = 0.16770539\n",
      "Iteration 29, loss = 0.16775647\n",
      "Iteration 30, loss = 0.16773319\n",
      "Iteration 31, loss = 0.16764542\n",
      "Iteration 32, loss = 0.16774063\n",
      "Iteration 33, loss = 0.16754951\n",
      "Iteration 34, loss = 0.16765547\n",
      "Iteration 35, loss = 0.16774098\n",
      "Iteration 36, loss = 0.16769516\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.47562340\n",
      "Iteration 2, loss = 0.26823250\n",
      "Iteration 3, loss = 0.21246205\n",
      "Iteration 4, loss = 0.19310378\n",
      "Iteration 5, loss = 0.18470959\n",
      "Iteration 6, loss = 0.17997584\n",
      "Iteration 7, loss = 0.17680765\n",
      "Iteration 8, loss = 0.17447532\n",
      "Iteration 9, loss = 0.17287022\n",
      "Iteration 10, loss = 0.17158741\n",
      "Iteration 11, loss = 0.17080823\n",
      "Iteration 12, loss = 0.16994056\n",
      "Iteration 13, loss = 0.16954953\n",
      "Iteration 14, loss = 0.16903722\n",
      "Iteration 15, loss = 0.16887522\n",
      "Iteration 16, loss = 0.16841103\n",
      "Iteration 17, loss = 0.16812130\n",
      "Iteration 18, loss = 0.16797406\n",
      "Iteration 19, loss = 0.16785194\n",
      "Iteration 20, loss = 0.16769190\n",
      "Iteration 21, loss = 0.16771747\n",
      "Iteration 22, loss = 0.16761309\n",
      "Iteration 23, loss = 0.16747064\n",
      "Iteration 24, loss = 0.16752533\n",
      "Iteration 25, loss = 0.16729087\n",
      "Iteration 26, loss = 0.16721268\n",
      "Iteration 27, loss = 0.16728984\n",
      "Iteration 28, loss = 0.16712147\n",
      "Iteration 29, loss = 0.16725056\n",
      "Iteration 30, loss = 0.16711600\n",
      "Iteration 31, loss = 0.16720242\n",
      "Iteration 32, loss = 0.16712930\n",
      "Iteration 33, loss = 0.16703771\n",
      "Iteration 34, loss = 0.16694510\n",
      "Iteration 35, loss = 0.16697272\n",
      "Iteration 36, loss = 0.16697128\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.48354958\n",
      "Iteration 2, loss = 0.26783137\n",
      "Iteration 3, loss = 0.21353466\n",
      "Iteration 4, loss = 0.19473660\n",
      "Iteration 5, loss = 0.18662451\n",
      "Iteration 6, loss = 0.18236199\n",
      "Iteration 7, loss = 0.17961724\n",
      "Iteration 8, loss = 0.17754730\n",
      "Iteration 9, loss = 0.17611823\n",
      "Iteration 10, loss = 0.17481751\n",
      "Iteration 11, loss = 0.17430879\n",
      "Iteration 12, loss = 0.17357997\n",
      "Iteration 13, loss = 0.17317925\n",
      "Iteration 14, loss = 0.17299559\n",
      "Iteration 15, loss = 0.17240142\n",
      "Iteration 16, loss = 0.17217266\n",
      "Iteration 17, loss = 0.17208582\n",
      "Iteration 18, loss = 0.17182350\n",
      "Iteration 19, loss = 0.17162736\n",
      "Iteration 20, loss = 0.17150871\n",
      "Iteration 21, loss = 0.17160171\n",
      "Iteration 22, loss = 0.17134154\n",
      "Iteration 23, loss = 0.17122776\n",
      "Iteration 24, loss = 0.17140283\n",
      "Iteration 25, loss = 0.17109772\n",
      "Iteration 26, loss = 0.17128378\n",
      "Iteration 27, loss = 0.17103080\n",
      "Iteration 28, loss = 0.17091011\n",
      "Iteration 29, loss = 0.17099030\n",
      "Iteration 30, loss = 0.17095393\n",
      "Iteration 31, loss = 0.17089877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32, loss = 0.17073676\n",
      "Iteration 33, loss = 0.17091914\n",
      "Iteration 34, loss = 0.17076631\n",
      "Iteration 35, loss = 0.17086523\n",
      "Iteration 36, loss = 0.17062565\n",
      "Iteration 37, loss = 0.17079122\n",
      "Iteration 38, loss = 0.17097250\n",
      "Iteration 39, loss = 0.17081855\n",
      "Iteration 40, loss = 0.17068889\n",
      "Iteration 41, loss = 0.17082950\n",
      "Iteration 42, loss = 0.17089264\n",
      "Iteration 43, loss = 0.17087647\n",
      "Iteration 44, loss = 0.17059411\n",
      "Iteration 45, loss = 0.17064632\n",
      "Iteration 46, loss = 0.17070901\n",
      "Iteration 47, loss = 0.17070386\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.45239132\n",
      "Iteration 2, loss = 0.21041518\n",
      "Iteration 3, loss = 0.16315757\n",
      "Iteration 4, loss = 0.14804698\n",
      "Iteration 5, loss = 0.14160004\n",
      "Iteration 6, loss = 0.13854905\n",
      "Iteration 7, loss = 0.13667564\n",
      "Iteration 8, loss = 0.13508341\n",
      "Iteration 9, loss = 0.13386785\n",
      "Iteration 10, loss = 0.13272338\n",
      "Iteration 11, loss = 0.13176390\n",
      "Iteration 12, loss = 0.13088756\n",
      "Iteration 13, loss = 0.13034270\n",
      "Iteration 14, loss = 0.12937439\n",
      "Iteration 15, loss = 0.12857960\n",
      "Iteration 16, loss = 0.12812983\n",
      "Iteration 17, loss = 0.12704371\n",
      "Iteration 18, loss = 0.12642697\n",
      "Iteration 19, loss = 0.12568478\n",
      "Iteration 20, loss = 0.12497720\n",
      "Iteration 21, loss = 0.12439036\n",
      "Iteration 22, loss = 0.12391856\n",
      "Iteration 23, loss = 0.12316080\n",
      "Iteration 24, loss = 0.12250970\n",
      "Iteration 25, loss = 0.12216691\n",
      "Iteration 26, loss = 0.12166526\n",
      "Iteration 27, loss = 0.12129615\n",
      "Iteration 28, loss = 0.12073896\n",
      "Iteration 29, loss = 0.12041175\n",
      "Iteration 30, loss = 0.11987218\n",
      "Iteration 31, loss = 0.11952017\n",
      "Iteration 32, loss = 0.11926825\n",
      "Iteration 33, loss = 0.11900048\n",
      "Iteration 34, loss = 0.11848554\n",
      "Iteration 35, loss = 0.11835755\n",
      "Iteration 36, loss = 0.11791034\n",
      "Iteration 37, loss = 0.11752147\n",
      "Iteration 38, loss = 0.11715228\n",
      "Iteration 39, loss = 0.11667692\n",
      "Iteration 40, loss = 0.11665283\n",
      "Iteration 41, loss = 0.11649942\n",
      "Iteration 42, loss = 0.11606341\n",
      "Iteration 43, loss = 0.11578585\n",
      "Iteration 44, loss = 0.11569744\n",
      "Iteration 45, loss = 0.11543618\n",
      "Iteration 46, loss = 0.11523000\n",
      "Iteration 47, loss = 0.11503162\n",
      "Iteration 48, loss = 0.11468727\n",
      "Iteration 49, loss = 0.11465660\n",
      "Iteration 50, loss = 0.11462327\n",
      "Iteration 51, loss = 0.11413262\n",
      "Iteration 52, loss = 0.11384717\n",
      "Iteration 53, loss = 0.11361041\n",
      "Iteration 54, loss = 0.11367583\n",
      "Iteration 55, loss = 0.11332317\n",
      "Iteration 56, loss = 0.11320769\n",
      "Iteration 57, loss = 0.11318763\n",
      "Iteration 58, loss = 0.11273388\n",
      "Iteration 59, loss = 0.11250103\n",
      "Iteration 60, loss = 0.11264464\n",
      "Iteration 61, loss = 0.11249659\n",
      "Iteration 62, loss = 0.11203819\n",
      "Iteration 63, loss = 0.11201199\n",
      "Iteration 64, loss = 0.11181459\n",
      "Iteration 65, loss = 0.11153761\n",
      "Iteration 66, loss = 0.11158819\n",
      "Iteration 67, loss = 0.11135917\n",
      "Iteration 68, loss = 0.11111109\n",
      "Iteration 69, loss = 0.11115527\n",
      "Iteration 70, loss = 0.11075420\n",
      "Iteration 71, loss = 0.11068144\n",
      "Iteration 72, loss = 0.11023786\n",
      "Iteration 73, loss = 0.11024549\n",
      "Iteration 74, loss = 0.11000806\n",
      "Iteration 75, loss = 0.10971434\n",
      "Iteration 76, loss = 0.10963345\n",
      "Iteration 77, loss = 0.10918765\n",
      "Iteration 78, loss = 0.10934859\n",
      "Iteration 79, loss = 0.10904490\n",
      "Iteration 80, loss = 0.10911112\n",
      "Iteration 81, loss = 0.10858155\n",
      "Iteration 82, loss = 0.10851653\n",
      "Iteration 83, loss = 0.10832277\n",
      "Iteration 84, loss = 0.10840510\n",
      "Iteration 85, loss = 0.10775147\n",
      "Iteration 86, loss = 0.10821077\n",
      "Iteration 87, loss = 0.10793645\n",
      "Iteration 88, loss = 0.10776731\n",
      "Iteration 89, loss = 0.10763705\n",
      "Iteration 90, loss = 0.10728505\n",
      "Iteration 91, loss = 0.10729850\n",
      "Iteration 92, loss = 0.10714504\n",
      "Iteration 93, loss = 0.10714675\n",
      "Iteration 94, loss = 0.10708573\n",
      "Iteration 95, loss = 0.10678416\n",
      "Iteration 96, loss = 0.10670787\n",
      "Iteration 97, loss = 0.10666601\n",
      "Iteration 98, loss = 0.10631624\n",
      "Iteration 99, loss = 0.10659114\n",
      "Iteration 100, loss = 0.10643011\n",
      "Iteration 101, loss = 0.10610960\n",
      "Iteration 102, loss = 0.10602620\n",
      "Iteration 103, loss = 0.10595667\n",
      "Iteration 104, loss = 0.10580109\n",
      "Iteration 105, loss = 0.10565182\n",
      "Iteration 106, loss = 0.10549961\n",
      "Iteration 107, loss = 0.10533236\n",
      "Iteration 108, loss = 0.10536864\n",
      "Iteration 109, loss = 0.10535324\n",
      "Iteration 110, loss = 0.10527284\n",
      "Iteration 111, loss = 0.10520192\n",
      "Iteration 112, loss = 0.10506860\n",
      "Iteration 113, loss = 0.10491362\n",
      "Iteration 114, loss = 0.10488600\n",
      "Iteration 115, loss = 0.10494286\n",
      "Iteration 116, loss = 0.10485810\n",
      "Iteration 117, loss = 0.10453957\n",
      "Iteration 118, loss = 0.10437141\n",
      "Iteration 119, loss = 0.10432654\n",
      "Iteration 120, loss = 0.10461423\n",
      "Iteration 121, loss = 0.10426198\n",
      "Iteration 122, loss = 0.10441115\n",
      "Iteration 123, loss = 0.10413648\n",
      "Iteration 124, loss = 0.10405481\n",
      "Iteration 125, loss = 0.10417578\n",
      "Iteration 126, loss = 0.10397959\n",
      "Iteration 127, loss = 0.10403600\n",
      "Iteration 128, loss = 0.10403244\n",
      "Iteration 129, loss = 0.10378220\n",
      "Iteration 130, loss = 0.10374216\n",
      "Iteration 131, loss = 0.10362785\n",
      "Iteration 132, loss = 0.10339152\n",
      "Iteration 133, loss = 0.10366413\n",
      "Iteration 134, loss = 0.10345671\n",
      "Iteration 135, loss = 0.10326113\n",
      "Iteration 136, loss = 0.10335429\n",
      "Iteration 137, loss = 0.10336324\n",
      "Iteration 138, loss = 0.10337885\n",
      "Iteration 139, loss = 0.10305441\n",
      "Iteration 140, loss = 0.10321050\n",
      "Iteration 141, loss = 0.10294073\n",
      "Iteration 142, loss = 0.10331592\n",
      "Iteration 143, loss = 0.10302571\n",
      "Iteration 144, loss = 0.10285445\n",
      "Iteration 145, loss = 0.10275224\n",
      "Iteration 146, loss = 0.10274785\n",
      "Iteration 147, loss = 0.10269028\n",
      "Iteration 148, loss = 0.10237576\n",
      "Iteration 149, loss = 0.10246562\n",
      "Iteration 150, loss = 0.10257709\n",
      "Iteration 151, loss = 0.10237703\n",
      "Iteration 152, loss = 0.10242867\n",
      "Iteration 153, loss = 0.10231922\n",
      "Iteration 154, loss = 0.10231813\n",
      "Iteration 155, loss = 0.10213869\n",
      "Iteration 156, loss = 0.10225635\n",
      "Iteration 157, loss = 0.10204128\n",
      "Iteration 158, loss = 0.10245627\n",
      "Iteration 159, loss = 0.10207325\n",
      "Iteration 160, loss = 0.10213658\n",
      "Iteration 161, loss = 0.10197934\n",
      "Iteration 162, loss = 0.10176687\n",
      "Iteration 163, loss = 0.10189321\n",
      "Iteration 164, loss = 0.10206579\n",
      "Iteration 165, loss = 0.10184393\n",
      "Iteration 166, loss = 0.10164362\n",
      "Iteration 167, loss = 0.10176551\n",
      "Iteration 168, loss = 0.10173064\n",
      "Iteration 169, loss = 0.10168727\n",
      "Iteration 170, loss = 0.10170172\n",
      "Iteration 171, loss = 0.10151136\n",
      "Iteration 172, loss = 0.10135353\n",
      "Iteration 173, loss = 0.10147940\n",
      "Iteration 174, loss = 0.10141852\n",
      "Iteration 175, loss = 0.10126490\n",
      "Iteration 176, loss = 0.10123359\n",
      "Iteration 177, loss = 0.10141607\n",
      "Iteration 178, loss = 0.10130893\n",
      "Iteration 179, loss = 0.10114940\n",
      "Iteration 180, loss = 0.10077863\n",
      "Iteration 181, loss = 0.10109211\n",
      "Iteration 182, loss = 0.10093194\n",
      "Iteration 183, loss = 0.10096525\n",
      "Iteration 184, loss = 0.10102387\n",
      "Iteration 185, loss = 0.10094830\n",
      "Iteration 186, loss = 0.10079289\n",
      "Iteration 187, loss = 0.10055986\n",
      "Iteration 188, loss = 0.10093134\n",
      "Iteration 189, loss = 0.10055884\n",
      "Iteration 190, loss = 0.10057670\n",
      "Iteration 191, loss = 0.10066180\n",
      "Iteration 192, loss = 0.10061235\n",
      "Iteration 193, loss = 0.10038835\n",
      "Iteration 194, loss = 0.10064292\n",
      "Iteration 195, loss = 0.10054644\n",
      "Iteration 196, loss = 0.10063914\n",
      "Iteration 197, loss = 0.10047100\n",
      "Iteration 198, loss = 0.10058434\n",
      "Iteration 199, loss = 0.10020416\n",
      "Iteration 200, loss = 0.10029777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.45303735\n",
      "Iteration 2, loss = 0.22409716\n",
      "Iteration 3, loss = 0.17055718\n",
      "Iteration 4, loss = 0.15159673\n",
      "Iteration 5, loss = 0.14299066\n",
      "Iteration 6, loss = 0.13851904\n",
      "Iteration 7, loss = 0.13557239\n",
      "Iteration 8, loss = 0.13393690\n",
      "Iteration 9, loss = 0.13235923\n",
      "Iteration 10, loss = 0.13138904\n",
      "Iteration 11, loss = 0.13046654\n",
      "Iteration 12, loss = 0.12976987\n",
      "Iteration 13, loss = 0.12908267\n",
      "Iteration 14, loss = 0.12840553\n",
      "Iteration 15, loss = 0.12778100\n",
      "Iteration 16, loss = 0.12707128\n",
      "Iteration 17, loss = 0.12660295\n",
      "Iteration 18, loss = 0.12587652\n",
      "Iteration 19, loss = 0.12550025\n",
      "Iteration 20, loss = 0.12488876\n",
      "Iteration 21, loss = 0.12422215\n",
      "Iteration 22, loss = 0.12371674\n",
      "Iteration 23, loss = 0.12333871\n",
      "Iteration 24, loss = 0.12301810\n",
      "Iteration 25, loss = 0.12224313\n",
      "Iteration 26, loss = 0.12203821\n",
      "Iteration 27, loss = 0.12163388\n",
      "Iteration 28, loss = 0.12100431\n",
      "Iteration 29, loss = 0.12080910\n",
      "Iteration 30, loss = 0.12020362\n",
      "Iteration 31, loss = 0.11986989\n",
      "Iteration 32, loss = 0.11953985\n",
      "Iteration 33, loss = 0.11918864\n",
      "Iteration 34, loss = 0.11876046\n",
      "Iteration 35, loss = 0.11837186\n",
      "Iteration 36, loss = 0.11815098\n",
      "Iteration 37, loss = 0.11772228\n",
      "Iteration 38, loss = 0.11721038\n",
      "Iteration 39, loss = 0.11677148\n",
      "Iteration 40, loss = 0.11649163\n",
      "Iteration 41, loss = 0.11594246\n",
      "Iteration 42, loss = 0.11567307\n",
      "Iteration 43, loss = 0.11536985\n",
      "Iteration 44, loss = 0.11518129\n",
      "Iteration 45, loss = 0.11454160\n",
      "Iteration 46, loss = 0.11434946\n",
      "Iteration 47, loss = 0.11423493\n",
      "Iteration 48, loss = 0.11391921\n",
      "Iteration 49, loss = 0.11349634\n",
      "Iteration 50, loss = 0.11310901\n",
      "Iteration 51, loss = 0.11302874\n",
      "Iteration 52, loss = 0.11260350\n",
      "Iteration 53, loss = 0.11258591\n",
      "Iteration 54, loss = 0.11240503\n",
      "Iteration 55, loss = 0.11190219\n",
      "Iteration 56, loss = 0.11177131\n",
      "Iteration 57, loss = 0.11146730\n",
      "Iteration 58, loss = 0.11149074\n",
      "Iteration 59, loss = 0.11106202\n",
      "Iteration 60, loss = 0.11095763\n",
      "Iteration 61, loss = 0.11083009\n",
      "Iteration 62, loss = 0.11062838\n",
      "Iteration 63, loss = 0.11052234\n",
      "Iteration 64, loss = 0.11028015\n",
      "Iteration 65, loss = 0.10986737\n",
      "Iteration 66, loss = 0.10999995\n",
      "Iteration 67, loss = 0.10959099\n",
      "Iteration 68, loss = 0.10958686\n",
      "Iteration 69, loss = 0.10945718\n",
      "Iteration 70, loss = 0.10925744\n",
      "Iteration 71, loss = 0.10897434\n",
      "Iteration 72, loss = 0.10905200\n",
      "Iteration 73, loss = 0.10870633\n",
      "Iteration 74, loss = 0.10876917\n",
      "Iteration 75, loss = 0.10852835\n",
      "Iteration 76, loss = 0.10829841\n",
      "Iteration 77, loss = 0.10802424\n",
      "Iteration 78, loss = 0.10810088\n",
      "Iteration 79, loss = 0.10788438\n",
      "Iteration 80, loss = 0.10758150\n",
      "Iteration 81, loss = 0.10765790\n",
      "Iteration 82, loss = 0.10722405\n",
      "Iteration 83, loss = 0.10729782\n",
      "Iteration 84, loss = 0.10745990\n",
      "Iteration 85, loss = 0.10709781\n",
      "Iteration 86, loss = 0.10682029\n",
      "Iteration 87, loss = 0.10679445\n",
      "Iteration 88, loss = 0.10658244\n",
      "Iteration 89, loss = 0.10645029\n",
      "Iteration 90, loss = 0.10645563\n",
      "Iteration 91, loss = 0.10606924\n",
      "Iteration 92, loss = 0.10592756\n",
      "Iteration 93, loss = 0.10595091\n",
      "Iteration 94, loss = 0.10576454\n",
      "Iteration 95, loss = 0.10584165\n",
      "Iteration 96, loss = 0.10558792\n",
      "Iteration 97, loss = 0.10525905\n",
      "Iteration 98, loss = 0.10530307\n",
      "Iteration 99, loss = 0.10498703\n",
      "Iteration 100, loss = 0.10522491\n",
      "Iteration 101, loss = 0.10475573\n",
      "Iteration 102, loss = 0.10494342\n",
      "Iteration 103, loss = 0.10451347\n",
      "Iteration 104, loss = 0.10458118\n",
      "Iteration 105, loss = 0.10432224\n",
      "Iteration 106, loss = 0.10433416\n",
      "Iteration 107, loss = 0.10419173\n",
      "Iteration 108, loss = 0.10388468\n",
      "Iteration 109, loss = 0.10388005\n",
      "Iteration 110, loss = 0.10370944\n",
      "Iteration 111, loss = 0.10361655\n",
      "Iteration 112, loss = 0.10364828\n",
      "Iteration 113, loss = 0.10363766\n",
      "Iteration 114, loss = 0.10354977\n",
      "Iteration 115, loss = 0.10331121\n",
      "Iteration 116, loss = 0.10334844\n",
      "Iteration 117, loss = 0.10303943\n",
      "Iteration 118, loss = 0.10316877\n",
      "Iteration 119, loss = 0.10262916\n",
      "Iteration 120, loss = 0.10290540\n",
      "Iteration 121, loss = 0.10252674\n",
      "Iteration 122, loss = 0.10269582\n",
      "Iteration 123, loss = 0.10229994\n",
      "Iteration 124, loss = 0.10244703\n",
      "Iteration 125, loss = 0.10227708\n",
      "Iteration 126, loss = 0.10228083\n",
      "Iteration 127, loss = 0.10220639\n",
      "Iteration 128, loss = 0.10196848\n",
      "Iteration 129, loss = 0.10179430\n",
      "Iteration 130, loss = 0.10190327\n",
      "Iteration 131, loss = 0.10152294\n",
      "Iteration 132, loss = 0.10159714\n",
      "Iteration 133, loss = 0.10167234\n",
      "Iteration 134, loss = 0.10154854\n",
      "Iteration 135, loss = 0.10132961\n",
      "Iteration 136, loss = 0.10143057\n",
      "Iteration 137, loss = 0.10123883\n",
      "Iteration 138, loss = 0.10120628\n",
      "Iteration 139, loss = 0.10114409\n",
      "Iteration 140, loss = 0.10101783\n",
      "Iteration 141, loss = 0.10077381\n",
      "Iteration 142, loss = 0.10092936\n",
      "Iteration 143, loss = 0.10089321\n",
      "Iteration 144, loss = 0.10080242\n",
      "Iteration 145, loss = 0.10116829\n",
      "Iteration 146, loss = 0.10047932\n",
      "Iteration 147, loss = 0.10042198\n",
      "Iteration 148, loss = 0.10054865\n",
      "Iteration 149, loss = 0.10050100\n",
      "Iteration 150, loss = 0.10026970\n",
      "Iteration 151, loss = 0.10012659\n",
      "Iteration 152, loss = 0.10016587\n",
      "Iteration 153, loss = 0.09992043\n",
      "Iteration 154, loss = 0.09989987\n",
      "Iteration 155, loss = 0.09990245\n",
      "Iteration 156, loss = 0.09985446\n",
      "Iteration 157, loss = 0.09995935\n",
      "Iteration 158, loss = 0.09977752\n",
      "Iteration 159, loss = 0.09993402\n",
      "Iteration 160, loss = 0.09991489\n",
      "Iteration 161, loss = 0.09959234\n",
      "Iteration 162, loss = 0.09969096\n",
      "Iteration 163, loss = 0.09950716\n",
      "Iteration 164, loss = 0.09952345\n",
      "Iteration 165, loss = 0.09926768\n",
      "Iteration 166, loss = 0.09930402\n",
      "Iteration 167, loss = 0.09942960\n",
      "Iteration 168, loss = 0.09916026\n",
      "Iteration 169, loss = 0.09912187\n",
      "Iteration 170, loss = 0.09905539\n",
      "Iteration 171, loss = 0.09904889\n",
      "Iteration 172, loss = 0.09888804\n",
      "Iteration 173, loss = 0.09876524\n",
      "Iteration 174, loss = 0.09915790\n",
      "Iteration 175, loss = 0.09859761\n",
      "Iteration 176, loss = 0.09877652\n",
      "Iteration 177, loss = 0.09863123\n",
      "Iteration 178, loss = 0.09873146\n",
      "Iteration 179, loss = 0.09850955\n",
      "Iteration 180, loss = 0.09845004\n",
      "Iteration 181, loss = 0.09837028\n",
      "Iteration 182, loss = 0.09834573\n",
      "Iteration 183, loss = 0.09829960\n",
      "Iteration 184, loss = 0.09827295\n",
      "Iteration 185, loss = 0.09830063\n",
      "Iteration 186, loss = 0.09819950\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.46244064\n",
      "Iteration 2, loss = 0.23624624\n",
      "Iteration 3, loss = 0.17599970\n",
      "Iteration 4, loss = 0.15383302\n",
      "Iteration 5, loss = 0.14478862\n",
      "Iteration 6, loss = 0.14003138\n",
      "Iteration 7, loss = 0.13760249\n",
      "Iteration 8, loss = 0.13592524\n",
      "Iteration 9, loss = 0.13475561\n",
      "Iteration 10, loss = 0.13402161\n",
      "Iteration 11, loss = 0.13309694\n",
      "Iteration 12, loss = 0.13260472\n",
      "Iteration 13, loss = 0.13174377\n",
      "Iteration 14, loss = 0.13116559\n",
      "Iteration 15, loss = 0.13061309\n",
      "Iteration 16, loss = 0.12998263\n",
      "Iteration 17, loss = 0.12956123\n",
      "Iteration 18, loss = 0.12904659\n",
      "Iteration 19, loss = 0.12842473\n",
      "Iteration 20, loss = 0.12795052\n",
      "Iteration 21, loss = 0.12745966\n",
      "Iteration 22, loss = 0.12679611\n",
      "Iteration 23, loss = 0.12636024\n",
      "Iteration 24, loss = 0.12577683\n",
      "Iteration 25, loss = 0.12520221\n",
      "Iteration 26, loss = 0.12475909\n",
      "Iteration 27, loss = 0.12414574\n",
      "Iteration 28, loss = 0.12346523\n",
      "Iteration 29, loss = 0.12294087\n",
      "Iteration 30, loss = 0.12252687\n",
      "Iteration 31, loss = 0.12169106\n",
      "Iteration 32, loss = 0.12129555\n",
      "Iteration 33, loss = 0.12062765\n",
      "Iteration 34, loss = 0.12006557\n",
      "Iteration 35, loss = 0.11975590\n",
      "Iteration 36, loss = 0.11936451\n",
      "Iteration 37, loss = 0.11907546\n",
      "Iteration 38, loss = 0.11844992\n",
      "Iteration 39, loss = 0.11826526\n",
      "Iteration 40, loss = 0.11774614\n",
      "Iteration 41, loss = 0.11749023\n",
      "Iteration 42, loss = 0.11724587\n",
      "Iteration 43, loss = 0.11677542\n",
      "Iteration 44, loss = 0.11654157\n",
      "Iteration 45, loss = 0.11633599\n",
      "Iteration 46, loss = 0.11628018\n",
      "Iteration 47, loss = 0.11581297\n",
      "Iteration 48, loss = 0.11558462\n",
      "Iteration 49, loss = 0.11562408\n",
      "Iteration 50, loss = 0.11513674\n",
      "Iteration 51, loss = 0.11493094\n",
      "Iteration 52, loss = 0.11487319\n",
      "Iteration 53, loss = 0.11454217\n",
      "Iteration 54, loss = 0.11443377\n",
      "Iteration 55, loss = 0.11429375\n",
      "Iteration 56, loss = 0.11407023\n",
      "Iteration 57, loss = 0.11402899\n",
      "Iteration 58, loss = 0.11372123\n",
      "Iteration 59, loss = 0.11367137\n",
      "Iteration 60, loss = 0.11348467\n",
      "Iteration 61, loss = 0.11331192\n",
      "Iteration 62, loss = 0.11335478\n",
      "Iteration 63, loss = 0.11301227\n",
      "Iteration 64, loss = 0.11288772\n",
      "Iteration 65, loss = 0.11292672\n",
      "Iteration 66, loss = 0.11255753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 67, loss = 0.11248912\n",
      "Iteration 68, loss = 0.11243862\n",
      "Iteration 69, loss = 0.11239758\n",
      "Iteration 70, loss = 0.11231258\n",
      "Iteration 71, loss = 0.11214003\n",
      "Iteration 72, loss = 0.11207819\n",
      "Iteration 73, loss = 0.11188670\n",
      "Iteration 74, loss = 0.11162668\n",
      "Iteration 75, loss = 0.11181713\n",
      "Iteration 76, loss = 0.11168795\n",
      "Iteration 77, loss = 0.11149584\n",
      "Iteration 78, loss = 0.11129316\n",
      "Iteration 79, loss = 0.11133163\n",
      "Iteration 80, loss = 0.11129946\n",
      "Iteration 81, loss = 0.11096568\n",
      "Iteration 82, loss = 0.11081829\n",
      "Iteration 83, loss = 0.11087679\n",
      "Iteration 84, loss = 0.11076413\n",
      "Iteration 85, loss = 0.11061028\n",
      "Iteration 86, loss = 0.11039676\n",
      "Iteration 87, loss = 0.11031885\n",
      "Iteration 88, loss = 0.11027457\n",
      "Iteration 89, loss = 0.11021639\n",
      "Iteration 90, loss = 0.11002455\n",
      "Iteration 91, loss = 0.10996126\n",
      "Iteration 92, loss = 0.10998640\n",
      "Iteration 93, loss = 0.10974135\n",
      "Iteration 94, loss = 0.10961437\n",
      "Iteration 95, loss = 0.10965513\n",
      "Iteration 96, loss = 0.10943627\n",
      "Iteration 97, loss = 0.10937105\n",
      "Iteration 98, loss = 0.10934635\n",
      "Iteration 99, loss = 0.10892614\n",
      "Iteration 100, loss = 0.10901509\n",
      "Iteration 101, loss = 0.10892316\n",
      "Iteration 102, loss = 0.10907969\n",
      "Iteration 103, loss = 0.10880476\n",
      "Iteration 104, loss = 0.10862083\n",
      "Iteration 105, loss = 0.10854097\n",
      "Iteration 106, loss = 0.10857673\n",
      "Iteration 107, loss = 0.10854817\n",
      "Iteration 108, loss = 0.10871885\n",
      "Iteration 109, loss = 0.10855593\n",
      "Iteration 110, loss = 0.10813294\n",
      "Iteration 111, loss = 0.10817539\n",
      "Iteration 112, loss = 0.10818054\n",
      "Iteration 113, loss = 0.10789695\n",
      "Iteration 114, loss = 0.10776027\n",
      "Iteration 115, loss = 0.10765820\n",
      "Iteration 116, loss = 0.10773542\n",
      "Iteration 117, loss = 0.10761605\n",
      "Iteration 118, loss = 0.10749551\n",
      "Iteration 119, loss = 0.10744930\n",
      "Iteration 120, loss = 0.10734068\n",
      "Iteration 121, loss = 0.10721996\n",
      "Iteration 122, loss = 0.10719168\n",
      "Iteration 123, loss = 0.10687554\n",
      "Iteration 124, loss = 0.10695850\n",
      "Iteration 125, loss = 0.10682220\n",
      "Iteration 126, loss = 0.10683051\n",
      "Iteration 127, loss = 0.10664957\n",
      "Iteration 128, loss = 0.10668020\n",
      "Iteration 129, loss = 0.10649983\n",
      "Iteration 130, loss = 0.10675310\n",
      "Iteration 131, loss = 0.10667631\n",
      "Iteration 132, loss = 0.10643353\n",
      "Iteration 133, loss = 0.10630665\n",
      "Iteration 134, loss = 0.10633915\n",
      "Iteration 135, loss = 0.10625337\n",
      "Iteration 136, loss = 0.10615288\n",
      "Iteration 137, loss = 0.10597698\n",
      "Iteration 138, loss = 0.10571099\n",
      "Iteration 139, loss = 0.10586577\n",
      "Iteration 140, loss = 0.10570604\n",
      "Iteration 141, loss = 0.10603140\n",
      "Iteration 142, loss = 0.10566629\n",
      "Iteration 143, loss = 0.10581993\n",
      "Iteration 144, loss = 0.10553304\n",
      "Iteration 145, loss = 0.10539384\n",
      "Iteration 146, loss = 0.10549842\n",
      "Iteration 147, loss = 0.10549867\n",
      "Iteration 148, loss = 0.10538410\n",
      "Iteration 149, loss = 0.10540501\n",
      "Iteration 150, loss = 0.10532048\n",
      "Iteration 151, loss = 0.10512512\n",
      "Iteration 152, loss = 0.10506729\n",
      "Iteration 153, loss = 0.10503053\n",
      "Iteration 154, loss = 0.10513541\n",
      "Iteration 155, loss = 0.10507737\n",
      "Iteration 156, loss = 0.10512437\n",
      "Iteration 157, loss = 0.10518758\n",
      "Iteration 158, loss = 0.10476591\n",
      "Iteration 159, loss = 0.10473654\n",
      "Iteration 160, loss = 0.10462544\n",
      "Iteration 161, loss = 0.10478130\n",
      "Iteration 162, loss = 0.10435856\n",
      "Iteration 163, loss = 0.10453383\n",
      "Iteration 164, loss = 0.10455131\n",
      "Iteration 165, loss = 0.10427232\n",
      "Iteration 166, loss = 0.10448165\n",
      "Iteration 167, loss = 0.10419401\n",
      "Iteration 168, loss = 0.10430892\n",
      "Iteration 169, loss = 0.10412000\n",
      "Iteration 170, loss = 0.10407511\n",
      "Iteration 171, loss = 0.10426653\n",
      "Iteration 172, loss = 0.10391513\n",
      "Iteration 173, loss = 0.10393063\n",
      "Iteration 174, loss = 0.10385991\n",
      "Iteration 175, loss = 0.10375326\n",
      "Iteration 176, loss = 0.10376748\n",
      "Iteration 177, loss = 0.10372386\n",
      "Iteration 178, loss = 0.10323293\n",
      "Iteration 179, loss = 0.10365517\n",
      "Iteration 180, loss = 0.10344535\n",
      "Iteration 181, loss = 0.10330611\n",
      "Iteration 182, loss = 0.10307107\n",
      "Iteration 183, loss = 0.10331109\n",
      "Iteration 184, loss = 0.10325819\n",
      "Iteration 185, loss = 0.10337013\n",
      "Iteration 186, loss = 0.10319684\n",
      "Iteration 187, loss = 0.10294198\n",
      "Iteration 188, loss = 0.10312473\n",
      "Iteration 189, loss = 0.10297960\n",
      "Iteration 190, loss = 0.10308230\n",
      "Iteration 191, loss = 0.10305195\n",
      "Iteration 192, loss = 0.10268578\n",
      "Iteration 193, loss = 0.10263720\n",
      "Iteration 194, loss = 0.10279085\n",
      "Iteration 195, loss = 0.10246001\n",
      "Iteration 196, loss = 0.10259164\n",
      "Iteration 197, loss = 0.10272068\n",
      "Iteration 198, loss = 0.10248477\n",
      "Iteration 199, loss = 0.10280960\n",
      "Iteration 200, loss = 0.10228165\n",
      "Iteration 1, loss = 0.42196646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.21312288\n",
      "Iteration 3, loss = 0.16471515\n",
      "Iteration 4, loss = 0.14919099\n",
      "Iteration 5, loss = 0.14234791\n",
      "Iteration 6, loss = 0.13877903\n",
      "Iteration 7, loss = 0.13675291\n",
      "Iteration 8, loss = 0.13523352\n",
      "Iteration 9, loss = 0.13404882\n",
      "Iteration 10, loss = 0.13334138\n",
      "Iteration 11, loss = 0.13240239\n",
      "Iteration 12, loss = 0.13147517\n",
      "Iteration 13, loss = 0.13103513\n",
      "Iteration 14, loss = 0.13032362\n",
      "Iteration 15, loss = 0.12948403\n",
      "Iteration 16, loss = 0.12905410\n",
      "Iteration 17, loss = 0.12832110\n",
      "Iteration 18, loss = 0.12780589\n",
      "Iteration 19, loss = 0.12720819\n",
      "Iteration 20, loss = 0.12672311\n",
      "Iteration 21, loss = 0.12611176\n",
      "Iteration 22, loss = 0.12557959\n",
      "Iteration 23, loss = 0.12522398\n",
      "Iteration 24, loss = 0.12473524\n",
      "Iteration 25, loss = 0.12432284\n",
      "Iteration 26, loss = 0.12393449\n",
      "Iteration 27, loss = 0.12373290\n",
      "Iteration 28, loss = 0.12299406\n",
      "Iteration 29, loss = 0.12266861\n",
      "Iteration 30, loss = 0.12233833\n",
      "Iteration 31, loss = 0.12187604\n",
      "Iteration 32, loss = 0.12157841\n",
      "Iteration 33, loss = 0.12116303\n",
      "Iteration 34, loss = 0.12063007\n",
      "Iteration 35, loss = 0.12029726\n",
      "Iteration 36, loss = 0.12007368\n",
      "Iteration 37, loss = 0.11983588\n",
      "Iteration 38, loss = 0.11944953\n",
      "Iteration 39, loss = 0.11907928\n",
      "Iteration 40, loss = 0.11863243\n",
      "Iteration 41, loss = 0.11858530\n",
      "Iteration 42, loss = 0.11811696\n",
      "Iteration 43, loss = 0.11793371\n",
      "Iteration 44, loss = 0.11757783\n",
      "Iteration 45, loss = 0.11733497\n",
      "Iteration 46, loss = 0.11697442\n",
      "Iteration 47, loss = 0.11680363\n",
      "Iteration 48, loss = 0.11626723\n",
      "Iteration 49, loss = 0.11604055\n",
      "Iteration 50, loss = 0.11589026\n",
      "Iteration 51, loss = 0.11556607\n",
      "Iteration 52, loss = 0.11537239\n",
      "Iteration 53, loss = 0.11508641\n",
      "Iteration 54, loss = 0.11490682\n",
      "Iteration 55, loss = 0.11489209\n",
      "Iteration 56, loss = 0.11462098\n",
      "Iteration 57, loss = 0.11421640\n",
      "Iteration 58, loss = 0.11396531\n",
      "Iteration 59, loss = 0.11355439\n",
      "Iteration 60, loss = 0.11338621\n",
      "Iteration 61, loss = 0.11320354\n",
      "Iteration 62, loss = 0.11308636\n",
      "Iteration 63, loss = 0.11273223\n",
      "Iteration 64, loss = 0.11266475\n",
      "Iteration 65, loss = 0.11254898\n",
      "Iteration 66, loss = 0.11278839\n",
      "Iteration 67, loss = 0.11214912\n",
      "Iteration 68, loss = 0.11189024\n",
      "Iteration 69, loss = 0.11174622\n",
      "Iteration 70, loss = 0.11166026\n",
      "Iteration 71, loss = 0.11135738\n",
      "Iteration 72, loss = 0.11146284\n",
      "Iteration 73, loss = 0.11129989\n",
      "Iteration 74, loss = 0.11116282\n",
      "Iteration 75, loss = 0.11091363\n",
      "Iteration 76, loss = 0.11069984\n",
      "Iteration 77, loss = 0.11068355\n",
      "Iteration 78, loss = 0.11028766\n",
      "Iteration 79, loss = 0.11013273\n",
      "Iteration 80, loss = 0.11020889\n",
      "Iteration 81, loss = 0.10991237\n",
      "Iteration 82, loss = 0.11005452\n",
      "Iteration 83, loss = 0.10957304\n",
      "Iteration 84, loss = 0.10952596\n",
      "Iteration 85, loss = 0.10946841\n",
      "Iteration 86, loss = 0.10944258\n",
      "Iteration 87, loss = 0.10911258\n",
      "Iteration 88, loss = 0.10899533\n",
      "Iteration 89, loss = 0.10899505\n",
      "Iteration 90, loss = 0.10858461\n",
      "Iteration 91, loss = 0.10847602\n",
      "Iteration 92, loss = 0.10856433\n",
      "Iteration 93, loss = 0.10822724\n",
      "Iteration 94, loss = 0.10815280\n",
      "Iteration 95, loss = 0.10806648\n",
      "Iteration 96, loss = 0.10780520\n",
      "Iteration 97, loss = 0.10791658\n",
      "Iteration 98, loss = 0.10783520\n",
      "Iteration 99, loss = 0.10761868\n",
      "Iteration 100, loss = 0.10748666\n",
      "Iteration 101, loss = 0.10725840\n",
      "Iteration 102, loss = 0.10738272\n",
      "Iteration 103, loss = 0.10727515\n",
      "Iteration 104, loss = 0.10698461\n",
      "Iteration 105, loss = 0.10697018\n",
      "Iteration 106, loss = 0.10689754\n",
      "Iteration 107, loss = 0.10666044\n",
      "Iteration 108, loss = 0.10665304\n",
      "Iteration 109, loss = 0.10694658\n",
      "Iteration 110, loss = 0.10676305\n",
      "Iteration 111, loss = 0.10641750\n",
      "Iteration 112, loss = 0.10622164\n",
      "Iteration 113, loss = 0.10607433\n",
      "Iteration 114, loss = 0.10595566\n",
      "Iteration 115, loss = 0.10631334\n",
      "Iteration 116, loss = 0.10598284\n",
      "Iteration 117, loss = 0.10587321\n",
      "Iteration 118, loss = 0.10595414\n",
      "Iteration 119, loss = 0.10583577\n",
      "Iteration 120, loss = 0.10555503\n",
      "Iteration 121, loss = 0.10557790\n",
      "Iteration 122, loss = 0.10539536\n",
      "Iteration 123, loss = 0.10539213\n",
      "Iteration 124, loss = 0.10517162\n",
      "Iteration 125, loss = 0.10517536\n",
      "Iteration 126, loss = 0.10501078\n",
      "Iteration 127, loss = 0.10513014\n",
      "Iteration 128, loss = 0.10507101\n",
      "Iteration 129, loss = 0.10491737\n",
      "Iteration 130, loss = 0.10482877\n",
      "Iteration 131, loss = 0.10475807\n",
      "Iteration 132, loss = 0.10502737\n",
      "Iteration 133, loss = 0.10484439\n",
      "Iteration 134, loss = 0.10458835\n",
      "Iteration 135, loss = 0.10472542\n",
      "Iteration 136, loss = 0.10457415\n",
      "Iteration 137, loss = 0.10449110\n",
      "Iteration 138, loss = 0.10451262\n",
      "Iteration 139, loss = 0.10435134\n",
      "Iteration 140, loss = 0.10430416\n",
      "Iteration 141, loss = 0.10421499\n",
      "Iteration 142, loss = 0.10401414\n",
      "Iteration 143, loss = 0.10398833\n",
      "Iteration 144, loss = 0.10450025\n",
      "Iteration 145, loss = 0.10412567\n",
      "Iteration 146, loss = 0.10382053\n",
      "Iteration 147, loss = 0.10382103\n",
      "Iteration 148, loss = 0.10369404\n",
      "Iteration 149, loss = 0.10393845\n",
      "Iteration 150, loss = 0.10366226\n",
      "Iteration 151, loss = 0.10371699\n",
      "Iteration 152, loss = 0.10349966\n",
      "Iteration 153, loss = 0.10338177\n",
      "Iteration 154, loss = 0.10352413\n",
      "Iteration 155, loss = 0.10336111\n",
      "Iteration 156, loss = 0.10320195\n",
      "Iteration 157, loss = 0.10338161\n",
      "Iteration 158, loss = 0.10320474\n",
      "Iteration 159, loss = 0.10357737\n",
      "Iteration 160, loss = 0.10312283\n",
      "Iteration 161, loss = 0.10299419\n",
      "Iteration 162, loss = 0.10280436\n",
      "Iteration 163, loss = 0.10283343\n",
      "Iteration 164, loss = 0.10285996\n",
      "Iteration 165, loss = 0.10273271\n",
      "Iteration 166, loss = 0.10288045\n",
      "Iteration 167, loss = 0.10280680\n",
      "Iteration 168, loss = 0.10235987\n",
      "Iteration 169, loss = 0.10286263\n",
      "Iteration 170, loss = 0.10248092\n",
      "Iteration 171, loss = 0.10244885\n",
      "Iteration 172, loss = 0.10252198\n",
      "Iteration 173, loss = 0.10214534\n",
      "Iteration 174, loss = 0.10234246\n",
      "Iteration 175, loss = 0.10243345\n",
      "Iteration 176, loss = 0.10200791\n",
      "Iteration 177, loss = 0.10240648\n",
      "Iteration 178, loss = 0.10227031\n",
      "Iteration 179, loss = 0.10198172\n",
      "Iteration 180, loss = 0.10213241\n",
      "Iteration 181, loss = 0.10201829\n",
      "Iteration 182, loss = 0.10179039\n",
      "Iteration 183, loss = 0.10178927\n",
      "Iteration 184, loss = 0.10185187\n",
      "Iteration 185, loss = 0.10159561\n",
      "Iteration 186, loss = 0.10167553\n",
      "Iteration 187, loss = 0.10177737\n",
      "Iteration 188, loss = 0.10139120\n",
      "Iteration 189, loss = 0.10167175\n",
      "Iteration 190, loss = 0.10164602\n",
      "Iteration 191, loss = 0.10148718\n",
      "Iteration 192, loss = 0.10130056\n",
      "Iteration 193, loss = 0.10157973\n",
      "Iteration 194, loss = 0.10121594\n",
      "Iteration 195, loss = 0.10118974\n",
      "Iteration 196, loss = 0.10122295\n",
      "Iteration 197, loss = 0.10104119\n",
      "Iteration 198, loss = 0.10117780\n",
      "Iteration 199, loss = 0.10091224\n",
      "Iteration 200, loss = 0.10093428\n",
      "Iteration 1, loss = 0.41299038\n",
      "Iteration 2, loss = 0.21677166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.16907234\n",
      "Iteration 4, loss = 0.15103861\n",
      "Iteration 5, loss = 0.14251692\n",
      "Iteration 6, loss = 0.13757045\n",
      "Iteration 7, loss = 0.13445143\n",
      "Iteration 8, loss = 0.13238792\n",
      "Iteration 9, loss = 0.13067777\n",
      "Iteration 10, loss = 0.12931278\n",
      "Iteration 11, loss = 0.12820877\n",
      "Iteration 12, loss = 0.12737787\n",
      "Iteration 13, loss = 0.12635235\n",
      "Iteration 14, loss = 0.12575872\n",
      "Iteration 15, loss = 0.12493695\n",
      "Iteration 16, loss = 0.12425787\n",
      "Iteration 17, loss = 0.12356554\n",
      "Iteration 18, loss = 0.12305168\n",
      "Iteration 19, loss = 0.12244016\n",
      "Iteration 20, loss = 0.12179726\n",
      "Iteration 21, loss = 0.12144891\n",
      "Iteration 22, loss = 0.12083588\n",
      "Iteration 23, loss = 0.12022949\n",
      "Iteration 24, loss = 0.11965735\n",
      "Iteration 25, loss = 0.11934519\n",
      "Iteration 26, loss = 0.11910494\n",
      "Iteration 27, loss = 0.11862690\n",
      "Iteration 28, loss = 0.11813589\n",
      "Iteration 29, loss = 0.11771117\n",
      "Iteration 30, loss = 0.11737759\n",
      "Iteration 31, loss = 0.11692505\n",
      "Iteration 32, loss = 0.11663399\n",
      "Iteration 33, loss = 0.11623348\n",
      "Iteration 34, loss = 0.11585178\n",
      "Iteration 35, loss = 0.11561240\n",
      "Iteration 36, loss = 0.11533758\n",
      "Iteration 37, loss = 0.11502246\n",
      "Iteration 38, loss = 0.11465825\n",
      "Iteration 39, loss = 0.11475389\n",
      "Iteration 40, loss = 0.11422466\n",
      "Iteration 41, loss = 0.11397024\n",
      "Iteration 42, loss = 0.11389219\n",
      "Iteration 43, loss = 0.11351095\n",
      "Iteration 44, loss = 0.11331985\n",
      "Iteration 45, loss = 0.11308287\n",
      "Iteration 46, loss = 0.11286717\n",
      "Iteration 47, loss = 0.11268311\n",
      "Iteration 48, loss = 0.11253944\n",
      "Iteration 49, loss = 0.11256510\n",
      "Iteration 50, loss = 0.11255905\n",
      "Iteration 51, loss = 0.11198445\n",
      "Iteration 52, loss = 0.11206138\n",
      "Iteration 53, loss = 0.11166090\n",
      "Iteration 54, loss = 0.11159442\n",
      "Iteration 55, loss = 0.11162803\n",
      "Iteration 56, loss = 0.11122423\n",
      "Iteration 57, loss = 0.11122050\n",
      "Iteration 58, loss = 0.11106939\n",
      "Iteration 59, loss = 0.11088639\n",
      "Iteration 60, loss = 0.11078200\n",
      "Iteration 61, loss = 0.11084431\n",
      "Iteration 62, loss = 0.11068124\n",
      "Iteration 63, loss = 0.11053374\n",
      "Iteration 64, loss = 0.11039040\n",
      "Iteration 65, loss = 0.11043398\n",
      "Iteration 66, loss = 0.11011865\n",
      "Iteration 67, loss = 0.10994737\n",
      "Iteration 68, loss = 0.10982692\n",
      "Iteration 69, loss = 0.11013784\n",
      "Iteration 70, loss = 0.11000112\n",
      "Iteration 71, loss = 0.10981740\n",
      "Iteration 72, loss = 0.10945858\n",
      "Iteration 73, loss = 0.10959177\n",
      "Iteration 74, loss = 0.10953625\n",
      "Iteration 75, loss = 0.10927085\n",
      "Iteration 76, loss = 0.10908988\n",
      "Iteration 77, loss = 0.10913753\n",
      "Iteration 78, loss = 0.10911576\n",
      "Iteration 79, loss = 0.10913876\n",
      "Iteration 80, loss = 0.10885507\n",
      "Iteration 81, loss = 0.10875854\n",
      "Iteration 82, loss = 0.10867849\n",
      "Iteration 83, loss = 0.10858604\n",
      "Iteration 84, loss = 0.10838989\n",
      "Iteration 85, loss = 0.10870590\n",
      "Iteration 86, loss = 0.10838932\n",
      "Iteration 87, loss = 0.10849757\n",
      "Iteration 88, loss = 0.10803912\n",
      "Iteration 89, loss = 0.10798477\n",
      "Iteration 90, loss = 0.10799543\n",
      "Iteration 91, loss = 0.10758952\n",
      "Iteration 92, loss = 0.10769185\n",
      "Iteration 93, loss = 0.10771553\n",
      "Iteration 94, loss = 0.10755658\n",
      "Iteration 95, loss = 0.10770617\n",
      "Iteration 96, loss = 0.10755648\n",
      "Iteration 97, loss = 0.10736920\n",
      "Iteration 98, loss = 0.10726659\n",
      "Iteration 99, loss = 0.10714126\n",
      "Iteration 100, loss = 0.10719836\n",
      "Iteration 101, loss = 0.10711813\n",
      "Iteration 102, loss = 0.10695764\n",
      "Iteration 103, loss = 0.10680207\n",
      "Iteration 104, loss = 0.10659438\n",
      "Iteration 105, loss = 0.10668438\n",
      "Iteration 106, loss = 0.10664517\n",
      "Iteration 107, loss = 0.10664943\n",
      "Iteration 108, loss = 0.10635237\n",
      "Iteration 109, loss = 0.10630754\n",
      "Iteration 110, loss = 0.10610623\n",
      "Iteration 111, loss = 0.10611956\n",
      "Iteration 112, loss = 0.10621894\n",
      "Iteration 113, loss = 0.10614642\n",
      "Iteration 114, loss = 0.10601996\n",
      "Iteration 115, loss = 0.10584651\n",
      "Iteration 116, loss = 0.10565639\n",
      "Iteration 117, loss = 0.10584557\n",
      "Iteration 118, loss = 0.10562176\n",
      "Iteration 119, loss = 0.10559788\n",
      "Iteration 120, loss = 0.10532744\n",
      "Iteration 121, loss = 0.10526254\n",
      "Iteration 122, loss = 0.10521541\n",
      "Iteration 123, loss = 0.10527689\n",
      "Iteration 124, loss = 0.10518025\n",
      "Iteration 125, loss = 0.10489942\n",
      "Iteration 126, loss = 0.10481738\n",
      "Iteration 127, loss = 0.10499112\n",
      "Iteration 128, loss = 0.10488221\n",
      "Iteration 129, loss = 0.10443129\n",
      "Iteration 130, loss = 0.10463379\n",
      "Iteration 131, loss = 0.10439823\n",
      "Iteration 132, loss = 0.10417633\n",
      "Iteration 133, loss = 0.10403075\n",
      "Iteration 134, loss = 0.10398695\n",
      "Iteration 135, loss = 0.10408910\n",
      "Iteration 136, loss = 0.10397948\n",
      "Iteration 137, loss = 0.10397025\n",
      "Iteration 138, loss = 0.10382189\n",
      "Iteration 139, loss = 0.10351616\n",
      "Iteration 140, loss = 0.10350292\n",
      "Iteration 141, loss = 0.10345310\n",
      "Iteration 142, loss = 0.10346505\n",
      "Iteration 143, loss = 0.10322134\n",
      "Iteration 144, loss = 0.10341835\n",
      "Iteration 145, loss = 0.10333134\n",
      "Iteration 146, loss = 0.10316256\n",
      "Iteration 147, loss = 0.10302996\n",
      "Iteration 148, loss = 0.10321319\n",
      "Iteration 149, loss = 0.10307482\n",
      "Iteration 150, loss = 0.10264926\n",
      "Iteration 151, loss = 0.10281871\n",
      "Iteration 152, loss = 0.10288514\n",
      "Iteration 153, loss = 0.10263348\n",
      "Iteration 154, loss = 0.10250332\n",
      "Iteration 155, loss = 0.10257524\n",
      "Iteration 156, loss = 0.10248889\n",
      "Iteration 157, loss = 0.10227706\n",
      "Iteration 158, loss = 0.10227029\n",
      "Iteration 159, loss = 0.10224903\n",
      "Iteration 160, loss = 0.10219998\n",
      "Iteration 161, loss = 0.10185669\n",
      "Iteration 162, loss = 0.10186439\n",
      "Iteration 163, loss = 0.10178724\n",
      "Iteration 164, loss = 0.10148646\n",
      "Iteration 165, loss = 0.10135507\n",
      "Iteration 166, loss = 0.10133530\n",
      "Iteration 167, loss = 0.10138623\n",
      "Iteration 168, loss = 0.10142655\n",
      "Iteration 169, loss = 0.10108426\n",
      "Iteration 170, loss = 0.10142780\n",
      "Iteration 171, loss = 0.10107428\n",
      "Iteration 172, loss = 0.10100339\n",
      "Iteration 173, loss = 0.10103407\n",
      "Iteration 174, loss = 0.10076776\n",
      "Iteration 175, loss = 0.10071441\n",
      "Iteration 176, loss = 0.10091143\n",
      "Iteration 177, loss = 0.10085789\n",
      "Iteration 178, loss = 0.10102736\n",
      "Iteration 179, loss = 0.10072781\n",
      "Iteration 180, loss = 0.10040201\n",
      "Iteration 181, loss = 0.10012973\n",
      "Iteration 182, loss = 0.10058757\n",
      "Iteration 183, loss = 0.10026837\n",
      "Iteration 184, loss = 0.10031026\n",
      "Iteration 185, loss = 0.10036706\n",
      "Iteration 186, loss = 0.10023016\n",
      "Iteration 187, loss = 0.09999186\n",
      "Iteration 188, loss = 0.10004052\n",
      "Iteration 189, loss = 0.10017864\n",
      "Iteration 190, loss = 0.09980852\n",
      "Iteration 191, loss = 0.10004578\n",
      "Iteration 192, loss = 0.09991253\n",
      "Iteration 193, loss = 0.09994736\n",
      "Iteration 194, loss = 0.09985987\n",
      "Iteration 195, loss = 0.09972013\n",
      "Iteration 196, loss = 0.09988375\n",
      "Iteration 197, loss = 0.09988763\n",
      "Iteration 198, loss = 0.09965600\n",
      "Iteration 199, loss = 0.09954862\n",
      "Iteration 200, loss = 0.09970151\n",
      "Iteration 1, loss = 0.40798245\n",
      "Iteration 2, loss = 0.22200049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 3, loss = 0.17285677\n",
      "Iteration 4, loss = 0.15508484\n",
      "Iteration 5, loss = 0.14700603\n",
      "Iteration 6, loss = 0.14281436\n",
      "Iteration 7, loss = 0.14016648\n",
      "Iteration 8, loss = 0.13828734\n",
      "Iteration 9, loss = 0.13689874\n",
      "Iteration 10, loss = 0.13572406\n",
      "Iteration 11, loss = 0.13466085\n",
      "Iteration 12, loss = 0.13402330\n",
      "Iteration 13, loss = 0.13295228\n",
      "Iteration 14, loss = 0.13222453\n",
      "Iteration 15, loss = 0.13186971\n",
      "Iteration 16, loss = 0.13103585\n",
      "Iteration 17, loss = 0.13044301\n",
      "Iteration 18, loss = 0.13002291\n",
      "Iteration 19, loss = 0.12945503\n",
      "Iteration 20, loss = 0.12903636\n",
      "Iteration 21, loss = 0.12878532\n",
      "Iteration 22, loss = 0.12805903\n",
      "Iteration 23, loss = 0.12765791\n",
      "Iteration 24, loss = 0.12740762\n",
      "Iteration 25, loss = 0.12687180\n",
      "Iteration 26, loss = 0.12639626\n",
      "Iteration 27, loss = 0.12606166\n",
      "Iteration 28, loss = 0.12556114\n",
      "Iteration 29, loss = 0.12499008\n",
      "Iteration 30, loss = 0.12444538\n",
      "Iteration 31, loss = 0.12407139\n",
      "Iteration 32, loss = 0.12387996\n",
      "Iteration 33, loss = 0.12331564\n",
      "Iteration 34, loss = 0.12290544\n",
      "Iteration 35, loss = 0.12281017\n",
      "Iteration 36, loss = 0.12281237\n",
      "Iteration 37, loss = 0.12202647\n",
      "Iteration 38, loss = 0.12193217\n",
      "Iteration 39, loss = 0.12163817\n",
      "Iteration 40, loss = 0.12134839\n",
      "Iteration 41, loss = 0.12107105\n",
      "Iteration 42, loss = 0.12078781\n",
      "Iteration 43, loss = 0.12052540\n",
      "Iteration 44, loss = 0.12035916\n",
      "Iteration 45, loss = 0.12011293\n",
      "Iteration 46, loss = 0.11951866\n",
      "Iteration 47, loss = 0.11942245\n",
      "Iteration 48, loss = 0.11925742\n",
      "Iteration 49, loss = 0.11898665\n",
      "Iteration 50, loss = 0.11859928\n",
      "Iteration 51, loss = 0.11853131\n",
      "Iteration 52, loss = 0.11811812\n",
      "Iteration 53, loss = 0.11797560\n",
      "Iteration 54, loss = 0.11796985\n",
      "Iteration 55, loss = 0.11771644\n",
      "Iteration 56, loss = 0.11744581\n",
      "Iteration 57, loss = 0.11726079\n",
      "Iteration 58, loss = 0.11724484\n",
      "Iteration 59, loss = 0.11682914\n",
      "Iteration 60, loss = 0.11664962\n",
      "Iteration 61, loss = 0.11650857\n",
      "Iteration 62, loss = 0.11630946\n",
      "Iteration 63, loss = 0.11602512\n",
      "Iteration 64, loss = 0.11594582\n",
      "Iteration 65, loss = 0.11561041\n",
      "Iteration 66, loss = 0.11564553\n",
      "Iteration 67, loss = 0.11558556\n",
      "Iteration 68, loss = 0.11549915\n",
      "Iteration 69, loss = 0.11517650\n",
      "Iteration 70, loss = 0.11500637\n",
      "Iteration 71, loss = 0.11490707\n",
      "Iteration 72, loss = 0.11449304\n",
      "Iteration 73, loss = 0.11453334\n",
      "Iteration 74, loss = 0.11430345\n",
      "Iteration 75, loss = 0.11420759\n",
      "Iteration 76, loss = 0.11402886\n",
      "Iteration 77, loss = 0.11408803\n",
      "Iteration 78, loss = 0.11381377\n",
      "Iteration 79, loss = 0.11392006\n",
      "Iteration 80, loss = 0.11370513\n",
      "Iteration 81, loss = 0.11345529\n",
      "Iteration 82, loss = 0.11310556\n",
      "Iteration 83, loss = 0.11316492\n",
      "Iteration 84, loss = 0.11321974\n",
      "Iteration 85, loss = 0.11280002\n",
      "Iteration 86, loss = 0.11272155\n",
      "Iteration 87, loss = 0.11247677\n",
      "Iteration 88, loss = 0.11238326\n",
      "Iteration 89, loss = 0.11223414\n",
      "Iteration 90, loss = 0.11202427\n",
      "Iteration 91, loss = 0.11229184\n",
      "Iteration 92, loss = 0.11195165\n",
      "Iteration 93, loss = 0.11179690\n",
      "Iteration 94, loss = 0.11175765\n",
      "Iteration 95, loss = 0.11148211\n",
      "Iteration 96, loss = 0.11149145\n",
      "Iteration 97, loss = 0.11150991\n",
      "Iteration 98, loss = 0.11091289\n",
      "Iteration 99, loss = 0.11123822\n",
      "Iteration 100, loss = 0.11081563\n",
      "Iteration 101, loss = 0.11078694\n",
      "Iteration 102, loss = 0.11078101\n",
      "Iteration 103, loss = 0.11059459\n",
      "Iteration 104, loss = 0.11034780\n",
      "Iteration 105, loss = 0.11022001\n",
      "Iteration 106, loss = 0.11030993\n",
      "Iteration 107, loss = 0.11003811\n",
      "Iteration 108, loss = 0.10994390\n",
      "Iteration 109, loss = 0.10987270\n",
      "Iteration 110, loss = 0.10998841\n",
      "Iteration 111, loss = 0.10952140\n",
      "Iteration 112, loss = 0.10970951\n",
      "Iteration 113, loss = 0.10916552\n",
      "Iteration 114, loss = 0.10926179\n",
      "Iteration 115, loss = 0.10927081\n",
      "Iteration 116, loss = 0.10909293\n",
      "Iteration 117, loss = 0.10869237\n",
      "Iteration 118, loss = 0.10878311\n",
      "Iteration 119, loss = 0.10884960\n",
      "Iteration 120, loss = 0.10866214\n",
      "Iteration 121, loss = 0.10845521\n",
      "Iteration 122, loss = 0.10858808\n",
      "Iteration 123, loss = 0.10816588\n",
      "Iteration 124, loss = 0.10819685\n",
      "Iteration 125, loss = 0.10810481\n",
      "Iteration 126, loss = 0.10797076\n",
      "Iteration 127, loss = 0.10792169\n",
      "Iteration 128, loss = 0.10796216\n",
      "Iteration 129, loss = 0.10745436\n",
      "Iteration 130, loss = 0.10776201\n",
      "Iteration 131, loss = 0.10781645\n",
      "Iteration 132, loss = 0.10729737\n",
      "Iteration 133, loss = 0.10743415\n",
      "Iteration 134, loss = 0.10761523\n",
      "Iteration 135, loss = 0.10745006\n",
      "Iteration 136, loss = 0.10749623\n",
      "Iteration 137, loss = 0.10729652\n",
      "Iteration 138, loss = 0.10714046\n",
      "Iteration 139, loss = 0.10754729\n",
      "Iteration 140, loss = 0.10682610\n",
      "Iteration 141, loss = 0.10670289\n",
      "Iteration 142, loss = 0.10644153\n",
      "Iteration 143, loss = 0.10642415\n",
      "Iteration 144, loss = 0.10664773\n",
      "Iteration 145, loss = 0.10627782\n",
      "Iteration 146, loss = 0.10624393\n",
      "Iteration 147, loss = 0.10633212\n",
      "Iteration 148, loss = 0.10621076\n",
      "Iteration 149, loss = 0.10632666\n",
      "Iteration 150, loss = 0.10614317\n",
      "Iteration 151, loss = 0.10583618\n",
      "Iteration 152, loss = 0.10576927\n",
      "Iteration 153, loss = 0.10578086\n",
      "Iteration 154, loss = 0.10586452\n",
      "Iteration 155, loss = 0.10583628\n",
      "Iteration 156, loss = 0.10565740\n",
      "Iteration 157, loss = 0.10545143\n",
      "Iteration 158, loss = 0.10566130\n",
      "Iteration 159, loss = 0.10530665\n",
      "Iteration 160, loss = 0.10517954\n",
      "Iteration 161, loss = 0.10537079\n",
      "Iteration 162, loss = 0.10518755\n",
      "Iteration 163, loss = 0.10497905\n",
      "Iteration 164, loss = 0.10501890\n",
      "Iteration 165, loss = 0.10499046\n",
      "Iteration 166, loss = 0.10487345\n",
      "Iteration 167, loss = 0.10482510\n",
      "Iteration 168, loss = 0.10482504\n",
      "Iteration 169, loss = 0.10477198\n",
      "Iteration 170, loss = 0.10463491\n",
      "Iteration 171, loss = 0.10462825\n",
      "Iteration 172, loss = 0.10468502\n",
      "Iteration 173, loss = 0.10435922\n",
      "Iteration 174, loss = 0.10446774\n",
      "Iteration 175, loss = 0.10431128\n",
      "Iteration 176, loss = 0.10428557\n",
      "Iteration 177, loss = 0.10414211\n",
      "Iteration 178, loss = 0.10420384\n",
      "Iteration 179, loss = 0.10400593\n",
      "Iteration 180, loss = 0.10402227\n",
      "Iteration 181, loss = 0.10409781\n",
      "Iteration 182, loss = 0.10413086\n",
      "Iteration 183, loss = 0.10390274\n",
      "Iteration 184, loss = 0.10395201\n",
      "Iteration 185, loss = 0.10369639\n",
      "Iteration 186, loss = 0.10398311\n",
      "Iteration 187, loss = 0.10372763\n",
      "Iteration 188, loss = 0.10372643\n",
      "Iteration 189, loss = 0.10380876\n",
      "Iteration 190, loss = 0.10357395\n",
      "Iteration 191, loss = 0.10374951\n",
      "Iteration 192, loss = 0.10323729\n",
      "Iteration 193, loss = 0.10338619\n",
      "Iteration 194, loss = 0.10379214\n",
      "Iteration 195, loss = 0.10315666\n",
      "Iteration 196, loss = 0.10336687\n",
      "Iteration 197, loss = 0.10312665\n",
      "Iteration 198, loss = 0.10331105\n",
      "Iteration 199, loss = 0.10313683\n",
      "Iteration 200, loss = 0.10322019\n",
      "Iteration 1, loss = 0.39332236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.20769968\n",
      "Iteration 3, loss = 0.17803457\n",
      "Iteration 4, loss = 0.17133328\n",
      "Iteration 5, loss = 0.16846607\n",
      "Iteration 6, loss = 0.16705306\n",
      "Iteration 7, loss = 0.16603707\n",
      "Iteration 8, loss = 0.16529249\n",
      "Iteration 9, loss = 0.16478644\n",
      "Iteration 10, loss = 0.16422609\n",
      "Iteration 11, loss = 0.16392646\n",
      "Iteration 12, loss = 0.16370566\n",
      "Iteration 13, loss = 0.16349644\n",
      "Iteration 14, loss = 0.16330080\n",
      "Iteration 15, loss = 0.16300603\n",
      "Iteration 16, loss = 0.16287944\n",
      "Iteration 17, loss = 0.16292779\n",
      "Iteration 18, loss = 0.16278361\n",
      "Iteration 19, loss = 0.16267234\n",
      "Iteration 20, loss = 0.16283068\n",
      "Iteration 21, loss = 0.16267747\n",
      "Iteration 22, loss = 0.16264629\n",
      "Iteration 23, loss = 0.16244627\n",
      "Iteration 24, loss = 0.16248307\n",
      "Iteration 25, loss = 0.16253311\n",
      "Iteration 26, loss = 0.16255505\n",
      "Iteration 27, loss = 0.16246021\n",
      "Iteration 28, loss = 0.16260915\n",
      "Iteration 29, loss = 0.16238806\n",
      "Iteration 30, loss = 0.16235877\n",
      "Iteration 31, loss = 0.16236607\n",
      "Iteration 32, loss = 0.16244290\n",
      "Iteration 33, loss = 0.16237678\n",
      "Iteration 34, loss = 0.16238867\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.44962402\n",
      "Iteration 2, loss = 0.24288148\n",
      "Iteration 3, loss = 0.19317022\n",
      "Iteration 4, loss = 0.17785904\n",
      "Iteration 5, loss = 0.17202898\n",
      "Iteration 6, loss = 0.16938232\n",
      "Iteration 7, loss = 0.16737106\n",
      "Iteration 8, loss = 0.16635872\n",
      "Iteration 9, loss = 0.16525551\n",
      "Iteration 10, loss = 0.16445464\n",
      "Iteration 11, loss = 0.16402686\n",
      "Iteration 12, loss = 0.16349264\n",
      "Iteration 13, loss = 0.16304364\n",
      "Iteration 14, loss = 0.16285274\n",
      "Iteration 15, loss = 0.16256787\n",
      "Iteration 16, loss = 0.16235433\n",
      "Iteration 17, loss = 0.16216780\n",
      "Iteration 18, loss = 0.16203549\n",
      "Iteration 19, loss = 0.16181269\n",
      "Iteration 20, loss = 0.16168532\n",
      "Iteration 21, loss = 0.16174726\n",
      "Iteration 22, loss = 0.16156682\n",
      "Iteration 23, loss = 0.16164235\n",
      "Iteration 24, loss = 0.16148603\n",
      "Iteration 25, loss = 0.16151620\n",
      "Iteration 26, loss = 0.16137914\n",
      "Iteration 27, loss = 0.16133503\n",
      "Iteration 28, loss = 0.16127125\n",
      "Iteration 29, loss = 0.16133868\n",
      "Iteration 30, loss = 0.16124739\n",
      "Iteration 31, loss = 0.16113687\n",
      "Iteration 32, loss = 0.16117436\n",
      "Iteration 33, loss = 0.16117647\n",
      "Iteration 34, loss = 0.16125547\n",
      "Iteration 35, loss = 0.16134808\n",
      "Iteration 36, loss = 0.16119079\n",
      "Iteration 37, loss = 0.16119196\n",
      "Iteration 38, loss = 0.16104508\n",
      "Iteration 39, loss = 0.16104763\n",
      "Iteration 40, loss = 0.16101101\n",
      "Iteration 41, loss = 0.16107520\n",
      "Iteration 42, loss = 0.16100295\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.46324730\n",
      "Iteration 2, loss = 0.24061372\n",
      "Iteration 3, loss = 0.19160021\n",
      "Iteration 4, loss = 0.17852233\n",
      "Iteration 5, loss = 0.17373750\n",
      "Iteration 6, loss = 0.17147130\n",
      "Iteration 7, loss = 0.17001445\n",
      "Iteration 8, loss = 0.16846734\n",
      "Iteration 9, loss = 0.16744627\n",
      "Iteration 10, loss = 0.16653676\n",
      "Iteration 11, loss = 0.16614303\n",
      "Iteration 12, loss = 0.16531251\n",
      "Iteration 13, loss = 0.16487267\n",
      "Iteration 14, loss = 0.16454859\n",
      "Iteration 15, loss = 0.16443482\n",
      "Iteration 16, loss = 0.16401281\n",
      "Iteration 17, loss = 0.16378507\n",
      "Iteration 18, loss = 0.16374023\n",
      "Iteration 19, loss = 0.16345497\n",
      "Iteration 20, loss = 0.16337661\n",
      "Iteration 21, loss = 0.16332364\n",
      "Iteration 22, loss = 0.16325007\n",
      "Iteration 23, loss = 0.16283517\n",
      "Iteration 24, loss = 0.16307092\n",
      "Iteration 25, loss = 0.16310962\n",
      "Iteration 26, loss = 0.16295069\n",
      "Iteration 27, loss = 0.16292756\n",
      "Iteration 28, loss = 0.16281304\n",
      "Iteration 29, loss = 0.16272498\n",
      "Iteration 30, loss = 0.16259878\n",
      "Iteration 31, loss = 0.16274065\n",
      "Iteration 32, loss = 0.16261304\n",
      "Iteration 33, loss = 0.16280844\n",
      "Iteration 34, loss = 0.16280678\n",
      "Iteration 35, loss = 0.16270650\n",
      "Iteration 36, loss = 0.16239191\n",
      "Iteration 37, loss = 0.16258410\n",
      "Iteration 38, loss = 0.16262372\n",
      "Iteration 39, loss = 0.16249037\n",
      "Iteration 40, loss = 0.16258117\n",
      "Iteration 41, loss = 0.16232527\n",
      "Iteration 42, loss = 0.16265144\n",
      "Iteration 43, loss = 0.16248075\n",
      "Iteration 44, loss = 0.16245853\n",
      "Iteration 45, loss = 0.16261367\n",
      "Iteration 46, loss = 0.16244709\n",
      "Iteration 47, loss = 0.16246300\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.46408601\n",
      "Iteration 2, loss = 0.24646764\n",
      "Iteration 3, loss = 0.19372035\n",
      "Iteration 4, loss = 0.17793410\n",
      "Iteration 5, loss = 0.17203140\n",
      "Iteration 6, loss = 0.16901778\n",
      "Iteration 7, loss = 0.16766031\n",
      "Iteration 8, loss = 0.16623396\n",
      "Iteration 9, loss = 0.16516899\n",
      "Iteration 10, loss = 0.16448935\n",
      "Iteration 11, loss = 0.16402418\n",
      "Iteration 12, loss = 0.16368605\n",
      "Iteration 13, loss = 0.16322890\n",
      "Iteration 14, loss = 0.16282575\n",
      "Iteration 15, loss = 0.16271219\n",
      "Iteration 16, loss = 0.16247446\n",
      "Iteration 17, loss = 0.16225283\n",
      "Iteration 18, loss = 0.16218113\n",
      "Iteration 19, loss = 0.16188891\n",
      "Iteration 20, loss = 0.16178398\n",
      "Iteration 21, loss = 0.16167989\n",
      "Iteration 22, loss = 0.16192504\n",
      "Iteration 23, loss = 0.16170432\n",
      "Iteration 24, loss = 0.16143449\n",
      "Iteration 25, loss = 0.16140283\n",
      "Iteration 26, loss = 0.16151357\n",
      "Iteration 27, loss = 0.16136805\n",
      "Iteration 28, loss = 0.16125414\n",
      "Iteration 29, loss = 0.16120509\n",
      "Iteration 30, loss = 0.16130528\n",
      "Iteration 31, loss = 0.16124917\n",
      "Iteration 32, loss = 0.16130972\n",
      "Iteration 33, loss = 0.16132843\n",
      "Iteration 34, loss = 0.16116116\n",
      "Iteration 35, loss = 0.16120548\n",
      "Iteration 36, loss = 0.16119872\n",
      "Iteration 37, loss = 0.16104261\n",
      "Iteration 38, loss = 0.16107188\n",
      "Iteration 39, loss = 0.16108072\n",
      "Iteration 40, loss = 0.16098166\n",
      "Iteration 41, loss = 0.16112210\n",
      "Iteration 42, loss = 0.16110808\n",
      "Iteration 43, loss = 0.16102897\n",
      "Iteration 44, loss = 0.16096877\n",
      "Iteration 45, loss = 0.16103619\n",
      "Iteration 46, loss = 0.16102261\n",
      "Iteration 47, loss = 0.16111642\n",
      "Iteration 48, loss = 0.16097269\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.42590863\n",
      "Iteration 2, loss = 0.23518263\n",
      "Iteration 3, loss = 0.18878109\n",
      "Iteration 4, loss = 0.17523282\n",
      "Iteration 5, loss = 0.17048645\n",
      "Iteration 6, loss = 0.16796423\n",
      "Iteration 7, loss = 0.16651563\n",
      "Iteration 8, loss = 0.16564864\n",
      "Iteration 9, loss = 0.16479846\n",
      "Iteration 10, loss = 0.16421157\n",
      "Iteration 11, loss = 0.16379449\n",
      "Iteration 12, loss = 0.16336309\n",
      "Iteration 13, loss = 0.16302285\n",
      "Iteration 14, loss = 0.16284528\n",
      "Iteration 15, loss = 0.16279653\n",
      "Iteration 16, loss = 0.16261375\n",
      "Iteration 17, loss = 0.16231435\n",
      "Iteration 18, loss = 0.16211985\n",
      "Iteration 19, loss = 0.16191460\n",
      "Iteration 20, loss = 0.16199336\n",
      "Iteration 21, loss = 0.16180461\n",
      "Iteration 22, loss = 0.16187410\n",
      "Iteration 23, loss = 0.16201980\n",
      "Iteration 24, loss = 0.16166270\n",
      "Iteration 25, loss = 0.16162687\n",
      "Iteration 26, loss = 0.16156490\n",
      "Iteration 27, loss = 0.16149895\n",
      "Iteration 28, loss = 0.16136508\n",
      "Iteration 29, loss = 0.16159941\n",
      "Iteration 30, loss = 0.16150737\n",
      "Iteration 31, loss = 0.16157717\n",
      "Iteration 32, loss = 0.16153847\n",
      "Iteration 33, loss = 0.16122073\n",
      "Iteration 34, loss = 0.16159943\n",
      "Iteration 35, loss = 0.16131231\n",
      "Iteration 36, loss = 0.16130886\n",
      "Iteration 37, loss = 0.16128200\n",
      "Iteration 38, loss = 0.16152061\n",
      "Iteration 39, loss = 0.16134066\n",
      "Iteration 40, loss = 0.16127622\n",
      "Iteration 41, loss = 0.16131287\n",
      "Iteration 42, loss = 0.16128234\n",
      "Iteration 43, loss = 0.16142925\n",
      "Iteration 44, loss = 0.16121589\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.47855068\n",
      "Iteration 2, loss = 0.24774562\n",
      "Iteration 3, loss = 0.19618822\n",
      "Iteration 4, loss = 0.18117612\n",
      "Iteration 5, loss = 0.17540606\n",
      "Iteration 6, loss = 0.17271485\n",
      "Iteration 7, loss = 0.17099374\n",
      "Iteration 8, loss = 0.17003232\n",
      "Iteration 9, loss = 0.16924316\n",
      "Iteration 10, loss = 0.16856767\n",
      "Iteration 11, loss = 0.16807055\n",
      "Iteration 12, loss = 0.16763066\n",
      "Iteration 13, loss = 0.16733767\n",
      "Iteration 14, loss = 0.16697556\n",
      "Iteration 15, loss = 0.16658948\n",
      "Iteration 16, loss = 0.16656735\n",
      "Iteration 17, loss = 0.16634868\n",
      "Iteration 18, loss = 0.16613102\n",
      "Iteration 19, loss = 0.16605075\n",
      "Iteration 20, loss = 0.16601475\n",
      "Iteration 21, loss = 0.16593338\n",
      "Iteration 22, loss = 0.16568396\n",
      "Iteration 23, loss = 0.16543715\n",
      "Iteration 24, loss = 0.16549485\n",
      "Iteration 25, loss = 0.16542274\n",
      "Iteration 26, loss = 0.16544193\n",
      "Iteration 27, loss = 0.16531245\n",
      "Iteration 28, loss = 0.16510204\n",
      "Iteration 29, loss = 0.16522143\n",
      "Iteration 30, loss = 0.16531021\n",
      "Iteration 31, loss = 0.16489517\n",
      "Iteration 32, loss = 0.16506781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33, loss = 0.16518004\n",
      "Iteration 34, loss = 0.16517970\n",
      "Iteration 35, loss = 0.16504829\n",
      "Iteration 36, loss = 0.16501313\n",
      "Iteration 37, loss = 0.16494576\n",
      "Iteration 38, loss = 0.16502154\n",
      "Iteration 39, loss = 0.16491320\n",
      "Iteration 40, loss = 0.16493169\n",
      "Iteration 41, loss = 0.16495386\n",
      "Iteration 42, loss = 0.16495903\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.50449458\n",
      "Iteration 2, loss = 0.39495288\n",
      "Iteration 3, loss = 0.35073161\n",
      "Iteration 4, loss = 0.32623346\n",
      "Iteration 5, loss = 0.31339044\n",
      "Iteration 6, loss = 0.30504772\n",
      "Iteration 7, loss = 0.29939047\n",
      "Iteration 8, loss = 0.29500214\n",
      "Iteration 9, loss = 0.29157405\n",
      "Iteration 10, loss = 0.28876596\n",
      "Iteration 11, loss = 0.28616210\n",
      "Iteration 12, loss = 0.28394683\n",
      "Iteration 13, loss = 0.28204051\n",
      "Iteration 14, loss = 0.28027748\n",
      "Iteration 15, loss = 0.27884121\n",
      "Iteration 16, loss = 0.27772452\n",
      "Iteration 17, loss = 0.27668256\n",
      "Iteration 18, loss = 0.27588104\n",
      "Iteration 19, loss = 0.27522425\n",
      "Iteration 20, loss = 0.27466380\n",
      "Iteration 21, loss = 0.27428605\n",
      "Iteration 22, loss = 0.27341997\n",
      "Iteration 23, loss = 0.27326177\n",
      "Iteration 24, loss = 0.27278860\n",
      "Iteration 25, loss = 0.27234171\n",
      "Iteration 26, loss = 0.27209992\n",
      "Iteration 27, loss = 0.27203312\n",
      "Iteration 28, loss = 0.27138766\n",
      "Iteration 29, loss = 0.27125931\n",
      "Iteration 30, loss = 0.27093949\n",
      "Iteration 31, loss = 0.27090659\n",
      "Iteration 32, loss = 0.27066960\n",
      "Iteration 33, loss = 0.27071964\n",
      "Iteration 34, loss = 0.27034947\n",
      "Iteration 35, loss = 0.27031821\n",
      "Iteration 36, loss = 0.27034841\n",
      "Iteration 37, loss = 0.27036848\n",
      "Iteration 38, loss = 0.27023710\n",
      "Iteration 39, loss = 0.26999180\n",
      "Iteration 40, loss = 0.27007233\n",
      "Iteration 41, loss = 0.26990270\n",
      "Iteration 42, loss = 0.26970995\n",
      "Iteration 43, loss = 0.26953671\n",
      "Iteration 44, loss = 0.26962219\n",
      "Iteration 45, loss = 0.26950553\n",
      "Iteration 46, loss = 0.26937118\n",
      "Iteration 47, loss = 0.26932768\n",
      "Iteration 48, loss = 0.26939308\n",
      "Iteration 49, loss = 0.26934531\n",
      "Iteration 50, loss = 0.26906290\n",
      "Iteration 51, loss = 0.26925481\n",
      "Iteration 52, loss = 0.26917224\n",
      "Iteration 53, loss = 0.26902524\n",
      "Iteration 54, loss = 0.26906990\n",
      "Iteration 55, loss = 0.26905640\n",
      "Iteration 56, loss = 0.26930866\n",
      "Iteration 57, loss = 0.26894877\n",
      "Iteration 58, loss = 0.26896500\n",
      "Iteration 59, loss = 0.26907645\n",
      "Iteration 60, loss = 0.26893256\n",
      "Iteration 61, loss = 0.26880351\n",
      "Iteration 62, loss = 0.26885966\n",
      "Iteration 63, loss = 0.26880568\n",
      "Iteration 64, loss = 0.26875403\n",
      "Iteration 65, loss = 0.26882173\n",
      "Iteration 66, loss = 0.26883090\n",
      "Iteration 67, loss = 0.26891069\n",
      "Iteration 68, loss = 0.26862419\n",
      "Iteration 69, loss = 0.26851895\n",
      "Iteration 70, loss = 0.26870075\n",
      "Iteration 71, loss = 0.26853546\n",
      "Iteration 72, loss = 0.26855744\n",
      "Iteration 73, loss = 0.26871977\n",
      "Iteration 74, loss = 0.26842388\n",
      "Iteration 75, loss = 0.26858922\n",
      "Iteration 76, loss = 0.26841645\n",
      "Iteration 77, loss = 0.26879071\n",
      "Iteration 78, loss = 0.26862773\n",
      "Iteration 79, loss = 0.26839267\n",
      "Iteration 80, loss = 0.26840850\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.51769275\n",
      "Iteration 2, loss = 0.40284447\n",
      "Iteration 3, loss = 0.36255675\n",
      "Iteration 4, loss = 0.33666448\n",
      "Iteration 5, loss = 0.32107417\n",
      "Iteration 6, loss = 0.31121318\n",
      "Iteration 7, loss = 0.30491108\n",
      "Iteration 8, loss = 0.30018140\n",
      "Iteration 9, loss = 0.29641944\n",
      "Iteration 10, loss = 0.29297170\n",
      "Iteration 11, loss = 0.28972496\n",
      "Iteration 12, loss = 0.28728301\n",
      "Iteration 13, loss = 0.28488342\n",
      "Iteration 14, loss = 0.28295277\n",
      "Iteration 15, loss = 0.28100611\n",
      "Iteration 16, loss = 0.27967462\n",
      "Iteration 17, loss = 0.27822673\n",
      "Iteration 18, loss = 0.27666468\n",
      "Iteration 19, loss = 0.27576747\n",
      "Iteration 20, loss = 0.27468420\n",
      "Iteration 21, loss = 0.27361745\n",
      "Iteration 22, loss = 0.27285779\n",
      "Iteration 23, loss = 0.27251361\n",
      "Iteration 24, loss = 0.27184437\n",
      "Iteration 25, loss = 0.27105780\n",
      "Iteration 26, loss = 0.27067499\n",
      "Iteration 27, loss = 0.27054065\n",
      "Iteration 28, loss = 0.27034627\n",
      "Iteration 29, loss = 0.26967554\n",
      "Iteration 30, loss = 0.26951409\n",
      "Iteration 31, loss = 0.26952563\n",
      "Iteration 32, loss = 0.26898637\n",
      "Iteration 33, loss = 0.26881869\n",
      "Iteration 34, loss = 0.26872654\n",
      "Iteration 35, loss = 0.26873322\n",
      "Iteration 36, loss = 0.26848233\n",
      "Iteration 37, loss = 0.26819913\n",
      "Iteration 38, loss = 0.26808271\n",
      "Iteration 39, loss = 0.26831504\n",
      "Iteration 40, loss = 0.26792237\n",
      "Iteration 41, loss = 0.26793575\n",
      "Iteration 42, loss = 0.26771936\n",
      "Iteration 43, loss = 0.26757224\n",
      "Iteration 44, loss = 0.26745059\n",
      "Iteration 45, loss = 0.26736920\n",
      "Iteration 46, loss = 0.26713623\n",
      "Iteration 47, loss = 0.26731449\n",
      "Iteration 48, loss = 0.26711784\n",
      "Iteration 49, loss = 0.26703707\n",
      "Iteration 50, loss = 0.26711610\n",
      "Iteration 51, loss = 0.26708656\n",
      "Iteration 52, loss = 0.26674839\n",
      "Iteration 53, loss = 0.26702317\n",
      "Iteration 54, loss = 0.26680413\n",
      "Iteration 55, loss = 0.26662775\n",
      "Iteration 56, loss = 0.26668958\n",
      "Iteration 57, loss = 0.26668037\n",
      "Iteration 58, loss = 0.26645683\n",
      "Iteration 59, loss = 0.26672316\n",
      "Iteration 60, loss = 0.26637674\n",
      "Iteration 61, loss = 0.26654254\n",
      "Iteration 62, loss = 0.26628381\n",
      "Iteration 63, loss = 0.26628075\n",
      "Iteration 64, loss = 0.26642832\n",
      "Iteration 65, loss = 0.26629800\n",
      "Iteration 66, loss = 0.26610478\n",
      "Iteration 67, loss = 0.26616826\n",
      "Iteration 68, loss = 0.26627018\n",
      "Iteration 69, loss = 0.26624308\n",
      "Iteration 70, loss = 0.26611591\n",
      "Iteration 71, loss = 0.26613662\n",
      "Iteration 72, loss = 0.26609001\n",
      "Iteration 73, loss = 0.26637612\n",
      "Iteration 74, loss = 0.26610548\n",
      "Iteration 75, loss = 0.26603279\n",
      "Iteration 76, loss = 0.26580456\n",
      "Iteration 77, loss = 0.26594052\n",
      "Iteration 78, loss = 0.26579779\n",
      "Iteration 79, loss = 0.26609221\n",
      "Iteration 80, loss = 0.26576074\n",
      "Iteration 81, loss = 0.26597461\n",
      "Iteration 82, loss = 0.26612758\n",
      "Iteration 83, loss = 0.26606075\n",
      "Iteration 84, loss = 0.26581539\n",
      "Iteration 85, loss = 0.26585415\n",
      "Iteration 86, loss = 0.26574146\n",
      "Iteration 87, loss = 0.26598715\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.56352409\n",
      "Iteration 2, loss = 0.41921755\n",
      "Iteration 3, loss = 0.37554005\n",
      "Iteration 4, loss = 0.34644171\n",
      "Iteration 5, loss = 0.32810811\n",
      "Iteration 6, loss = 0.31668963\n",
      "Iteration 7, loss = 0.30877034\n",
      "Iteration 8, loss = 0.30327307\n",
      "Iteration 9, loss = 0.29923906\n",
      "Iteration 10, loss = 0.29583725\n",
      "Iteration 11, loss = 0.29336239\n",
      "Iteration 12, loss = 0.29115612\n",
      "Iteration 13, loss = 0.28896638\n",
      "Iteration 14, loss = 0.28736781\n",
      "Iteration 15, loss = 0.28583246\n",
      "Iteration 16, loss = 0.28448097\n",
      "Iteration 17, loss = 0.28324209\n",
      "Iteration 18, loss = 0.28249109\n",
      "Iteration 19, loss = 0.28148085\n",
      "Iteration 20, loss = 0.28053380\n",
      "Iteration 21, loss = 0.27962492\n",
      "Iteration 22, loss = 0.27873481\n",
      "Iteration 23, loss = 0.27782340\n",
      "Iteration 24, loss = 0.27728719\n",
      "Iteration 25, loss = 0.27672641\n",
      "Iteration 26, loss = 0.27605069\n",
      "Iteration 27, loss = 0.27531115\n",
      "Iteration 28, loss = 0.27514451\n",
      "Iteration 29, loss = 0.27464105\n",
      "Iteration 30, loss = 0.27435011\n",
      "Iteration 31, loss = 0.27424070\n",
      "Iteration 32, loss = 0.27358226\n",
      "Iteration 33, loss = 0.27313472\n",
      "Iteration 34, loss = 0.27287472\n",
      "Iteration 35, loss = 0.27260939\n",
      "Iteration 36, loss = 0.27223140\n",
      "Iteration 37, loss = 0.27230226\n",
      "Iteration 38, loss = 0.27229889\n",
      "Iteration 39, loss = 0.27170278\n",
      "Iteration 40, loss = 0.27170556\n",
      "Iteration 41, loss = 0.27161340\n",
      "Iteration 42, loss = 0.27137745\n",
      "Iteration 43, loss = 0.27100065\n",
      "Iteration 44, loss = 0.27112806\n",
      "Iteration 45, loss = 0.27093939\n",
      "Iteration 46, loss = 0.27100585\n",
      "Iteration 47, loss = 0.27075828\n",
      "Iteration 48, loss = 0.27063840\n",
      "Iteration 49, loss = 0.27068910\n",
      "Iteration 50, loss = 0.27076927\n",
      "Iteration 51, loss = 0.27055981\n",
      "Iteration 52, loss = 0.27034288\n",
      "Iteration 53, loss = 0.27041446\n",
      "Iteration 54, loss = 0.27026084\n",
      "Iteration 55, loss = 0.27035545\n",
      "Iteration 56, loss = 0.27009909\n",
      "Iteration 57, loss = 0.27035844\n",
      "Iteration 58, loss = 0.27012103\n",
      "Iteration 59, loss = 0.26993078\n",
      "Iteration 60, loss = 0.27009831\n",
      "Iteration 61, loss = 0.27029536\n",
      "Iteration 62, loss = 0.26974862\n",
      "Iteration 63, loss = 0.27006996\n",
      "Iteration 64, loss = 0.26978958\n",
      "Iteration 65, loss = 0.26981142\n",
      "Iteration 66, loss = 0.26945994\n",
      "Iteration 67, loss = 0.26968198\n",
      "Iteration 68, loss = 0.26979656\n",
      "Iteration 69, loss = 0.26944100\n",
      "Iteration 70, loss = 0.26968405\n",
      "Iteration 71, loss = 0.26961794\n",
      "Iteration 72, loss = 0.26977434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 73, loss = 0.26958293\n",
      "Iteration 74, loss = 0.26931549\n",
      "Iteration 75, loss = 0.26937668\n",
      "Iteration 76, loss = 0.26969695\n",
      "Iteration 77, loss = 0.26929803\n",
      "Iteration 78, loss = 0.26960586\n",
      "Iteration 79, loss = 0.26914428\n",
      "Iteration 80, loss = 0.26923109\n",
      "Iteration 81, loss = 0.26939969\n",
      "Iteration 82, loss = 0.26904435\n",
      "Iteration 83, loss = 0.26955476\n",
      "Iteration 84, loss = 0.26911481\n",
      "Iteration 85, loss = 0.26946499\n",
      "Iteration 86, loss = 0.26931184\n",
      "Iteration 87, loss = 0.26938203\n",
      "Iteration 88, loss = 0.26942576\n",
      "Iteration 89, loss = 0.26917449\n",
      "Iteration 90, loss = 0.26935259\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.51460319\n",
      "Iteration 2, loss = 0.40262787\n",
      "Iteration 3, loss = 0.35860269\n",
      "Iteration 4, loss = 0.33234630\n",
      "Iteration 5, loss = 0.31784477\n",
      "Iteration 6, loss = 0.30909378\n",
      "Iteration 7, loss = 0.30275711\n",
      "Iteration 8, loss = 0.29802372\n",
      "Iteration 9, loss = 0.29418904\n",
      "Iteration 10, loss = 0.29160507\n",
      "Iteration 11, loss = 0.28854995\n",
      "Iteration 12, loss = 0.28641470\n",
      "Iteration 13, loss = 0.28396711\n",
      "Iteration 14, loss = 0.28223441\n",
      "Iteration 15, loss = 0.28061892\n",
      "Iteration 16, loss = 0.27937626\n",
      "Iteration 17, loss = 0.27806616\n",
      "Iteration 18, loss = 0.27746166\n",
      "Iteration 19, loss = 0.27624485\n",
      "Iteration 20, loss = 0.27537955\n",
      "Iteration 21, loss = 0.27481937\n",
      "Iteration 22, loss = 0.27424767\n",
      "Iteration 23, loss = 0.27356725\n",
      "Iteration 24, loss = 0.27303627\n",
      "Iteration 25, loss = 0.27251031\n",
      "Iteration 26, loss = 0.27237327\n",
      "Iteration 27, loss = 0.27182081\n",
      "Iteration 28, loss = 0.27167636\n",
      "Iteration 29, loss = 0.27158510\n",
      "Iteration 30, loss = 0.27152029\n",
      "Iteration 31, loss = 0.27083410\n",
      "Iteration 32, loss = 0.27060131\n",
      "Iteration 33, loss = 0.27044595\n",
      "Iteration 34, loss = 0.27019741\n",
      "Iteration 35, loss = 0.27001081\n",
      "Iteration 36, loss = 0.26993773\n",
      "Iteration 37, loss = 0.26966090\n",
      "Iteration 38, loss = 0.26967331\n",
      "Iteration 39, loss = 0.26958760\n",
      "Iteration 40, loss = 0.26956683\n",
      "Iteration 41, loss = 0.26955681\n",
      "Iteration 42, loss = 0.26923181\n",
      "Iteration 43, loss = 0.26945599\n",
      "Iteration 44, loss = 0.26916971\n",
      "Iteration 45, loss = 0.26899155\n",
      "Iteration 46, loss = 0.26888804\n",
      "Iteration 47, loss = 0.26890511\n",
      "Iteration 48, loss = 0.26886219\n",
      "Iteration 49, loss = 0.26874416\n",
      "Iteration 50, loss = 0.26859273\n",
      "Iteration 51, loss = 0.26850290\n",
      "Iteration 52, loss = 0.26846946\n",
      "Iteration 53, loss = 0.26864248\n",
      "Iteration 54, loss = 0.26854740\n",
      "Iteration 55, loss = 0.26828441\n",
      "Iteration 56, loss = 0.26843848\n",
      "Iteration 57, loss = 0.26820920\n",
      "Iteration 58, loss = 0.26801603\n",
      "Iteration 59, loss = 0.26830516\n",
      "Iteration 60, loss = 0.26803858\n",
      "Iteration 61, loss = 0.26811827\n",
      "Iteration 62, loss = 0.26788510\n",
      "Iteration 63, loss = 0.26793124\n",
      "Iteration 64, loss = 0.26784952\n",
      "Iteration 65, loss = 0.26774109\n",
      "Iteration 66, loss = 0.26778348\n",
      "Iteration 67, loss = 0.26763799\n",
      "Iteration 68, loss = 0.26781372\n",
      "Iteration 69, loss = 0.26759537\n",
      "Iteration 70, loss = 0.26750983\n",
      "Iteration 71, loss = 0.26753595\n",
      "Iteration 72, loss = 0.26741217\n",
      "Iteration 73, loss = 0.26748814\n",
      "Iteration 74, loss = 0.26741759\n",
      "Iteration 75, loss = 0.26725887\n",
      "Iteration 76, loss = 0.26760447\n",
      "Iteration 77, loss = 0.26723935\n",
      "Iteration 78, loss = 0.26735984\n",
      "Iteration 79, loss = 0.26728470\n",
      "Iteration 80, loss = 0.26732238\n",
      "Iteration 81, loss = 0.26700873\n",
      "Iteration 82, loss = 0.26689409\n",
      "Iteration 83, loss = 0.26702454\n",
      "Iteration 84, loss = 0.26695063\n",
      "Iteration 85, loss = 0.26699057\n",
      "Iteration 86, loss = 0.26711411\n",
      "Iteration 87, loss = 0.26679160\n",
      "Iteration 88, loss = 0.26705784\n",
      "Iteration 89, loss = 0.26704664\n",
      "Iteration 90, loss = 0.26696785\n",
      "Iteration 91, loss = 0.26680338\n",
      "Iteration 92, loss = 0.26668314\n",
      "Iteration 93, loss = 0.26673323\n",
      "Iteration 94, loss = 0.26678107\n",
      "Iteration 95, loss = 0.26667341\n",
      "Iteration 96, loss = 0.26670021\n",
      "Iteration 97, loss = 0.26643617\n",
      "Iteration 98, loss = 0.26681246\n",
      "Iteration 99, loss = 0.26658922\n",
      "Iteration 100, loss = 0.26677268\n",
      "Iteration 101, loss = 0.26641362\n",
      "Iteration 102, loss = 0.26646575\n",
      "Iteration 103, loss = 0.26647505\n",
      "Iteration 104, loss = 0.26645818\n",
      "Iteration 105, loss = 0.26629317\n",
      "Iteration 106, loss = 0.26649366\n",
      "Iteration 107, loss = 0.26645581\n",
      "Iteration 108, loss = 0.26634256\n",
      "Iteration 109, loss = 0.26621476\n",
      "Iteration 110, loss = 0.26640009\n",
      "Iteration 111, loss = 0.26648108\n",
      "Iteration 112, loss = 0.26623996\n",
      "Iteration 113, loss = 0.26642815\n",
      "Iteration 114, loss = 0.26650096\n",
      "Iteration 115, loss = 0.26629634\n",
      "Iteration 116, loss = 0.26616688\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.57520218\n",
      "Iteration 2, loss = 0.42332312\n",
      "Iteration 3, loss = 0.38191300\n",
      "Iteration 4, loss = 0.35531856\n",
      "Iteration 5, loss = 0.33785579\n",
      "Iteration 6, loss = 0.32603363\n",
      "Iteration 7, loss = 0.31785624\n",
      "Iteration 8, loss = 0.31137815\n",
      "Iteration 9, loss = 0.30643250\n",
      "Iteration 10, loss = 0.30186786\n",
      "Iteration 11, loss = 0.29803471\n",
      "Iteration 12, loss = 0.29477208\n",
      "Iteration 13, loss = 0.29193568\n",
      "Iteration 14, loss = 0.28954288\n",
      "Iteration 15, loss = 0.28740917\n",
      "Iteration 16, loss = 0.28579182\n",
      "Iteration 17, loss = 0.28399271\n",
      "Iteration 18, loss = 0.28252839\n",
      "Iteration 19, loss = 0.28116248\n",
      "Iteration 20, loss = 0.28009556\n",
      "Iteration 21, loss = 0.27934486\n",
      "Iteration 22, loss = 0.27859684\n",
      "Iteration 23, loss = 0.27795037\n",
      "Iteration 24, loss = 0.27693773\n",
      "Iteration 25, loss = 0.27651912\n",
      "Iteration 26, loss = 0.27584382\n",
      "Iteration 27, loss = 0.27549973\n",
      "Iteration 28, loss = 0.27487769\n",
      "Iteration 29, loss = 0.27486456\n",
      "Iteration 30, loss = 0.27424650\n",
      "Iteration 31, loss = 0.27435806\n",
      "Iteration 32, loss = 0.27397104\n",
      "Iteration 33, loss = 0.27360632\n",
      "Iteration 34, loss = 0.27332082\n",
      "Iteration 35, loss = 0.27332381\n",
      "Iteration 36, loss = 0.27345179\n",
      "Iteration 37, loss = 0.27291054\n",
      "Iteration 38, loss = 0.27282530\n",
      "Iteration 39, loss = 0.27255125\n",
      "Iteration 40, loss = 0.27215721\n",
      "Iteration 41, loss = 0.27233090\n",
      "Iteration 42, loss = 0.27199143\n",
      "Iteration 43, loss = 0.27180885\n",
      "Iteration 44, loss = 0.27177613\n",
      "Iteration 45, loss = 0.27184437\n",
      "Iteration 46, loss = 0.27170651\n",
      "Iteration 47, loss = 0.27160670\n",
      "Iteration 48, loss = 0.27150506\n",
      "Iteration 49, loss = 0.27140638\n",
      "Iteration 50, loss = 0.27159714\n",
      "Iteration 51, loss = 0.27111375\n",
      "Iteration 52, loss = 0.27106220\n",
      "Iteration 53, loss = 0.27128617\n",
      "Iteration 54, loss = 0.27092474\n",
      "Iteration 55, loss = 0.27084436\n",
      "Iteration 56, loss = 0.27089062\n",
      "Iteration 57, loss = 0.27087954\n",
      "Iteration 58, loss = 0.27072362\n",
      "Iteration 59, loss = 0.27059240\n",
      "Iteration 60, loss = 0.27059476\n",
      "Iteration 61, loss = 0.27055132\n",
      "Iteration 62, loss = 0.27061588\n",
      "Iteration 63, loss = 0.27034087\n",
      "Iteration 64, loss = 0.27060213\n",
      "Iteration 65, loss = 0.27033549\n",
      "Iteration 66, loss = 0.27042766\n",
      "Iteration 67, loss = 0.27031420\n",
      "Iteration 68, loss = 0.27017384\n",
      "Iteration 69, loss = 0.27028070\n",
      "Iteration 70, loss = 0.27026588\n",
      "Iteration 71, loss = 0.26994212\n",
      "Iteration 72, loss = 0.26985634\n",
      "Iteration 73, loss = 0.27022288\n",
      "Iteration 74, loss = 0.26999824\n",
      "Iteration 75, loss = 0.27025185\n",
      "Iteration 76, loss = 0.27005223\n",
      "Iteration 77, loss = 0.26978284\n",
      "Iteration 78, loss = 0.26985895\n",
      "Iteration 79, loss = 0.26980351\n",
      "Iteration 80, loss = 0.26992433\n",
      "Iteration 81, loss = 0.26981920\n",
      "Iteration 82, loss = 0.26990733\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.56704477\n",
      "Iteration 2, loss = 0.42037026\n",
      "Iteration 3, loss = 0.37717204\n",
      "Iteration 4, loss = 0.34869805\n",
      "Iteration 5, loss = 0.33074964\n",
      "Iteration 6, loss = 0.31894599\n",
      "Iteration 7, loss = 0.31149800\n",
      "Iteration 8, loss = 0.30614053\n",
      "Iteration 9, loss = 0.30217727\n",
      "Iteration 10, loss = 0.29873549\n",
      "Iteration 11, loss = 0.29611386\n",
      "Iteration 12, loss = 0.29370150\n",
      "Iteration 13, loss = 0.29115444\n",
      "Iteration 14, loss = 0.28921186\n",
      "Iteration 15, loss = 0.28775917\n",
      "Iteration 16, loss = 0.28594251\n",
      "Iteration 17, loss = 0.28490471\n",
      "Iteration 18, loss = 0.28387180\n",
      "Iteration 19, loss = 0.28290757\n",
      "Iteration 20, loss = 0.28197211\n",
      "Iteration 21, loss = 0.28084722\n",
      "Iteration 22, loss = 0.28004890\n",
      "Iteration 23, loss = 0.27911587\n",
      "Iteration 24, loss = 0.27866747\n",
      "Iteration 25, loss = 0.27790385\n",
      "Iteration 26, loss = 0.27729298\n",
      "Iteration 27, loss = 0.27728545\n",
      "Iteration 28, loss = 0.27662267\n",
      "Iteration 29, loss = 0.27629706\n",
      "Iteration 30, loss = 0.27600569\n",
      "Iteration 31, loss = 0.27570284\n",
      "Iteration 32, loss = 0.27533642\n",
      "Iteration 33, loss = 0.27513747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34, loss = 0.27498623\n",
      "Iteration 35, loss = 0.27474572\n",
      "Iteration 36, loss = 0.27433252\n",
      "Iteration 37, loss = 0.27400734\n",
      "Iteration 38, loss = 0.27431031\n",
      "Iteration 39, loss = 0.27417102\n",
      "Iteration 40, loss = 0.27380689\n",
      "Iteration 41, loss = 0.27375729\n",
      "Iteration 42, loss = 0.27355636\n",
      "Iteration 43, loss = 0.27331636\n",
      "Iteration 44, loss = 0.27324682\n",
      "Iteration 45, loss = 0.27327745\n",
      "Iteration 46, loss = 0.27298387\n",
      "Iteration 47, loss = 0.27296809\n",
      "Iteration 48, loss = 0.27273183\n",
      "Iteration 49, loss = 0.27262725\n",
      "Iteration 50, loss = 0.27241846\n",
      "Iteration 51, loss = 0.27280572\n",
      "Iteration 52, loss = 0.27238570\n",
      "Iteration 53, loss = 0.27265243\n",
      "Iteration 54, loss = 0.27245209\n",
      "Iteration 55, loss = 0.27264599\n",
      "Iteration 56, loss = 0.27218879\n",
      "Iteration 57, loss = 0.27233773\n",
      "Iteration 58, loss = 0.27195353\n",
      "Iteration 59, loss = 0.27203272\n",
      "Iteration 60, loss = 0.27210422\n",
      "Iteration 61, loss = 0.27200907\n",
      "Iteration 62, loss = 0.27178121\n",
      "Iteration 63, loss = 0.27187129\n",
      "Iteration 64, loss = 0.27156662\n",
      "Iteration 65, loss = 0.27177953\n",
      "Iteration 66, loss = 0.27184490\n",
      "Iteration 67, loss = 0.27151321\n",
      "Iteration 68, loss = 0.27138456\n",
      "Iteration 69, loss = 0.27154746\n",
      "Iteration 70, loss = 0.27160826\n",
      "Iteration 71, loss = 0.27148099\n",
      "Iteration 72, loss = 0.27126373\n",
      "Iteration 73, loss = 0.27135927\n",
      "Iteration 74, loss = 0.27143220\n",
      "Iteration 75, loss = 0.27118916\n",
      "Iteration 76, loss = 0.27121444\n",
      "Iteration 77, loss = 0.27105525\n",
      "Iteration 78, loss = 0.27128855\n",
      "Iteration 79, loss = 0.27100349\n",
      "Iteration 80, loss = 0.27131936\n",
      "Iteration 81, loss = 0.27101950\n",
      "Iteration 82, loss = 0.27101400\n",
      "Iteration 83, loss = 0.27084883\n",
      "Iteration 84, loss = 0.27087527\n",
      "Iteration 85, loss = 0.27080391\n",
      "Iteration 86, loss = 0.27099666\n",
      "Iteration 87, loss = 0.27070934\n",
      "Iteration 88, loss = 0.27071046\n",
      "Iteration 89, loss = 0.27054872\n",
      "Iteration 90, loss = 0.27043009\n",
      "Iteration 91, loss = 0.27055125\n",
      "Iteration 92, loss = 0.27079452\n",
      "Iteration 93, loss = 0.27078555\n",
      "Iteration 94, loss = 0.27018062\n",
      "Iteration 95, loss = 0.27065679\n",
      "Iteration 96, loss = 0.27043937\n",
      "Iteration 97, loss = 0.27046270\n",
      "Iteration 98, loss = 0.27021586\n",
      "Iteration 99, loss = 0.27010988\n",
      "Iteration 100, loss = 0.27029292\n",
      "Iteration 101, loss = 0.27001698\n",
      "Iteration 102, loss = 0.27026509\n",
      "Iteration 103, loss = 0.27035664\n",
      "Iteration 104, loss = 0.27011744\n",
      "Iteration 105, loss = 0.27016551\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38938823\n",
      "Iteration 2, loss = 0.18628071\n",
      "Iteration 3, loss = 0.13087515\n",
      "Iteration 4, loss = 0.10943186\n",
      "Iteration 5, loss = 0.10049685\n",
      "Iteration 6, loss = 0.09594494\n",
      "Iteration 7, loss = 0.09255581\n",
      "Iteration 8, loss = 0.09005839\n",
      "Iteration 9, loss = 0.08836349\n",
      "Iteration 10, loss = 0.08656154\n",
      "Iteration 11, loss = 0.08504725\n",
      "Iteration 12, loss = 0.08385347\n",
      "Iteration 13, loss = 0.08288325\n",
      "Iteration 14, loss = 0.08159210\n",
      "Iteration 15, loss = 0.08066255\n",
      "Iteration 16, loss = 0.07959101\n",
      "Iteration 17, loss = 0.07885630\n",
      "Iteration 18, loss = 0.07798901\n",
      "Iteration 19, loss = 0.07726603\n",
      "Iteration 20, loss = 0.07654446\n",
      "Iteration 21, loss = 0.07558145\n",
      "Iteration 22, loss = 0.07507293\n",
      "Iteration 23, loss = 0.07446706\n",
      "Iteration 24, loss = 0.07376715\n",
      "Iteration 25, loss = 0.07316053\n",
      "Iteration 26, loss = 0.07267834\n",
      "Iteration 27, loss = 0.07225099\n",
      "Iteration 28, loss = 0.07145562\n",
      "Iteration 29, loss = 0.07115252\n",
      "Iteration 30, loss = 0.07068743\n",
      "Iteration 31, loss = 0.07035231\n",
      "Iteration 32, loss = 0.06981504\n",
      "Iteration 33, loss = 0.06925836\n",
      "Iteration 34, loss = 0.06917916\n",
      "Iteration 35, loss = 0.06840551\n",
      "Iteration 36, loss = 0.06781574\n",
      "Iteration 37, loss = 0.06761028\n",
      "Iteration 38, loss = 0.06707407\n",
      "Iteration 39, loss = 0.06695457\n",
      "Iteration 40, loss = 0.06694187\n",
      "Iteration 41, loss = 0.06615934\n",
      "Iteration 42, loss = 0.06576438\n",
      "Iteration 43, loss = 0.06570473\n",
      "Iteration 44, loss = 0.06530875\n",
      "Iteration 45, loss = 0.06505593\n",
      "Iteration 46, loss = 0.06460808\n",
      "Iteration 47, loss = 0.06447523\n",
      "Iteration 48, loss = 0.06392065\n",
      "Iteration 49, loss = 0.06377468\n",
      "Iteration 50, loss = 0.06359757\n",
      "Iteration 51, loss = 0.06314991\n",
      "Iteration 52, loss = 0.06319260\n",
      "Iteration 53, loss = 0.06278731\n",
      "Iteration 54, loss = 0.06237433\n",
      "Iteration 55, loss = 0.06236176\n",
      "Iteration 56, loss = 0.06199240\n",
      "Iteration 57, loss = 0.06163781\n",
      "Iteration 58, loss = 0.06144558\n",
      "Iteration 59, loss = 0.06093359\n",
      "Iteration 60, loss = 0.06084490\n",
      "Iteration 61, loss = 0.06048655\n",
      "Iteration 62, loss = 0.06037736\n",
      "Iteration 63, loss = 0.06004365\n",
      "Iteration 64, loss = 0.06002779\n",
      "Iteration 65, loss = 0.06006664\n",
      "Iteration 66, loss = 0.05952042\n",
      "Iteration 67, loss = 0.05917085\n",
      "Iteration 68, loss = 0.05929627\n",
      "Iteration 69, loss = 0.05862686\n",
      "Iteration 70, loss = 0.05853784\n",
      "Iteration 71, loss = 0.05850075\n",
      "Iteration 72, loss = 0.05812354\n",
      "Iteration 73, loss = 0.05815159\n",
      "Iteration 74, loss = 0.05790598\n",
      "Iteration 75, loss = 0.05775714\n",
      "Iteration 76, loss = 0.05743397\n",
      "Iteration 77, loss = 0.05713617\n",
      "Iteration 78, loss = 0.05705189\n",
      "Iteration 79, loss = 0.05663042\n",
      "Iteration 80, loss = 0.05688887\n",
      "Iteration 81, loss = 0.05675085\n",
      "Iteration 82, loss = 0.05641401\n",
      "Iteration 83, loss = 0.05640099\n",
      "Iteration 84, loss = 0.05614854\n",
      "Iteration 85, loss = 0.05588392\n",
      "Iteration 86, loss = 0.05566274\n",
      "Iteration 87, loss = 0.05561938\n",
      "Iteration 88, loss = 0.05537249\n",
      "Iteration 89, loss = 0.05555341\n",
      "Iteration 90, loss = 0.05560111\n",
      "Iteration 91, loss = 0.05502389\n",
      "Iteration 92, loss = 0.05505409\n",
      "Iteration 93, loss = 0.05478506\n",
      "Iteration 94, loss = 0.05466061\n",
      "Iteration 95, loss = 0.05444733\n",
      "Iteration 96, loss = 0.05440456\n",
      "Iteration 97, loss = 0.05421281\n",
      "Iteration 98, loss = 0.05393281\n",
      "Iteration 99, loss = 0.05405108\n",
      "Iteration 100, loss = 0.05394734\n",
      "Iteration 101, loss = 0.05360134\n",
      "Iteration 102, loss = 0.05364888\n",
      "Iteration 103, loss = 0.05352063\n",
      "Iteration 104, loss = 0.05335943\n",
      "Iteration 105, loss = 0.05316816\n",
      "Iteration 106, loss = 0.05344479\n",
      "Iteration 107, loss = 0.05287219\n",
      "Iteration 108, loss = 0.05266472\n",
      "Iteration 109, loss = 0.05246050\n",
      "Iteration 110, loss = 0.05254403\n",
      "Iteration 111, loss = 0.05232058\n",
      "Iteration 112, loss = 0.05234170\n",
      "Iteration 113, loss = 0.05230236\n",
      "Iteration 114, loss = 0.05167627\n",
      "Iteration 115, loss = 0.05187863\n",
      "Iteration 116, loss = 0.05187403\n",
      "Iteration 117, loss = 0.05161724\n",
      "Iteration 118, loss = 0.05166706\n",
      "Iteration 119, loss = 0.05124593\n",
      "Iteration 120, loss = 0.05113233\n",
      "Iteration 121, loss = 0.05119804\n",
      "Iteration 122, loss = 0.05115838\n",
      "Iteration 123, loss = 0.05087780\n",
      "Iteration 124, loss = 0.05076003\n",
      "Iteration 125, loss = 0.05058940\n",
      "Iteration 126, loss = 0.05063489\n",
      "Iteration 127, loss = 0.05034409\n",
      "Iteration 128, loss = 0.05052972\n",
      "Iteration 129, loss = 0.04996019\n",
      "Iteration 130, loss = 0.05035281\n",
      "Iteration 131, loss = 0.04989159\n",
      "Iteration 132, loss = 0.04968376\n",
      "Iteration 133, loss = 0.04994048\n",
      "Iteration 134, loss = 0.04988655\n",
      "Iteration 135, loss = 0.04944774\n",
      "Iteration 136, loss = 0.04948656\n",
      "Iteration 137, loss = 0.04926684\n",
      "Iteration 138, loss = 0.04941892\n",
      "Iteration 139, loss = 0.04906904\n",
      "Iteration 140, loss = 0.04932415\n",
      "Iteration 141, loss = 0.04896068\n",
      "Iteration 142, loss = 0.04913066\n",
      "Iteration 143, loss = 0.04882444\n",
      "Iteration 144, loss = 0.04875337\n",
      "Iteration 145, loss = 0.04852536\n",
      "Iteration 146, loss = 0.04844621\n",
      "Iteration 147, loss = 0.04830292\n",
      "Iteration 148, loss = 0.04843558\n",
      "Iteration 149, loss = 0.04826040\n",
      "Iteration 150, loss = 0.04820572\n",
      "Iteration 151, loss = 0.04822010\n",
      "Iteration 152, loss = 0.04815459\n",
      "Iteration 153, loss = 0.04781490\n",
      "Iteration 154, loss = 0.04781871\n",
      "Iteration 155, loss = 0.04757329\n",
      "Iteration 156, loss = 0.04801253\n",
      "Iteration 157, loss = 0.04770884\n",
      "Iteration 158, loss = 0.04762385\n",
      "Iteration 159, loss = 0.04756998\n",
      "Iteration 160, loss = 0.04728459\n",
      "Iteration 161, loss = 0.04744145\n",
      "Iteration 162, loss = 0.04735089\n",
      "Iteration 163, loss = 0.04709993\n",
      "Iteration 164, loss = 0.04710653\n",
      "Iteration 165, loss = 0.04713516\n",
      "Iteration 166, loss = 0.04694004\n",
      "Iteration 167, loss = 0.04691424\n",
      "Iteration 168, loss = 0.04693295\n",
      "Iteration 169, loss = 0.04687503\n",
      "Iteration 170, loss = 0.04651018\n",
      "Iteration 171, loss = 0.04645339\n",
      "Iteration 172, loss = 0.04655980\n",
      "Iteration 173, loss = 0.04638282\n",
      "Iteration 174, loss = 0.04676535\n",
      "Iteration 175, loss = 0.04615079\n",
      "Iteration 176, loss = 0.04615974\n",
      "Iteration 177, loss = 0.04631093\n",
      "Iteration 178, loss = 0.04616726\n",
      "Iteration 179, loss = 0.04590304\n",
      "Iteration 180, loss = 0.04604571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 181, loss = 0.04568633\n",
      "Iteration 182, loss = 0.04596120\n",
      "Iteration 183, loss = 0.04572443\n",
      "Iteration 184, loss = 0.04587603\n",
      "Iteration 185, loss = 0.04544647\n",
      "Iteration 186, loss = 0.04550003\n",
      "Iteration 187, loss = 0.04534592\n",
      "Iteration 188, loss = 0.04544602\n",
      "Iteration 189, loss = 0.04547554\n",
      "Iteration 190, loss = 0.04524254\n",
      "Iteration 191, loss = 0.04527136\n",
      "Iteration 192, loss = 0.04560738\n",
      "Iteration 193, loss = 0.04535178\n",
      "Iteration 194, loss = 0.04506576\n",
      "Iteration 195, loss = 0.04511555\n",
      "Iteration 196, loss = 0.04526189\n",
      "Iteration 197, loss = 0.04524345\n",
      "Iteration 198, loss = 0.04499479\n",
      "Iteration 199, loss = 0.04486725\n",
      "Iteration 200, loss = 0.04467864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.47238940\n",
      "Iteration 2, loss = 0.21001097\n",
      "Iteration 3, loss = 0.14787328\n",
      "Iteration 4, loss = 0.12066279\n",
      "Iteration 5, loss = 0.10810439\n",
      "Iteration 6, loss = 0.10105274\n",
      "Iteration 7, loss = 0.09678899\n",
      "Iteration 8, loss = 0.09386608\n",
      "Iteration 9, loss = 0.09196042\n",
      "Iteration 10, loss = 0.08990587\n",
      "Iteration 11, loss = 0.08866609\n",
      "Iteration 12, loss = 0.08724086\n",
      "Iteration 13, loss = 0.08644593\n",
      "Iteration 14, loss = 0.08542169\n",
      "Iteration 15, loss = 0.08416655\n",
      "Iteration 16, loss = 0.08356750\n",
      "Iteration 17, loss = 0.08268570\n",
      "Iteration 18, loss = 0.08184649\n",
      "Iteration 19, loss = 0.08116569\n",
      "Iteration 20, loss = 0.08047069\n",
      "Iteration 21, loss = 0.07976444\n",
      "Iteration 22, loss = 0.07908286\n",
      "Iteration 23, loss = 0.07865933\n",
      "Iteration 24, loss = 0.07792774\n",
      "Iteration 25, loss = 0.07721950\n",
      "Iteration 26, loss = 0.07673243\n",
      "Iteration 27, loss = 0.07605623\n",
      "Iteration 28, loss = 0.07559370\n",
      "Iteration 29, loss = 0.07507686\n",
      "Iteration 30, loss = 0.07434351\n",
      "Iteration 31, loss = 0.07392282\n",
      "Iteration 32, loss = 0.07361510\n",
      "Iteration 33, loss = 0.07312454\n",
      "Iteration 34, loss = 0.07293189\n",
      "Iteration 35, loss = 0.07271911\n",
      "Iteration 36, loss = 0.07193932\n",
      "Iteration 37, loss = 0.07170968\n",
      "Iteration 38, loss = 0.07154644\n",
      "Iteration 39, loss = 0.07126721\n",
      "Iteration 40, loss = 0.07054994\n",
      "Iteration 41, loss = 0.07049443\n",
      "Iteration 42, loss = 0.06986287\n",
      "Iteration 43, loss = 0.06995480\n",
      "Iteration 44, loss = 0.06949086\n",
      "Iteration 45, loss = 0.06878060\n",
      "Iteration 46, loss = 0.06865303\n",
      "Iteration 47, loss = 0.06815060\n",
      "Iteration 48, loss = 0.06798631\n",
      "Iteration 49, loss = 0.06764252\n",
      "Iteration 50, loss = 0.06761484\n",
      "Iteration 51, loss = 0.06710243\n",
      "Iteration 52, loss = 0.06707861\n",
      "Iteration 53, loss = 0.06644438\n",
      "Iteration 54, loss = 0.06632058\n",
      "Iteration 55, loss = 0.06597901\n",
      "Iteration 56, loss = 0.06584352\n",
      "Iteration 57, loss = 0.06558153\n",
      "Iteration 58, loss = 0.06525874\n",
      "Iteration 59, loss = 0.06471790\n",
      "Iteration 60, loss = 0.06479028\n",
      "Iteration 61, loss = 0.06454401\n",
      "Iteration 62, loss = 0.06409452\n",
      "Iteration 63, loss = 0.06375658\n",
      "Iteration 64, loss = 0.06339965\n",
      "Iteration 65, loss = 0.06354745\n",
      "Iteration 66, loss = 0.06305604\n",
      "Iteration 67, loss = 0.06317125\n",
      "Iteration 68, loss = 0.06253424\n",
      "Iteration 69, loss = 0.06237869\n",
      "Iteration 70, loss = 0.06239864\n",
      "Iteration 71, loss = 0.06192059\n",
      "Iteration 72, loss = 0.06168262\n",
      "Iteration 73, loss = 0.06147154\n",
      "Iteration 74, loss = 0.06128731\n",
      "Iteration 75, loss = 0.06166443\n",
      "Iteration 76, loss = 0.06085559\n",
      "Iteration 77, loss = 0.06061113\n",
      "Iteration 78, loss = 0.06076211\n",
      "Iteration 79, loss = 0.06001905\n",
      "Iteration 80, loss = 0.06048144\n",
      "Iteration 81, loss = 0.05974497\n",
      "Iteration 82, loss = 0.06012440\n",
      "Iteration 83, loss = 0.05939241\n",
      "Iteration 84, loss = 0.05920200\n",
      "Iteration 85, loss = 0.05876809\n",
      "Iteration 86, loss = 0.05872130\n",
      "Iteration 87, loss = 0.05858346\n",
      "Iteration 88, loss = 0.05840265\n",
      "Iteration 89, loss = 0.05841069\n",
      "Iteration 90, loss = 0.05821800\n",
      "Iteration 91, loss = 0.05784009\n",
      "Iteration 92, loss = 0.05780576\n",
      "Iteration 93, loss = 0.05760167\n",
      "Iteration 94, loss = 0.05776707\n",
      "Iteration 95, loss = 0.05755458\n",
      "Iteration 96, loss = 0.05701307\n",
      "Iteration 97, loss = 0.05683308\n",
      "Iteration 98, loss = 0.05667149\n",
      "Iteration 99, loss = 0.05663468\n",
      "Iteration 100, loss = 0.05634456\n",
      "Iteration 101, loss = 0.05612562\n",
      "Iteration 102, loss = 0.05601930\n",
      "Iteration 103, loss = 0.05569483\n",
      "Iteration 104, loss = 0.05586415\n",
      "Iteration 105, loss = 0.05579871\n",
      "Iteration 106, loss = 0.05546855\n",
      "Iteration 107, loss = 0.05509653\n",
      "Iteration 108, loss = 0.05502156\n",
      "Iteration 109, loss = 0.05473490\n",
      "Iteration 110, loss = 0.05453589\n",
      "Iteration 111, loss = 0.05430497\n",
      "Iteration 112, loss = 0.05476342\n",
      "Iteration 113, loss = 0.05422038\n",
      "Iteration 114, loss = 0.05421682\n",
      "Iteration 115, loss = 0.05427822\n",
      "Iteration 116, loss = 0.05405097\n",
      "Iteration 117, loss = 0.05386203\n",
      "Iteration 118, loss = 0.05358370\n",
      "Iteration 119, loss = 0.05337622\n",
      "Iteration 120, loss = 0.05346407\n",
      "Iteration 121, loss = 0.05320228\n",
      "Iteration 122, loss = 0.05294078\n",
      "Iteration 123, loss = 0.05276256\n",
      "Iteration 124, loss = 0.05303862\n",
      "Iteration 125, loss = 0.05243405\n",
      "Iteration 126, loss = 0.05241019\n",
      "Iteration 127, loss = 0.05201832\n",
      "Iteration 128, loss = 0.05201545\n",
      "Iteration 129, loss = 0.05238473\n",
      "Iteration 130, loss = 0.05225771\n",
      "Iteration 131, loss = 0.05170292\n",
      "Iteration 132, loss = 0.05185496\n",
      "Iteration 133, loss = 0.05152690\n",
      "Iteration 134, loss = 0.05128510\n",
      "Iteration 135, loss = 0.05141815\n",
      "Iteration 136, loss = 0.05136780\n",
      "Iteration 137, loss = 0.05118339\n",
      "Iteration 138, loss = 0.05095952\n",
      "Iteration 139, loss = 0.05097057\n",
      "Iteration 140, loss = 0.05084253\n",
      "Iteration 141, loss = 0.05092647\n",
      "Iteration 142, loss = 0.05050981\n",
      "Iteration 143, loss = 0.05066827\n",
      "Iteration 144, loss = 0.05051036\n",
      "Iteration 145, loss = 0.05018644\n",
      "Iteration 146, loss = 0.05033954\n",
      "Iteration 147, loss = 0.04989125\n",
      "Iteration 148, loss = 0.04988212\n",
      "Iteration 149, loss = 0.04989126\n",
      "Iteration 150, loss = 0.04985387\n",
      "Iteration 151, loss = 0.04982594\n",
      "Iteration 152, loss = 0.04958644\n",
      "Iteration 153, loss = 0.04954585\n",
      "Iteration 154, loss = 0.04931010\n",
      "Iteration 155, loss = 0.04952975\n",
      "Iteration 156, loss = 0.04960247\n",
      "Iteration 157, loss = 0.04926659\n",
      "Iteration 158, loss = 0.04936043\n",
      "Iteration 159, loss = 0.04880834\n",
      "Iteration 160, loss = 0.04878607\n",
      "Iteration 161, loss = 0.04848463\n",
      "Iteration 162, loss = 0.04868614\n",
      "Iteration 163, loss = 0.04882982\n",
      "Iteration 164, loss = 0.04868648\n",
      "Iteration 165, loss = 0.04853371\n",
      "Iteration 166, loss = 0.04839128\n",
      "Iteration 167, loss = 0.04817840\n",
      "Iteration 168, loss = 0.04828294\n",
      "Iteration 169, loss = 0.04826270\n",
      "Iteration 170, loss = 0.04828716\n",
      "Iteration 171, loss = 0.04773706\n",
      "Iteration 172, loss = 0.04803064\n",
      "Iteration 173, loss = 0.04770473\n",
      "Iteration 174, loss = 0.04759117\n",
      "Iteration 175, loss = 0.04755279\n",
      "Iteration 176, loss = 0.04801639\n",
      "Iteration 177, loss = 0.04730477\n",
      "Iteration 178, loss = 0.04731255\n",
      "Iteration 179, loss = 0.04731609\n",
      "Iteration 180, loss = 0.04730880\n",
      "Iteration 181, loss = 0.04694844\n",
      "Iteration 182, loss = 0.04726633\n",
      "Iteration 183, loss = 0.04692334\n",
      "Iteration 184, loss = 0.04675918\n",
      "Iteration 185, loss = 0.04702731\n",
      "Iteration 186, loss = 0.04675265\n",
      "Iteration 187, loss = 0.04653377\n",
      "Iteration 188, loss = 0.04673498\n",
      "Iteration 189, loss = 0.04655207\n",
      "Iteration 190, loss = 0.04684836\n",
      "Iteration 191, loss = 0.04622791\n",
      "Iteration 192, loss = 0.04625253\n",
      "Iteration 193, loss = 0.04629021\n",
      "Iteration 194, loss = 0.04593025\n",
      "Iteration 195, loss = 0.04584423\n",
      "Iteration 196, loss = 0.04584724\n",
      "Iteration 197, loss = 0.04597932\n",
      "Iteration 198, loss = 0.04552957\n",
      "Iteration 199, loss = 0.04577904\n",
      "Iteration 200, loss = 0.04571487\n",
      "Iteration 1, loss = 0.46986494"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 2, loss = 0.23577348\n",
      "Iteration 3, loss = 0.16369729\n",
      "Iteration 4, loss = 0.12849205\n",
      "Iteration 5, loss = 0.11247070\n",
      "Iteration 6, loss = 0.10429430\n",
      "Iteration 7, loss = 0.09940129\n",
      "Iteration 8, loss = 0.09604110\n",
      "Iteration 9, loss = 0.09365330\n",
      "Iteration 10, loss = 0.09160672\n",
      "Iteration 11, loss = 0.08986262\n",
      "Iteration 12, loss = 0.08866028\n",
      "Iteration 13, loss = 0.08736489\n",
      "Iteration 14, loss = 0.08605855\n",
      "Iteration 15, loss = 0.08502279\n",
      "Iteration 16, loss = 0.08447469\n",
      "Iteration 17, loss = 0.08328973\n",
      "Iteration 18, loss = 0.08245556\n",
      "Iteration 19, loss = 0.08170338\n",
      "Iteration 20, loss = 0.08110266\n",
      "Iteration 21, loss = 0.08029581\n",
      "Iteration 22, loss = 0.07971889\n",
      "Iteration 23, loss = 0.07912452\n",
      "Iteration 24, loss = 0.07873490\n",
      "Iteration 25, loss = 0.07811693\n",
      "Iteration 26, loss = 0.07707380\n",
      "Iteration 27, loss = 0.07666290\n",
      "Iteration 28, loss = 0.07638212\n",
      "Iteration 29, loss = 0.07570862\n",
      "Iteration 30, loss = 0.07517277\n",
      "Iteration 31, loss = 0.07485060\n",
      "Iteration 32, loss = 0.07430633\n",
      "Iteration 33, loss = 0.07379855\n",
      "Iteration 34, loss = 0.07325612\n",
      "Iteration 35, loss = 0.07277158\n",
      "Iteration 36, loss = 0.07229352\n",
      "Iteration 37, loss = 0.07189349\n",
      "Iteration 38, loss = 0.07165005\n",
      "Iteration 39, loss = 0.07118722\n",
      "Iteration 40, loss = 0.07084604\n",
      "Iteration 41, loss = 0.07000539\n",
      "Iteration 42, loss = 0.06978115\n",
      "Iteration 43, loss = 0.06944131\n",
      "Iteration 44, loss = 0.06910740\n",
      "Iteration 45, loss = 0.06849864\n",
      "Iteration 46, loss = 0.06835941\n",
      "Iteration 47, loss = 0.06802910\n",
      "Iteration 48, loss = 0.06772977\n",
      "Iteration 49, loss = 0.06753548\n",
      "Iteration 50, loss = 0.06685516\n",
      "Iteration 51, loss = 0.06678319\n",
      "Iteration 52, loss = 0.06624379\n",
      "Iteration 53, loss = 0.06615601\n",
      "Iteration 54, loss = 0.06581122\n",
      "Iteration 55, loss = 0.06563039\n",
      "Iteration 56, loss = 0.06557257\n",
      "Iteration 57, loss = 0.06506838\n",
      "Iteration 58, loss = 0.06466550\n",
      "Iteration 59, loss = 0.06475720\n",
      "Iteration 60, loss = 0.06446573\n",
      "Iteration 61, loss = 0.06422114\n",
      "Iteration 62, loss = 0.06390728\n",
      "Iteration 63, loss = 0.06348588\n",
      "Iteration 64, loss = 0.06358954\n",
      "Iteration 65, loss = 0.06337505\n",
      "Iteration 66, loss = 0.06304136\n",
      "Iteration 67, loss = 0.06263729\n",
      "Iteration 68, loss = 0.06251902\n",
      "Iteration 69, loss = 0.06225103\n",
      "Iteration 70, loss = 0.06207313\n",
      "Iteration 71, loss = 0.06214040\n",
      "Iteration 72, loss = 0.06193092\n",
      "Iteration 73, loss = 0.06169345\n",
      "Iteration 74, loss = 0.06163162\n",
      "Iteration 75, loss = 0.06114545\n",
      "Iteration 76, loss = 0.06075936\n",
      "Iteration 77, loss = 0.06071083\n",
      "Iteration 78, loss = 0.06064729\n",
      "Iteration 79, loss = 0.06049936\n",
      "Iteration 80, loss = 0.06034780\n",
      "Iteration 81, loss = 0.06007077\n",
      "Iteration 82, loss = 0.06023194\n",
      "Iteration 83, loss = 0.05989633\n",
      "Iteration 84, loss = 0.05966195\n",
      "Iteration 85, loss = 0.05966852\n",
      "Iteration 86, loss = 0.05940930\n",
      "Iteration 87, loss = 0.05931666\n",
      "Iteration 88, loss = 0.05910975\n",
      "Iteration 89, loss = 0.05889465\n",
      "Iteration 90, loss = 0.05862023\n",
      "Iteration 91, loss = 0.05874090\n",
      "Iteration 92, loss = 0.05828682\n",
      "Iteration 93, loss = 0.05872851\n",
      "Iteration 94, loss = 0.05802960\n",
      "Iteration 95, loss = 0.05792873\n",
      "Iteration 96, loss = 0.05781026\n",
      "Iteration 97, loss = 0.05773836\n",
      "Iteration 98, loss = 0.05759889\n",
      "Iteration 99, loss = 0.05750898\n",
      "Iteration 100, loss = 0.05732710\n",
      "Iteration 101, loss = 0.05733410\n",
      "Iteration 102, loss = 0.05696840\n",
      "Iteration 103, loss = 0.05704967\n",
      "Iteration 104, loss = 0.05715545\n",
      "Iteration 105, loss = 0.05701302\n",
      "Iteration 106, loss = 0.05656888\n",
      "Iteration 107, loss = 0.05639352\n",
      "Iteration 108, loss = 0.05651521\n",
      "Iteration 109, loss = 0.05682665\n",
      "Iteration 110, loss = 0.05617131\n",
      "Iteration 111, loss = 0.05597356\n",
      "Iteration 112, loss = 0.05578824\n",
      "Iteration 113, loss = 0.05553568\n",
      "Iteration 114, loss = 0.05562970\n",
      "Iteration 115, loss = 0.05580937\n",
      "Iteration 116, loss = 0.05541202\n",
      "Iteration 117, loss = 0.05529829\n",
      "Iteration 118, loss = 0.05531820\n",
      "Iteration 119, loss = 0.05547504\n",
      "Iteration 120, loss = 0.05517736\n",
      "Iteration 121, loss = 0.05504970\n",
      "Iteration 122, loss = 0.05468107\n",
      "Iteration 123, loss = 0.05473129\n",
      "Iteration 124, loss = 0.05442282\n",
      "Iteration 125, loss = 0.05447057\n",
      "Iteration 126, loss = 0.05453441\n",
      "Iteration 127, loss = 0.05443191\n",
      "Iteration 128, loss = 0.05403401\n",
      "Iteration 129, loss = 0.05399763\n",
      "Iteration 130, loss = 0.05385545\n",
      "Iteration 131, loss = 0.05382444\n",
      "Iteration 132, loss = 0.05380217\n",
      "Iteration 133, loss = 0.05365273\n",
      "Iteration 134, loss = 0.05370945\n",
      "Iteration 135, loss = 0.05334787\n",
      "Iteration 136, loss = 0.05334392\n",
      "Iteration 137, loss = 0.05366018\n",
      "Iteration 138, loss = 0.05328510\n",
      "Iteration 139, loss = 0.05315716\n",
      "Iteration 140, loss = 0.05325275\n",
      "Iteration 141, loss = 0.05308674\n",
      "Iteration 142, loss = 0.05289584\n",
      "Iteration 143, loss = 0.05300899\n",
      "Iteration 144, loss = 0.05279009\n",
      "Iteration 145, loss = 0.05244158\n",
      "Iteration 146, loss = 0.05233999\n",
      "Iteration 147, loss = 0.05276126\n",
      "Iteration 148, loss = 0.05223248\n",
      "Iteration 149, loss = 0.05219054\n",
      "Iteration 150, loss = 0.05214817\n",
      "Iteration 151, loss = 0.05190057\n",
      "Iteration 152, loss = 0.05223139\n",
      "Iteration 153, loss = 0.05192260\n",
      "Iteration 154, loss = 0.05177433\n",
      "Iteration 155, loss = 0.05174856\n",
      "Iteration 156, loss = 0.05166109\n",
      "Iteration 157, loss = 0.05174994\n",
      "Iteration 158, loss = 0.05163548\n",
      "Iteration 159, loss = 0.05135487\n",
      "Iteration 160, loss = 0.05132257\n",
      "Iteration 161, loss = 0.05141420\n",
      "Iteration 162, loss = 0.05089176\n",
      "Iteration 163, loss = 0.05114353\n",
      "Iteration 164, loss = 0.05086522\n",
      "Iteration 165, loss = 0.05103783\n",
      "Iteration 166, loss = 0.05064440\n",
      "Iteration 167, loss = 0.05086937\n",
      "Iteration 168, loss = 0.05050334\n",
      "Iteration 169, loss = 0.05082425\n",
      "Iteration 170, loss = 0.05041961\n",
      "Iteration 171, loss = 0.05029659\n",
      "Iteration 172, loss = 0.05040064\n",
      "Iteration 173, loss = 0.05055197\n",
      "Iteration 174, loss = 0.05013009\n",
      "Iteration 175, loss = 0.05046103\n",
      "Iteration 176, loss = 0.05002991\n",
      "Iteration 177, loss = 0.04983497\n",
      "Iteration 178, loss = 0.04997132\n",
      "Iteration 179, loss = 0.04952205\n",
      "Iteration 180, loss = 0.04964755\n",
      "Iteration 181, loss = 0.04988358\n",
      "Iteration 182, loss = 0.04970168\n",
      "Iteration 183, loss = 0.04948464\n",
      "Iteration 184, loss = 0.04970185\n",
      "Iteration 185, loss = 0.04916376\n",
      "Iteration 186, loss = 0.04932853\n",
      "Iteration 187, loss = 0.04927903\n",
      "Iteration 188, loss = 0.04901332\n",
      "Iteration 189, loss = 0.04915005\n",
      "Iteration 190, loss = 0.04918862\n",
      "Iteration 191, loss = 0.04916597\n",
      "Iteration 192, loss = 0.04898105\n",
      "Iteration 193, loss = 0.04877807\n",
      "Iteration 194, loss = 0.04876926\n",
      "Iteration 195, loss = 0.04871854\n",
      "Iteration 196, loss = 0.04896910\n",
      "Iteration 197, loss = 0.04861774\n",
      "Iteration 198, loss = 0.04834700\n",
      "Iteration 199, loss = 0.04837706\n",
      "Iteration 200, loss = 0.04868259\n",
      "Iteration 1, loss = 0.44057983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.22661942\n",
      "Iteration 3, loss = 0.16131667\n",
      "Iteration 4, loss = 0.12782436\n",
      "Iteration 5, loss = 0.11159797\n",
      "Iteration 6, loss = 0.10298861\n",
      "Iteration 7, loss = 0.09801251\n",
      "Iteration 8, loss = 0.09452959\n",
      "Iteration 9, loss = 0.09185050\n",
      "Iteration 10, loss = 0.08974080\n",
      "Iteration 11, loss = 0.08793595\n",
      "Iteration 12, loss = 0.08658505\n",
      "Iteration 13, loss = 0.08513319\n",
      "Iteration 14, loss = 0.08386584\n",
      "Iteration 15, loss = 0.08260207\n",
      "Iteration 16, loss = 0.08171091\n",
      "Iteration 17, loss = 0.08067843\n",
      "Iteration 18, loss = 0.07958121\n",
      "Iteration 19, loss = 0.07879825\n",
      "Iteration 20, loss = 0.07807200\n",
      "Iteration 21, loss = 0.07717324\n",
      "Iteration 22, loss = 0.07657620\n",
      "Iteration 23, loss = 0.07566367\n",
      "Iteration 24, loss = 0.07506852\n",
      "Iteration 25, loss = 0.07420620\n",
      "Iteration 26, loss = 0.07375193\n",
      "Iteration 27, loss = 0.07292127\n",
      "Iteration 28, loss = 0.07267968\n",
      "Iteration 29, loss = 0.07155571\n",
      "Iteration 30, loss = 0.07163140\n",
      "Iteration 31, loss = 0.07077698\n",
      "Iteration 32, loss = 0.07020831\n",
      "Iteration 33, loss = 0.06983831\n",
      "Iteration 34, loss = 0.06924526\n",
      "Iteration 35, loss = 0.06870007\n",
      "Iteration 36, loss = 0.06821598\n",
      "Iteration 37, loss = 0.06807494\n",
      "Iteration 38, loss = 0.06735569\n",
      "Iteration 39, loss = 0.06677459\n",
      "Iteration 40, loss = 0.06676571\n",
      "Iteration 41, loss = 0.06632919\n",
      "Iteration 42, loss = 0.06585593\n",
      "Iteration 43, loss = 0.06539815\n",
      "Iteration 44, loss = 0.06509842\n",
      "Iteration 45, loss = 0.06473696\n",
      "Iteration 46, loss = 0.06445642\n",
      "Iteration 47, loss = 0.06393659\n",
      "Iteration 48, loss = 0.06343707\n",
      "Iteration 49, loss = 0.06342367\n",
      "Iteration 50, loss = 0.06297385\n",
      "Iteration 51, loss = 0.06271900\n",
      "Iteration 52, loss = 0.06246391\n",
      "Iteration 53, loss = 0.06200444\n",
      "Iteration 54, loss = 0.06176026\n",
      "Iteration 55, loss = 0.06140256\n",
      "Iteration 56, loss = 0.06124571\n",
      "Iteration 57, loss = 0.06079742\n",
      "Iteration 58, loss = 0.06062088\n",
      "Iteration 59, loss = 0.06024309\n",
      "Iteration 60, loss = 0.06015740\n",
      "Iteration 61, loss = 0.06004677\n",
      "Iteration 62, loss = 0.05949685\n",
      "Iteration 63, loss = 0.05945129\n",
      "Iteration 64, loss = 0.05915627\n",
      "Iteration 65, loss = 0.05940741\n",
      "Iteration 66, loss = 0.05873191\n",
      "Iteration 67, loss = 0.05861727\n",
      "Iteration 68, loss = 0.05820350\n",
      "Iteration 69, loss = 0.05817424\n",
      "Iteration 70, loss = 0.05808339\n",
      "Iteration 71, loss = 0.05744562\n",
      "Iteration 72, loss = 0.05738954\n",
      "Iteration 73, loss = 0.05706404\n",
      "Iteration 74, loss = 0.05665466\n",
      "Iteration 75, loss = 0.05672279\n",
      "Iteration 76, loss = 0.05653328\n",
      "Iteration 77, loss = 0.05637396\n",
      "Iteration 78, loss = 0.05596652\n",
      "Iteration 79, loss = 0.05588678\n",
      "Iteration 80, loss = 0.05527290\n",
      "Iteration 81, loss = 0.05539535\n",
      "Iteration 82, loss = 0.05501624\n",
      "Iteration 83, loss = 0.05503613\n",
      "Iteration 84, loss = 0.05483277\n",
      "Iteration 85, loss = 0.05458091\n",
      "Iteration 86, loss = 0.05441135\n",
      "Iteration 87, loss = 0.05443313\n",
      "Iteration 88, loss = 0.05406815\n",
      "Iteration 89, loss = 0.05384904\n",
      "Iteration 90, loss = 0.05361468\n",
      "Iteration 91, loss = 0.05332328\n",
      "Iteration 92, loss = 0.05320685\n",
      "Iteration 93, loss = 0.05315253\n",
      "Iteration 94, loss = 0.05273996\n",
      "Iteration 95, loss = 0.05274064\n",
      "Iteration 96, loss = 0.05255838\n",
      "Iteration 97, loss = 0.05251557\n",
      "Iteration 98, loss = 0.05258205\n",
      "Iteration 99, loss = 0.05211595\n",
      "Iteration 100, loss = 0.05228881\n",
      "Iteration 101, loss = 0.05213914\n",
      "Iteration 102, loss = 0.05180919\n",
      "Iteration 103, loss = 0.05155468\n",
      "Iteration 104, loss = 0.05168758\n",
      "Iteration 105, loss = 0.05175777\n",
      "Iteration 106, loss = 0.05118831\n",
      "Iteration 107, loss = 0.05149435\n",
      "Iteration 108, loss = 0.05113811\n",
      "Iteration 109, loss = 0.05096044\n",
      "Iteration 110, loss = 0.05079783\n",
      "Iteration 111, loss = 0.05044577\n",
      "Iteration 112, loss = 0.05079851\n",
      "Iteration 113, loss = 0.05036133\n",
      "Iteration 114, loss = 0.05019930\n",
      "Iteration 115, loss = 0.05019755\n",
      "Iteration 116, loss = 0.05003850\n",
      "Iteration 117, loss = 0.04982781\n",
      "Iteration 118, loss = 0.04959401\n",
      "Iteration 119, loss = 0.04957790\n",
      "Iteration 120, loss = 0.04942932\n",
      "Iteration 121, loss = 0.04934114\n",
      "Iteration 122, loss = 0.04910684\n",
      "Iteration 123, loss = 0.04892123\n",
      "Iteration 124, loss = 0.04895207\n",
      "Iteration 125, loss = 0.04876981\n",
      "Iteration 126, loss = 0.04859819\n",
      "Iteration 127, loss = 0.04858314\n",
      "Iteration 128, loss = 0.04827890\n",
      "Iteration 129, loss = 0.04810862\n",
      "Iteration 130, loss = 0.04807307\n",
      "Iteration 131, loss = 0.04805136\n",
      "Iteration 132, loss = 0.04771945\n",
      "Iteration 133, loss = 0.04764561\n",
      "Iteration 134, loss = 0.04767838\n",
      "Iteration 135, loss = 0.04757449\n",
      "Iteration 136, loss = 0.04749007\n",
      "Iteration 137, loss = 0.04743755\n",
      "Iteration 138, loss = 0.04735679\n",
      "Iteration 139, loss = 0.04696081\n",
      "Iteration 140, loss = 0.04707930\n",
      "Iteration 141, loss = 0.04682093\n",
      "Iteration 142, loss = 0.04654198\n",
      "Iteration 143, loss = 0.04670514\n",
      "Iteration 144, loss = 0.04658506\n",
      "Iteration 145, loss = 0.04670449\n",
      "Iteration 146, loss = 0.04627742\n",
      "Iteration 147, loss = 0.04654448\n",
      "Iteration 148, loss = 0.04612289\n",
      "Iteration 149, loss = 0.04606708\n",
      "Iteration 150, loss = 0.04566224\n",
      "Iteration 151, loss = 0.04572443\n",
      "Iteration 152, loss = 0.04595689\n",
      "Iteration 153, loss = 0.04567506\n",
      "Iteration 154, loss = 0.04558512\n",
      "Iteration 155, loss = 0.04565601\n",
      "Iteration 156, loss = 0.04532194\n",
      "Iteration 157, loss = 0.04497286\n",
      "Iteration 158, loss = 0.04544425\n",
      "Iteration 159, loss = 0.04508167\n",
      "Iteration 160, loss = 0.04516486\n",
      "Iteration 161, loss = 0.04491416\n",
      "Iteration 162, loss = 0.04522095\n",
      "Iteration 163, loss = 0.04459769\n",
      "Iteration 164, loss = 0.04439111\n",
      "Iteration 165, loss = 0.04455277\n",
      "Iteration 166, loss = 0.04441417\n",
      "Iteration 167, loss = 0.04468901\n",
      "Iteration 168, loss = 0.04430582\n",
      "Iteration 169, loss = 0.04424808\n",
      "Iteration 170, loss = 0.04434576\n",
      "Iteration 171, loss = 0.04430408\n",
      "Iteration 172, loss = 0.04408588\n",
      "Iteration 173, loss = 0.04374713\n",
      "Iteration 174, loss = 0.04385663\n",
      "Iteration 175, loss = 0.04395998\n",
      "Iteration 176, loss = 0.04381635\n",
      "Iteration 177, loss = 0.04372192\n",
      "Iteration 178, loss = 0.04379774\n",
      "Iteration 179, loss = 0.04353413\n",
      "Iteration 180, loss = 0.04329778\n",
      "Iteration 181, loss = 0.04353281\n",
      "Iteration 182, loss = 0.04324473\n",
      "Iteration 183, loss = 0.04353125\n",
      "Iteration 184, loss = 0.04317783\n",
      "Iteration 185, loss = 0.04346856\n",
      "Iteration 186, loss = 0.04314482\n",
      "Iteration 187, loss = 0.04299384\n",
      "Iteration 188, loss = 0.04285682\n",
      "Iteration 189, loss = 0.04277255\n",
      "Iteration 190, loss = 0.04273091\n",
      "Iteration 191, loss = 0.04277626\n",
      "Iteration 192, loss = 0.04316434\n",
      "Iteration 193, loss = 0.04243175\n",
      "Iteration 194, loss = 0.04239058\n",
      "Iteration 195, loss = 0.04238038\n",
      "Iteration 196, loss = 0.04251684\n",
      "Iteration 197, loss = 0.04221368\n",
      "Iteration 198, loss = 0.04260599\n",
      "Iteration 199, loss = 0.04236943\n",
      "Iteration 200, loss = 0.04218791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.34378965\n",
      "Iteration 2, loss = 0.18235037\n",
      "Iteration 3, loss = 0.13653124\n",
      "Iteration 4, loss = 0.11634753\n",
      "Iteration 5, loss = 0.10666203\n",
      "Iteration 6, loss = 0.10110105\n",
      "Iteration 7, loss = 0.09739567\n",
      "Iteration 8, loss = 0.09457620\n",
      "Iteration 9, loss = 0.09251103\n",
      "Iteration 10, loss = 0.09054581\n",
      "Iteration 11, loss = 0.08909052\n",
      "Iteration 12, loss = 0.08784565\n",
      "Iteration 13, loss = 0.08671204\n",
      "Iteration 14, loss = 0.08529699\n",
      "Iteration 15, loss = 0.08429899\n",
      "Iteration 16, loss = 0.08292749\n",
      "Iteration 17, loss = 0.08251586\n",
      "Iteration 18, loss = 0.08140570\n",
      "Iteration 19, loss = 0.08051572\n",
      "Iteration 20, loss = 0.07990736\n",
      "Iteration 21, loss = 0.07921593\n",
      "Iteration 22, loss = 0.07852573\n",
      "Iteration 23, loss = 0.07764788\n",
      "Iteration 24, loss = 0.07703029\n",
      "Iteration 25, loss = 0.07642426\n",
      "Iteration 26, loss = 0.07593811\n",
      "Iteration 27, loss = 0.07512393\n",
      "Iteration 28, loss = 0.07480903\n",
      "Iteration 29, loss = 0.07409567\n",
      "Iteration 30, loss = 0.07369346\n",
      "Iteration 31, loss = 0.07326388\n",
      "Iteration 32, loss = 0.07268761\n",
      "Iteration 33, loss = 0.07222318\n",
      "Iteration 34, loss = 0.07167380\n",
      "Iteration 35, loss = 0.07157573\n",
      "Iteration 36, loss = 0.07063352\n",
      "Iteration 37, loss = 0.07043576\n",
      "Iteration 38, loss = 0.06982951\n",
      "Iteration 39, loss = 0.06950555\n",
      "Iteration 40, loss = 0.06895537\n",
      "Iteration 41, loss = 0.06883784\n",
      "Iteration 42, loss = 0.06833926\n",
      "Iteration 43, loss = 0.06800431\n",
      "Iteration 44, loss = 0.06765633\n",
      "Iteration 45, loss = 0.06748491\n",
      "Iteration 46, loss = 0.06690527\n",
      "Iteration 47, loss = 0.06650539\n",
      "Iteration 48, loss = 0.06641087\n",
      "Iteration 49, loss = 0.06636239\n",
      "Iteration 50, loss = 0.06562436\n",
      "Iteration 51, loss = 0.06500328\n",
      "Iteration 52, loss = 0.06529801\n",
      "Iteration 53, loss = 0.06485262\n",
      "Iteration 54, loss = 0.06465291\n",
      "Iteration 55, loss = 0.06410637\n",
      "Iteration 56, loss = 0.06400767\n",
      "Iteration 57, loss = 0.06379651\n",
      "Iteration 58, loss = 0.06358184\n",
      "Iteration 59, loss = 0.06338590\n",
      "Iteration 60, loss = 0.06313047\n",
      "Iteration 61, loss = 0.06288411\n",
      "Iteration 62, loss = 0.06271371\n",
      "Iteration 63, loss = 0.06258330\n",
      "Iteration 64, loss = 0.06213491\n",
      "Iteration 65, loss = 0.06173470\n",
      "Iteration 66, loss = 0.06179738\n",
      "Iteration 67, loss = 0.06142155\n",
      "Iteration 68, loss = 0.06150854\n",
      "Iteration 69, loss = 0.06103290\n",
      "Iteration 70, loss = 0.06082542\n",
      "Iteration 71, loss = 0.06085857\n",
      "Iteration 72, loss = 0.06025110\n",
      "Iteration 73, loss = 0.06011007\n",
      "Iteration 74, loss = 0.05982625\n",
      "Iteration 75, loss = 0.06032468\n",
      "Iteration 76, loss = 0.05951297\n",
      "Iteration 77, loss = 0.05973631\n",
      "Iteration 78, loss = 0.05951972\n",
      "Iteration 79, loss = 0.05927376\n",
      "Iteration 80, loss = 0.05916993\n",
      "Iteration 81, loss = 0.05867802\n",
      "Iteration 82, loss = 0.05873187\n",
      "Iteration 83, loss = 0.05829861\n",
      "Iteration 84, loss = 0.05824353\n",
      "Iteration 85, loss = 0.05808275\n",
      "Iteration 86, loss = 0.05836504\n",
      "Iteration 87, loss = 0.05776533\n",
      "Iteration 88, loss = 0.05768082\n",
      "Iteration 89, loss = 0.05775943\n",
      "Iteration 90, loss = 0.05741035\n",
      "Iteration 91, loss = 0.05718783\n",
      "Iteration 92, loss = 0.05704992\n",
      "Iteration 93, loss = 0.05687312\n",
      "Iteration 94, loss = 0.05691398\n",
      "Iteration 95, loss = 0.05662393\n",
      "Iteration 96, loss = 0.05662103\n",
      "Iteration 97, loss = 0.05635032\n",
      "Iteration 98, loss = 0.05614445\n",
      "Iteration 99, loss = 0.05582419\n",
      "Iteration 100, loss = 0.05558164\n",
      "Iteration 101, loss = 0.05561549\n",
      "Iteration 102, loss = 0.05548247\n",
      "Iteration 103, loss = 0.05533736\n",
      "Iteration 104, loss = 0.05517567\n",
      "Iteration 105, loss = 0.05515787\n",
      "Iteration 106, loss = 0.05500354\n",
      "Iteration 107, loss = 0.05450915\n",
      "Iteration 108, loss = 0.05462786\n",
      "Iteration 109, loss = 0.05458533\n",
      "Iteration 110, loss = 0.05434949\n",
      "Iteration 111, loss = 0.05431508\n",
      "Iteration 112, loss = 0.05423437\n",
      "Iteration 113, loss = 0.05394840\n",
      "Iteration 114, loss = 0.05380870\n",
      "Iteration 115, loss = 0.05388667\n",
      "Iteration 116, loss = 0.05353950\n",
      "Iteration 117, loss = 0.05358677\n",
      "Iteration 118, loss = 0.05342131\n",
      "Iteration 119, loss = 0.05314113\n",
      "Iteration 120, loss = 0.05305220\n",
      "Iteration 121, loss = 0.05300002\n",
      "Iteration 122, loss = 0.05277846\n",
      "Iteration 123, loss = 0.05284770\n",
      "Iteration 124, loss = 0.05274409\n",
      "Iteration 125, loss = 0.05266018\n",
      "Iteration 126, loss = 0.05256584\n",
      "Iteration 127, loss = 0.05215974\n",
      "Iteration 128, loss = 0.05218059\n",
      "Iteration 129, loss = 0.05210968\n",
      "Iteration 130, loss = 0.05212522\n",
      "Iteration 131, loss = 0.05184693\n",
      "Iteration 132, loss = 0.05196877\n",
      "Iteration 133, loss = 0.05157612\n",
      "Iteration 134, loss = 0.05143600\n",
      "Iteration 135, loss = 0.05157911\n",
      "Iteration 136, loss = 0.05124560\n",
      "Iteration 137, loss = 0.05087781\n",
      "Iteration 138, loss = 0.05108962\n",
      "Iteration 139, loss = 0.05118655\n",
      "Iteration 140, loss = 0.05077573\n",
      "Iteration 141, loss = 0.05089767\n",
      "Iteration 142, loss = 0.05084032\n",
      "Iteration 143, loss = 0.05038324\n",
      "Iteration 144, loss = 0.05052752\n",
      "Iteration 145, loss = 0.05039415\n",
      "Iteration 146, loss = 0.05052858\n",
      "Iteration 147, loss = 0.04996067\n",
      "Iteration 148, loss = 0.05038451\n",
      "Iteration 149, loss = 0.04997685\n",
      "Iteration 150, loss = 0.04972284\n",
      "Iteration 151, loss = 0.04981080\n",
      "Iteration 152, loss = 0.04976109\n",
      "Iteration 153, loss = 0.04971640\n",
      "Iteration 154, loss = 0.04970109\n",
      "Iteration 155, loss = 0.04914773\n",
      "Iteration 156, loss = 0.04955977\n",
      "Iteration 157, loss = 0.04902322\n",
      "Iteration 158, loss = 0.04891266\n",
      "Iteration 159, loss = 0.04919106\n",
      "Iteration 160, loss = 0.04889843\n",
      "Iteration 161, loss = 0.04856623\n",
      "Iteration 162, loss = 0.04875552\n",
      "Iteration 163, loss = 0.04843443\n",
      "Iteration 164, loss = 0.04834802\n",
      "Iteration 165, loss = 0.04844812\n",
      "Iteration 166, loss = 0.04849321\n",
      "Iteration 167, loss = 0.04794367\n",
      "Iteration 168, loss = 0.04787852\n",
      "Iteration 169, loss = 0.04790075\n",
      "Iteration 170, loss = 0.04767479\n",
      "Iteration 171, loss = 0.04768478\n",
      "Iteration 172, loss = 0.04740686\n",
      "Iteration 173, loss = 0.04736900\n",
      "Iteration 174, loss = 0.04737468\n",
      "Iteration 175, loss = 0.04721074\n",
      "Iteration 176, loss = 0.04702354\n",
      "Iteration 177, loss = 0.04682360\n",
      "Iteration 178, loss = 0.04683859\n",
      "Iteration 179, loss = 0.04645818\n",
      "Iteration 180, loss = 0.04654526\n",
      "Iteration 181, loss = 0.04630628\n",
      "Iteration 182, loss = 0.04661795\n",
      "Iteration 183, loss = 0.04604877\n",
      "Iteration 184, loss = 0.04603964\n",
      "Iteration 185, loss = 0.04632103\n",
      "Iteration 186, loss = 0.04587694\n",
      "Iteration 187, loss = 0.04554677\n",
      "Iteration 188, loss = 0.04579774\n",
      "Iteration 189, loss = 0.04526503\n",
      "Iteration 190, loss = 0.04510961\n",
      "Iteration 191, loss = 0.04523383\n",
      "Iteration 192, loss = 0.04501948\n",
      "Iteration 193, loss = 0.04474701\n",
      "Iteration 194, loss = 0.04490970\n",
      "Iteration 195, loss = 0.04482759\n",
      "Iteration 196, loss = 0.04429014\n",
      "Iteration 197, loss = 0.04459801\n",
      "Iteration 198, loss = 0.04439571\n",
      "Iteration 199, loss = 0.04430467\n",
      "Iteration 200, loss = 0.04428305\n",
      "Iteration 1, loss = 0.41915707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 0.21159554\n",
      "Iteration 3, loss = 0.15154236\n",
      "Iteration 4, loss = 0.12387241\n",
      "Iteration 5, loss = 0.11092880\n",
      "Iteration 6, loss = 0.10402894\n",
      "Iteration 7, loss = 0.09942283\n",
      "Iteration 8, loss = 0.09635958\n",
      "Iteration 9, loss = 0.09392643\n",
      "Iteration 10, loss = 0.09141943\n",
      "Iteration 11, loss = 0.09000845\n",
      "Iteration 12, loss = 0.08869311\n",
      "Iteration 13, loss = 0.08724646\n",
      "Iteration 14, loss = 0.08618655\n",
      "Iteration 15, loss = 0.08509944\n",
      "Iteration 16, loss = 0.08442341\n",
      "Iteration 17, loss = 0.08338630\n",
      "Iteration 18, loss = 0.08255092\n",
      "Iteration 19, loss = 0.08185355\n",
      "Iteration 20, loss = 0.08129812\n",
      "Iteration 21, loss = 0.08082071\n",
      "Iteration 22, loss = 0.07991900\n",
      "Iteration 23, loss = 0.07973043\n",
      "Iteration 24, loss = 0.07915062\n",
      "Iteration 25, loss = 0.07850903\n",
      "Iteration 26, loss = 0.07830904\n",
      "Iteration 27, loss = 0.07747879\n",
      "Iteration 28, loss = 0.07691516\n",
      "Iteration 29, loss = 0.07670182\n",
      "Iteration 30, loss = 0.07623289\n",
      "Iteration 31, loss = 0.07587054\n",
      "Iteration 32, loss = 0.07523723\n",
      "Iteration 33, loss = 0.07516842\n",
      "Iteration 34, loss = 0.07424378\n",
      "Iteration 35, loss = 0.07387118\n",
      "Iteration 36, loss = 0.07367396\n",
      "Iteration 37, loss = 0.07319993\n",
      "Iteration 38, loss = 0.07295063\n",
      "Iteration 39, loss = 0.07217895\n",
      "Iteration 40, loss = 0.07199582\n",
      "Iteration 41, loss = 0.07138900\n",
      "Iteration 42, loss = 0.07127178\n",
      "Iteration 43, loss = 0.07083093\n",
      "Iteration 44, loss = 0.07018642\n",
      "Iteration 45, loss = 0.07007883\n",
      "Iteration 46, loss = 0.07002878\n",
      "Iteration 47, loss = 0.06930200\n",
      "Iteration 48, loss = 0.06893224\n",
      "Iteration 49, loss = 0.06842627\n",
      "Iteration 50, loss = 0.06795580\n",
      "Iteration 51, loss = 0.06825490\n",
      "Iteration 52, loss = 0.06772652\n",
      "Iteration 53, loss = 0.06720172\n",
      "Iteration 54, loss = 0.06701444\n",
      "Iteration 55, loss = 0.06690644\n",
      "Iteration 56, loss = 0.06645615\n",
      "Iteration 57, loss = 0.06624031\n",
      "Iteration 58, loss = 0.06585517\n",
      "Iteration 59, loss = 0.06576852\n",
      "Iteration 60, loss = 0.06540599\n",
      "Iteration 61, loss = 0.06525489\n",
      "Iteration 62, loss = 0.06497211\n",
      "Iteration 63, loss = 0.06486608\n",
      "Iteration 64, loss = 0.06441118\n",
      "Iteration 65, loss = 0.06463741\n",
      "Iteration 66, loss = 0.06439795\n",
      "Iteration 67, loss = 0.06379905\n",
      "Iteration 68, loss = 0.06395586\n",
      "Iteration 69, loss = 0.06357472\n",
      "Iteration 70, loss = 0.06328342\n",
      "Iteration 71, loss = 0.06278944\n",
      "Iteration 72, loss = 0.06294772\n",
      "Iteration 73, loss = 0.06277872\n",
      "Iteration 74, loss = 0.06266643\n",
      "Iteration 75, loss = 0.06268480\n",
      "Iteration 76, loss = 0.06193711\n",
      "Iteration 77, loss = 0.06184456\n",
      "Iteration 78, loss = 0.06152071\n",
      "Iteration 79, loss = 0.06143631\n",
      "Iteration 80, loss = 0.06138127\n",
      "Iteration 81, loss = 0.06097040\n",
      "Iteration 82, loss = 0.06119477\n",
      "Iteration 83, loss = 0.06081687\n",
      "Iteration 84, loss = 0.06050494\n",
      "Iteration 85, loss = 0.06035547\n",
      "Iteration 86, loss = 0.06048817\n",
      "Iteration 87, loss = 0.05978923\n",
      "Iteration 88, loss = 0.05969988\n",
      "Iteration 89, loss = 0.05980992\n",
      "Iteration 90, loss = 0.05965187\n",
      "Iteration 91, loss = 0.05933990\n",
      "Iteration 92, loss = 0.05897060\n",
      "Iteration 93, loss = 0.05922058\n",
      "Iteration 94, loss = 0.05884073\n",
      "Iteration 95, loss = 0.05850751\n",
      "Iteration 96, loss = 0.05844509\n",
      "Iteration 97, loss = 0.05813724\n",
      "Iteration 98, loss = 0.05823121\n",
      "Iteration 99, loss = 0.05778401\n",
      "Iteration 100, loss = 0.05763849\n",
      "Iteration 101, loss = 0.05761831\n",
      "Iteration 102, loss = 0.05750676\n",
      "Iteration 103, loss = 0.05749038\n",
      "Iteration 104, loss = 0.05710797\n",
      "Iteration 105, loss = 0.05717322\n",
      "Iteration 106, loss = 0.05667380\n",
      "Iteration 107, loss = 0.05686065\n",
      "Iteration 108, loss = 0.05663340\n",
      "Iteration 109, loss = 0.05642790\n",
      "Iteration 110, loss = 0.05661114\n",
      "Iteration 111, loss = 0.05639170\n",
      "Iteration 112, loss = 0.05604054\n",
      "Iteration 113, loss = 0.05604922\n",
      "Iteration 114, loss = 0.05570810\n",
      "Iteration 115, loss = 0.05569480\n",
      "Iteration 116, loss = 0.05584398\n",
      "Iteration 117, loss = 0.05559389\n",
      "Iteration 118, loss = 0.05568256\n",
      "Iteration 119, loss = 0.05544162\n",
      "Iteration 120, loss = 0.05528628\n",
      "Iteration 121, loss = 0.05524143\n",
      "Iteration 122, loss = 0.05503607\n",
      "Iteration 123, loss = 0.05487811\n",
      "Iteration 124, loss = 0.05485728\n",
      "Iteration 125, loss = 0.05489200\n",
      "Iteration 126, loss = 0.05465186\n",
      "Iteration 127, loss = 0.05481406\n",
      "Iteration 128, loss = 0.05454632\n",
      "Iteration 129, loss = 0.05468120\n",
      "Iteration 130, loss = 0.05436433\n",
      "Iteration 131, loss = 0.05431102\n",
      "Iteration 132, loss = 0.05406807\n",
      "Iteration 133, loss = 0.05410041\n",
      "Iteration 134, loss = 0.05376036\n",
      "Iteration 135, loss = 0.05375950\n",
      "Iteration 136, loss = 0.05370072\n",
      "Iteration 137, loss = 0.05347872\n",
      "Iteration 138, loss = 0.05340910\n",
      "Iteration 139, loss = 0.05359825\n",
      "Iteration 140, loss = 0.05347847\n",
      "Iteration 141, loss = 0.05349379\n",
      "Iteration 142, loss = 0.05293822\n",
      "Iteration 143, loss = 0.05306633\n",
      "Iteration 144, loss = 0.05309779\n",
      "Iteration 145, loss = 0.05271381\n",
      "Iteration 146, loss = 0.05272937\n",
      "Iteration 147, loss = 0.05276210\n",
      "Iteration 148, loss = 0.05256535\n",
      "Iteration 149, loss = 0.05248958\n",
      "Iteration 150, loss = 0.05252580\n",
      "Iteration 151, loss = 0.05244779\n",
      "Iteration 152, loss = 0.05199763\n",
      "Iteration 153, loss = 0.05233902\n",
      "Iteration 154, loss = 0.05188202\n",
      "Iteration 155, loss = 0.05218380\n",
      "Iteration 156, loss = 0.05203812\n",
      "Iteration 157, loss = 0.05186829\n",
      "Iteration 158, loss = 0.05161801\n",
      "Iteration 159, loss = 0.05163842\n",
      "Iteration 160, loss = 0.05173244\n",
      "Iteration 161, loss = 0.05146051\n",
      "Iteration 162, loss = 0.05147243\n",
      "Iteration 163, loss = 0.05116502\n",
      "Iteration 164, loss = 0.05142397\n",
      "Iteration 165, loss = 0.05108301\n",
      "Iteration 166, loss = 0.05077124\n",
      "Iteration 167, loss = 0.05085198\n",
      "Iteration 168, loss = 0.05063228\n",
      "Iteration 169, loss = 0.05057045\n",
      "Iteration 170, loss = 0.05045670\n",
      "Iteration 171, loss = 0.05055575\n",
      "Iteration 172, loss = 0.05038852\n",
      "Iteration 173, loss = 0.05022013\n",
      "Iteration 174, loss = 0.05027179\n",
      "Iteration 175, loss = 0.05019018\n",
      "Iteration 176, loss = 0.05028010\n",
      "Iteration 177, loss = 0.04979244\n",
      "Iteration 178, loss = 0.05003529\n",
      "Iteration 179, loss = 0.04958581\n",
      "Iteration 180, loss = 0.04966501\n",
      "Iteration 181, loss = 0.04987154\n",
      "Iteration 182, loss = 0.04969220\n",
      "Iteration 183, loss = 0.04956638\n",
      "Iteration 184, loss = 0.04926170\n",
      "Iteration 185, loss = 0.04928667\n",
      "Iteration 186, loss = 0.04940489\n",
      "Iteration 187, loss = 0.04948260\n",
      "Iteration 188, loss = 0.04890340\n",
      "Iteration 189, loss = 0.04946434\n",
      "Iteration 190, loss = 0.04889934\n",
      "Iteration 191, loss = 0.04926596\n",
      "Iteration 192, loss = 0.04918368\n",
      "Iteration 193, loss = 0.04849019\n",
      "Iteration 194, loss = 0.04900270\n",
      "Iteration 195, loss = 0.04904909\n",
      "Iteration 196, loss = 0.04843694\n",
      "Iteration 197, loss = 0.04864364\n",
      "Iteration 198, loss = 0.04868134\n",
      "Iteration 199, loss = 0.04824268\n",
      "Iteration 200, loss = 0.04818922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_mlp_models = []\n",
    "pred_release_training_MLP = []\n",
    "pred_release_testing_MLP = []\n",
    "pred_release_prob_MLP = []\n",
    "\n",
    "confusion_matrixes_training = []\n",
    "confusion_matrixes_test = []\n",
    "#feature_importances = []\n",
    "\n",
    "f1_scores = []\n",
    "ROC_curves = []\n",
    "CV_scores = []\n",
    "R2_scores = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "\n",
    "\n",
    "n = 0\n",
    "for i in feature_combinations:\n",
    "    \n",
    "    X_train = train_X[i]\n",
    "    X_test = validation_X[i]\n",
    "\n",
    "    AUTO_SCALING = True\n",
    "    if AUTO_SCALING:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_training = scaler.transform(X_train)\n",
    "        X_testing = scaler.transform(X_test)\n",
    "       \n",
    "    #nnetwork = MLPClassifier(max_iter=1000)    \n",
    "   \n",
    "    clf_mlp = MLPClassifier(solver = best_param_grid[n][\"solver\"], hidden_layer_sizes = best_param_grid[n][\"hidden_layer_sizes\"], alpha = best_param_grid[n][\"alpha\"], max_iter=200,verbose=3)\n",
    "    clf_mlp.fit(X_training, train_y)\n",
    "    clf_mlp_models.append(clf_mlp)\n",
    "    \n",
    "    pred_release_at_training_MLP = clf_mlp.predict(X_training)\n",
    "    pred_release_training_MLP.append(pred_release_at_training_MLP)\n",
    "    \n",
    "    pred_prob_MLP = clf_mlp.predict_proba(X_testing)\n",
    "    pred_release_prob_MLP.append(pred_prob_MLP)\n",
    "    \n",
    "    pred_release_at_validation_MLP = clf_mlp.predict(X_testing)\n",
    "    pred_release_testing_MLP.append(pred_release_at_validation_MLP)\n",
    "    \n",
    "    c_m = confusion_matrix(train_y,pred_release_at_training_MLP)\n",
    "    confusion_matrixes_training.append(c_m)\n",
    "    \n",
    "    c_m_v = confusion_matrix(validation_y,pred_release_at_validation_MLP)\n",
    "    confusion_matrixes_test.append(c_m_v)\n",
    "    \n",
    "    f1 = f1_score(validation_y, pred_release_at_validation_MLP, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    CV = cross_val_score(estimator= clf_mlp, X=X_training, y=train_y)\n",
    "    CV_scores.append(CV)\n",
    "    \n",
    "    CLF_ROC = plot_roc_curve(clf_mlp, X_testing, validation_y, color = 'r')\n",
    "    ROC_curves.append(CLF_ROC)\n",
    "    \n",
    "    r2 = r2_score(validation_y, pred_release_at_validation_MLP)\n",
    "    R2_scores.append(r2)\n",
    "    \n",
    "    acc = accuracy_score(validation_y, pred_release_at_validation_MLP)\n",
    "    accuracy_scores.append(acc)\n",
    "    \n",
    "    precision = precision_score(validation_y, pred_release_at_validation_MLP)\n",
    "    precision_scores.append(precision)\n",
    "    \n",
    "    recall = recall_score(validation_y, pred_release_at_validation_MLP)\n",
    "    recall_scores.append(recall)\n",
    "    \n",
    "    roc_auc = roc_auc_score(validation_y, pred_release_at_validation_MLP)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_scores = pd.DataFrame(roc_auc_scores)\n",
    "roc_auc_scores.to_excel('MLP_roc_auc_scores.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9347584849395298,\n",
       " 0.9421821618515844,\n",
       " 0.9378428520173236,\n",
       " 0.9434316737955324,\n",
       " 0.9583133159789907,\n",
       " 0.9424137517354829,\n",
       " 0.9044306498295012,\n",
       " 0.9773161856663246]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MLP_p8_Emhjellen2.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save models\n",
    "joblib.dump(clf_mlp_models[0], \"MLP_p1_Emhjellen2.joblib\",compress=3)\n",
    "joblib.dump(clf_mlp_models[1], \"MLP_p2_Emhjellen2.joblib\",compress=3)\n",
    "joblib.dump(clf_mlp_models[2], \"MLP_p3_Emhjellen2.joblib\",compress=3)\n",
    "joblib.dump(clf_mlp_models[3], \"MLP_p4_Emhjellen2.joblib\",compress=3)\n",
    "joblib.dump(clf_mlp_models[4], \"MLP_p5_Emhjellen2.joblib\",compress=3)\n",
    "joblib.dump(clf_mlp_models[5], \"MLP_p6_Emhjellen2.joblib\",compress=3)\n",
    "joblib.dump(clf_mlp_models[6], \"MLP_p7_Emhjellen2.joblib\",compress=3)\n",
    "joblib.dump(clf_mlp_models[7], \"MLP_p8_Emhjellen2.joblib\",compress=3)\n",
    "\n",
    "# ../saved_models/RF_p6_Emhjellen2.joblib\",compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of confusion matrixes from training\n",
    "n = 0;\n",
    "for i in confusion_matrixes_training:\n",
    "    n += 1\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                i.flatten()]\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                     i.flatten()/np.sum(i)]\n",
    "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "    zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    plt.figure()\n",
    "    plot = sns.heatmap(i, annot=labels, fmt='', cmap='Blues')\n",
    "    plt.savefig('saved_figures_2/confusion_matrix_MLP_feature_combination_training'+ 'p'+ str(n) +'.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of confusion matrixes from test\n",
    "n = 0;\n",
    "for i in confusion_matrixes_test:\n",
    "    n += 1\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                i.flatten()]\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                     i.flatten()/np.sum(i)]\n",
    "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "    zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    plt.figure()\n",
    "    plot = sns.heatmap(i, annot=labels, fmt='', cmap='Blues')\n",
    "    plt.savefig('saved_figures_2/confusion_matrix_MLP_feature_combination_validation'+ 'p'+ str(n) +'.png')\n",
    "    plt.close()\n",
    "    \n",
    "    #plt.savefig('saved_figures/confusion_matrix_RF_feature_combination_validation'+ 'p'+ str(n) +'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot of feature importances\n",
    "#\n",
    "#n = 0;\n",
    "#for i in feature_importances:\n",
    "#    n += 1\n",
    "#    sns.barplot(x=i, y=i.index)\n",
    "#    # Add labels to your graph\n",
    "#    plt.xlabel('Feature Importance Score')\n",
    "#    plt.ylabel('Features')\n",
    "#    plt.title(\"Visualizing Important Features, Random Forest Classifier\")\n",
    "#    plt.savefig('saved_figures/feature_importances'+ 'p'+ str(n) +'.png')\n",
    "#    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bar plot of f1 scores\n",
    "\n",
    "fig = sns.barplot(x=np.arange(1,9), y=f1_scores,palette=\"Blues_d\")\n",
    "    \n",
    "plt.xlabel('Feature Combination')\n",
    "plt.ylabel('F1 score')\n",
    "plt.title(\"\")\n",
    "ticks = np.arange(0, 1, 0.05)\n",
    "fig.set_yticks(ticks, minor=True)\n",
    "fig.grid(which='both',axis='y',linestyle='dashed')\n",
    "plt.rc('axes', axisbelow=True)\n",
    "plt.savefig('saved_figures_2/f1_scores_MLP.png')\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of ROC curves\n",
    "\n",
    "ax = plt.gca()\n",
    "n = 0\n",
    "for i in ROC_curves:\n",
    "    n += 1\n",
    "    i.plot(ax=ax, alpha=0.8, label = 'Multilayer Perceptron '+ 'pc'+ str(n))\n",
    "plt.savefig('saved_figures_2/ROC_curve_feature_combinations_MLP_2.png')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_RF = pd.DataFrame(CV_scores)\n",
    "cv_scores_RF.to_excel('MLP_CV_scores_training2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_RF = pd.DataFrame(f1_scores)\n",
    "f1_scores_RF.to_excel('MLP_F1_scores2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores_RF = pd.DataFrame(accuracy_scores)\n",
    "accuracy_scores_RF.to_excel('MLP_accuracy_scores2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_scores_RF = pd.DataFrame(precision_scores)\n",
    "precision_scores_RF.to_excel('MLP_precision_scores2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_scores_RF = pd.DataFrame(recall_scores)\n",
    "recall_scores_RF.to_excel('MLP_recall_scores2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_scores_RF = pd.DataFrame(R2_scores)\n",
    "R2_scores_RF.to_excel('MLP_R2_scores2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_y = pd.read_excel('ML_validation_target.xlsx')\n",
    "\n",
    "df_coor = validation_y[['POINT_X', 'POINT_Y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[9.97470687e-01, 2.52931305e-03],\n",
       "        [9.92388891e-01, 7.61110902e-03],\n",
       "        [9.99954933e-01, 4.50666686e-05],\n",
       "        ...,\n",
       "        [9.97729349e-01, 2.27065067e-03],\n",
       "        [9.99758734e-01, 2.41266042e-04],\n",
       "        [5.75343437e-02, 9.42465656e-01]]),\n",
       " array([[9.95496170e-01, 4.50383045e-03],\n",
       "        [9.96941832e-01, 3.05816818e-03],\n",
       "        [9.99996681e-01, 3.31892368e-06],\n",
       "        ...,\n",
       "        [9.90598087e-01, 9.40191317e-03],\n",
       "        [9.99900512e-01, 9.94875201e-05],\n",
       "        [5.87574644e-02, 9.41242536e-01]]),\n",
       " array([[9.99260501e-01, 7.39498958e-04],\n",
       "        [9.92834329e-01, 7.16567106e-03],\n",
       "        [9.99999700e-01, 3.00463655e-07],\n",
       "        ...,\n",
       "        [9.98071849e-01, 1.92815056e-03],\n",
       "        [9.99989059e-01, 1.09412156e-05],\n",
       "        [7.29467907e-02, 9.27053209e-01]]),\n",
       " array([[9.91338430e-01, 8.66156964e-03],\n",
       "        [9.75380167e-01, 2.46198328e-02],\n",
       "        [9.99494463e-01, 5.05537141e-04],\n",
       "        ...,\n",
       "        [9.88260487e-01, 1.17395134e-02],\n",
       "        [9.98552617e-01, 1.44738254e-03],\n",
       "        [6.60257700e-02, 9.33974230e-01]]),\n",
       " array([[9.99125209e-01, 8.74790858e-04],\n",
       "        [9.99335276e-01, 6.64724159e-04],\n",
       "        [9.99999720e-01, 2.80214050e-07],\n",
       "        ...,\n",
       "        [9.98059160e-01, 1.94084005e-03],\n",
       "        [9.99998671e-01, 1.32880761e-06],\n",
       "        [2.20046881e-02, 9.77995312e-01]]),\n",
       " array([[9.94770171e-01, 5.22982910e-03],\n",
       "        [9.92554715e-01, 7.44528540e-03],\n",
       "        [9.99851032e-01, 1.48967786e-04],\n",
       "        ...,\n",
       "        [9.89634117e-01, 1.03658831e-02],\n",
       "        [9.99183537e-01, 8.16463159e-04],\n",
       "        [7.47756237e-02, 9.25224376e-01]]),\n",
       " array([[0.88712387, 0.11287613],\n",
       "        [0.94177284, 0.05822716],\n",
       "        [0.98548542, 0.01451458],\n",
       "        ...,\n",
       "        [0.59893444, 0.40106556],\n",
       "        [0.97907626, 0.02092374],\n",
       "        [0.44354404, 0.55645596]]),\n",
       " array([[1.00000000e+00, 2.52413611e-18],\n",
       "        [1.00000000e+00, 3.16123977e-12],\n",
       "        [1.00000000e+00, 7.06762001e-24],\n",
       "        ...,\n",
       "        [9.87077025e-01, 1.29229751e-02],\n",
       "        [1.00000000e+00, 9.61404640e-20],\n",
       "        [1.75775751e-03, 9.98242242e-01]])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_release_prob_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-361dda0d81ad>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_coor['MLP_prob_p1'] = pred_release_prob_MLP[0][:,1]\n"
     ]
    }
   ],
   "source": [
    "# extracting the values that are probability for rockfall, class 1\n",
    "\n",
    "df_coor['MLP_prob_p1'] = pred_release_prob_MLP[0][:,1]\n",
    "df_coor['MLP_prob_p2'] = pred_release_prob_MLP[1][:,1]\n",
    "df_coor['MLP_prob_p3'] = pred_release_prob_MLP[2][:,1]\n",
    "df_coor['MLP_prob_p4'] = pred_release_prob_MLP[3][:,1]\n",
    "df_coor['MLP_prob_p5'] = pred_release_prob_MLP[4][:,1]\n",
    "df_coor['MLP_prob_p6'] = pred_release_prob_MLP[5][:,1]\n",
    "df_coor['MLP_prob_p7'] = pred_release_prob_MLP[6][:,1]\n",
    "df_coor['MLP_prob_p8'] = pred_release_prob_MLP[7][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coor['MLP_prediction_p1'] = pred_release_testing_MLP[0]\n",
    "df_coor['MLP_prediction_p2'] = pred_release_testing_MLP[1]\n",
    "df_coor['MLP_prediction_p3'] = pred_release_testing_MLP[2]\n",
    "df_coor['MLP_prediction_p4'] = pred_release_testing_MLP[3]\n",
    "df_coor['MLP_prediction_p5'] = pred_release_testing_MLP[4]\n",
    "df_coor['MLP_prediction_p6'] = pred_release_testing_MLP[5]\n",
    "df_coor['MLP_prediction_p7'] = pred_release_testing_MLP[6]\n",
    "df_coor['MLP_prediction_p8'] = pred_release_testing_MLP[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_coor.to_excel('predition_results_validation_MLP2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_coor = pd.read_excel('predition_results_validation_MLP2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coor['ReleaseArea'] = validation_y['ReleaseArea'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = []\n",
    "for row in range(0,len(df_coor)):\n",
    "    if df_coor['ReleaseArea'].iloc[row] == 1 and df_coor['MLP_prediction_p1'].iloc[row] == 1:\n",
    "        result1.append('TP')\n",
    "    elif df_coor['ReleaseArea'].iloc[row] == 0 and df_coor['MLP_prediction_p1'].iloc[row] == 0:\n",
    "        result1.append('TN')\n",
    "    elif df_coor['MLP_prediction_p1'].iloc[row] == 1 and df_coor['ReleaseArea'].iloc[row] == 0:\n",
    "        result1.append('FP')\n",
    "    elif df_coor['MLP_prediction_p1'].iloc[row] == 0 and df_coor['ReleaseArea'].iloc[row] == 1:\n",
    "        result1.append('FN')\n",
    "    else:\n",
    "        print('NaN')\n",
    "        \n",
    "        \n",
    "df_coor['result_p1'] = result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = []\n",
    "for row in range(0,len(df_coor)):\n",
    "    if df_coor['ReleaseArea'].iloc[row] == 1 and df_coor['MLP_prediction_p2'].iloc[row] == 1:\n",
    "        result2.append('TP')\n",
    "    elif df_coor['ReleaseArea'].iloc[row] == 0 and df_coor['MLP_prediction_p2'].iloc[row] == 0:\n",
    "        result2.append('TN')\n",
    "    elif df_coor['MLP_prediction_p2'].iloc[row] == 1 and df_coor['ReleaseArea'].iloc[row] == 0:\n",
    "        result2.append('FP')\n",
    "    elif df_coor['MLP_prediction_p2'].iloc[row] == 0 and df_coor['ReleaseArea'].iloc[row] == 1:\n",
    "        result2.append('FN')\n",
    "    else:\n",
    "        print('NaN')\n",
    "        \n",
    "        \n",
    "df_coor['result_p2'] = result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = []\n",
    "for row in range(0,len(df_coor)):\n",
    "    if df_coor['ReleaseArea'].iloc[row] == 1 and df_coor['MLP_prediction_p3'].iloc[row] == 1:\n",
    "        result3.append('TP')\n",
    "    elif df_coor['ReleaseArea'].iloc[row] == 0 and df_coor['MLP_prediction_p3'].iloc[row] == 0:\n",
    "        result3.append('TN')\n",
    "    elif df_coor['MLP_prediction_p3'].iloc[row] == 1 and df_coor['ReleaseArea'].iloc[row] == 0:\n",
    "        result3.append('FP')\n",
    "    elif df_coor['MLP_prediction_p3'].iloc[row] == 0 and df_coor['ReleaseArea'].iloc[row] == 1:\n",
    "        result3.append('FN')\n",
    "    else:\n",
    "        print('NaN')\n",
    "        \n",
    "        \n",
    "df_coor['result_p3'] = result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4 = []\n",
    "for row in range(0,len(df_coor)):\n",
    "    if df_coor['ReleaseArea'].iloc[row] == 1 and df_coor['MLP_prediction_p4'].iloc[row] == 1:\n",
    "        result4.append('TP')\n",
    "    elif df_coor['ReleaseArea'].iloc[row] == 0 and df_coor['MLP_prediction_p4'].iloc[row] == 0:\n",
    "        result4.append('TN')\n",
    "    elif df_coor['MLP_prediction_p4'].iloc[row] == 1 and df_coor['ReleaseArea'].iloc[row] == 0:\n",
    "        result4.append('FP')\n",
    "    elif df_coor['MLP_prediction_p4'].iloc[row] == 0 and df_coor['ReleaseArea'].iloc[row] == 1:\n",
    "        result4.append('FN')\n",
    "    else:\n",
    "        print('NaN')\n",
    "        \n",
    "        \n",
    "df_coor['result_p4'] = result4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "result5 = []\n",
    "for row in range(0,len(df_coor)):\n",
    "    if df_coor['ReleaseArea'].iloc[row] == 1 and df_coor['MLP_prediction_p5'].iloc[row] == 1:\n",
    "        result5.append('TP')\n",
    "    elif df_coor['ReleaseArea'].iloc[row] == 0 and df_coor['MLP_prediction_p5'].iloc[row] == 0:\n",
    "        result5.append('TN')\n",
    "    elif df_coor['MLP_prediction_p5'].iloc[row] == 1 and df_coor['ReleaseArea'].iloc[row] == 0:\n",
    "        result5.append('FP')\n",
    "    elif df_coor['MLP_prediction_p5'].iloc[row] == 0 and df_coor['ReleaseArea'].iloc[row] == 1:\n",
    "        result5.append('FN')\n",
    "    else:\n",
    "        print('NaN')\n",
    "        \n",
    "        \n",
    "df_coor['result_p5'] = result5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "result6 = []\n",
    "for row in range(0,len(df_coor)):\n",
    "    if df_coor['ReleaseArea'].iloc[row] == 1 and df_coor['MLP_prediction_p6'].iloc[row] == 1:\n",
    "        result6.append('TP')\n",
    "    elif df_coor['ReleaseArea'].iloc[row] == 0 and df_coor['MLP_prediction_p6'].iloc[row] == 0:\n",
    "        result6.append('TN')\n",
    "    elif df_coor['MLP_prediction_p6'].iloc[row] == 1 and df_coor['ReleaseArea'].iloc[row] == 0:\n",
    "        result6.append('FP')\n",
    "    elif df_coor['MLP_prediction_p6'].iloc[row] == 0 and df_coor['ReleaseArea'].iloc[row] == 1:\n",
    "        result6.append('FN')\n",
    "    else:\n",
    "        print('NaN')\n",
    "        \n",
    "        \n",
    "df_coor['result_p6'] = result6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "result7 = []\n",
    "for row in range(0,len(df_coor)):\n",
    "    if df_coor['ReleaseArea'].iloc[row] == 1 and df_coor['MLP_prediction_p7'].iloc[row] == 1:\n",
    "        result7.append('TP')\n",
    "    elif df_coor['ReleaseArea'].iloc[row] == 0 and df_coor['MLP_prediction_p7'].iloc[row] == 0:\n",
    "        result7.append('TN')\n",
    "    elif df_coor['MLP_prediction_p7'].iloc[row] == 1 and df_coor['ReleaseArea'].iloc[row] == 0:\n",
    "        result7.append('FP')\n",
    "    elif df_coor['MLP_prediction_p7'].iloc[row] == 0 and df_coor['ReleaseArea'].iloc[row] == 1:\n",
    "        result7.append('FN')\n",
    "    else:\n",
    "        print('NaN')\n",
    "        \n",
    "        \n",
    "df_coor['result_p7'] = result7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result8 = []\n",
    "for row in range(0,len(df_coor)):\n",
    "    if df_coor['ReleaseArea'].iloc[row] == 1 and df_coor['MLP_prediction_p8'].iloc[row] == 1:\n",
    "        result8.append('TP')\n",
    "    elif df_coor['ReleaseArea'].iloc[row] == 0 and df_coor['MLP_prediction_p8'].iloc[row] == 0:\n",
    "        result8.append('TN')\n",
    "    elif df_coor['MLP_prediction_p8'].iloc[row] == 1 and df_coor['ReleaseArea'].iloc[row] == 0:\n",
    "        result8.append('FP')\n",
    "    elif df_coor['MLP_prediction_p8'].iloc[row] == 0 and df_coor['ReleaseArea'].iloc[row] == 1:\n",
    "        result8.append('FN')\n",
    "    else:\n",
    "        print('NaN')\n",
    "        \n",
    "        \n",
    "df_coor['result_p8'] = result8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coor.to_excel('prediction_results_validation_MLP2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
